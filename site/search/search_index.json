{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Nanobot Agentic Operating System","text":"<p>Production-ready documentation for deploying and operating the Nanobot AI agent framework.</p> <p>Nanobot is a lightweight (~4,000 lines), extensible agentic framework that: - Routes to 100+ LLM models (Claude, GPT-4, local Ollama, Qwen, DeepSeek, etc.) - Integrates with 12+ communication channels (Discord, Slack, Telegram, Feishu, etc.) - Executes 14 built-in tools (web search, file ops, shell, GitHub, scheduling, MCP) - Provides 9 pre-built skills (Obsidian, memory, summarization, cron, GitHub automation) - Manages cost through tiered routing and budget controls - Enforces security with role-based access control and audit logging</p>"},{"location":"#about-this-documentation","title":"About This Documentation","text":"<p>Repository: HKUDS/nanobot Nanobot Version: v0.1.4 and later Documentation Updated: February 25, 2026</p>"},{"location":"#get-the-code","title":"Get the Code","text":"<pre><code>git clone https://github.com/HKUDS/nanobot.git\ncd nanobot\npip install -e .\n</code></pre> <p>Or install from PyPI: <pre><code>pip install nanobot-ai\n</code></pre></p>"},{"location":"#quick-start-5-minutes","title":"Quick Start (5 Minutes)","text":"<ol> <li>Quick Install &amp; Setup \u2014 Get nanobot running locally with your LLM provider</li> <li>LLM Provider Setup \u2014 Configure any of 100+ models</li> <li>Multi-Channel Integration \u2014 Connect Discord, Slack, or other platforms</li> </ol>"},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Master Index \u2014 Overview of the entire system architecture</li> <li>Build Procedure \u2014 Deploy to production (simple or advanced)</li> <li>Startup Procedure \u2014 Bring system online</li> </ul>"},{"location":"#operating-nanobot","title":"Operating Nanobot","text":"<ul> <li>Essential Skills \u2014 5 core skills you need</li> <li>Tools &amp; Skills Reference \u2014 Complete inventory of all capabilities</li> <li>Workflow Examples \u2014 Real-world workflows to copy &amp; customize</li> <li>Daily knowledge consolidation</li> <li>Multi-channel content distribution</li> <li>Customer support bot</li> <li>Research agent</li> <li>GitHub automation</li> </ul>"},{"location":"#cost-governance","title":"Cost &amp; Governance","text":"<ul> <li>Cost Calculator &amp; Optimization \u2014 Estimate your bill, optimize routing</li> <li>Provider cost matrix (cheapest to premium)</li> <li>Monthly cost calculators with examples</li> <li>Multi-provider routing for 60-70% savings</li> <li> <p>Break-even analysis (cloud vs. self-hosted)</p> </li> <li> <p>Governance Policies \u2014 Multi-team deployments</p> </li> <li>Role-based access control</li> <li>Channel naming conventions</li> <li>Approval workflows</li> <li>Escalation rules</li> <li>Audit logging</li> <li>Cost allocation &amp; chargeback</li> </ul>"},{"location":"#security-compliance","title":"Security &amp; Compliance","text":"<ul> <li>Security Validation Runbook \u2014 Monthly audit procedures</li> </ul>"},{"location":"#system-overview","title":"System Overview","text":""},{"location":"#3-plane-architecture","title":"3-Plane Architecture","text":"<p>Control Plane: Multi-channel intake (Discord, Slack, Telegram, etc.) Policy Plane: LLM routing, cost controls, approval gates Memory Plane: Obsidian vault for durable records and audit trails</p>"},{"location":"#example-workflow","title":"Example Workflow","text":"<ol> <li>Operator asks in Slack: \"Find competitor campaigns this week and propose a test\"</li> <li>Nanobot receives message via Slack integration</li> <li>Policy routes to Claude Opus (high-value task)</li> <li>Nanobot executes: web_search \u2192 summarize \u2192 synthesizes findings</li> <li>Posts back to Slack with recommendation and source links</li> <li>Logs to Obsidian for audit trail and replay</li> </ol>"},{"location":"#common-use-cases","title":"Common Use Cases","text":"<ul> <li>Product Marketing: Auto-generate content, run competitor research, report KPI deltas</li> <li>Customer Support: 24/7 FAQ routing, knowledge base search, escalate complex cases</li> <li>Research &amp; Development: Capture sources, synthesize findings with citations, stage approval gates</li> <li>Operations/DevOps: GitHub workflow automation, health monitoring, runbook execution</li> <li>Bookkeeping: Expense categorization, transaction reconciliation, month-end summaries</li> </ul>"},{"location":"#core-capabilities-at-a-glance","title":"Core Capabilities at a Glance","text":"Capability Examples LLM Routing Claude, GPT-4, local Ollama, Qwen, DeepSeek, + 95+ more Channels Discord, Slack, Telegram, Feishu, DingTalk, WhatsApp, Email, QQ, Matrix, Mochat, CLI Tools Web search, file read/write/edit, shell commands, GitHub, scheduling, MCP, subagents Skills Obsidian, memory consolidation, summarize, cron, weather, GitHub, skill creator, TMUX Cost Control Tiered routing, budget caps, escalation gates, token tracking Security Role-based access, tool allowlisting, audit logging, workspace isolation"},{"location":"#choose-your-path","title":"Choose Your Path","text":"Local + Cloud LLM (Easiest)VPS + Local Ollama (Advanced) <ul> <li>Setup: 5-10 minutes</li> <li>Cost: $0-50/month</li> <li>Best for: Teams, quick experiments, cost-conscious orgs</li> </ul> <p>\u2192 Quick Install &amp; Setup</p> <ul> <li>Setup: 30-45 minutes</li> <li>Cost: $20-200/month</li> <li>Best for: Privacy, self-hosted inference, scale</li> </ul> <p>\u2192 Build Procedure</p>"},{"location":"#support-community","title":"Support &amp; Community","text":"<ul> <li>GitHub: HKUDS/nanobot</li> <li>Documentation Issues: File on GitHub</li> <li>Feature Requests: Open a discussion</li> </ul>"},{"location":"#version","title":"Version","text":"<p>This documentation covers Nanobot v0.1.4+ (released February 2026)</p> <p>Last updated: February 25, 2026</p>"},{"location":"AOS-Startup-Procedure/","title":"AOS Startup Procedure","text":"<p>Bring nanobot from fully powered down to fully operational. Choose your path based on your deployment scenario.</p>"},{"location":"AOS-Startup-Procedure/#document-control","title":"Document Control","text":"<ul> <li>Owner:</li> <li>Version: 2.0.0</li> <li>Last Updated: 2026-02-25</li> <li>Status: Active</li> </ul>"},{"location":"AOS-Startup-Procedure/#1-overview","title":"1. Overview","text":"<p>Two startup scenarios: - Simple Startup (10 min) - Local nanobot + cloud LLM (Large Language Model) API - Advanced Startup (15 min) - VPS (Virtual Private Server) nanobot + local Ollama inference</p> <p>Both assume initial setup is complete (config files, secrets stored, channels configured).</p>"},{"location":"AOS-Startup-Procedure/#2-assumptions","title":"2. Assumptions","text":"<ul> <li>Installation and hardening are complete</li> <li>Config files exist (<code>~/.nanobot/config.json</code> or <code>.env</code>)</li> <li>All required secrets (API keys, tokens) are stored securely</li> <li>Channels are already configured (Discord, Slack, etc.)</li> <li>Obsidian vault exists (if using obsidian skill)</li> </ul>"},{"location":"AOS-Startup-Procedure/#3-startup-checklist-high-level","title":"3. Startup Checklist (High-Level)","text":"<p>Before you start, make sure you have: - [ ] Internet connection (required for cloud LLM) - [ ] Required services running (Ollama, Tailscale, VPS, etc. per your architecture) - [ ] LLM (language model) provider accessibility confirmed - [ ] Chat bot status verified (Discord/Slack/etc.) - [ ] One quick test command ready to verify end-to-end flow - [ ] Obsidian integration confirmed (if you're using it)</p>"},{"location":"AOS-Startup-Procedure/#path-a-simple-startup-local-cloud-api","title":"Path A: Simple Startup (Local + Cloud API)","text":"<p>For: Using local nanobot with OpenRouter, Anthropic, OpenAI, or other cloud LLM provider. Time: ~10 minutes</p>"},{"location":"AOS-Startup-Procedure/#step-1-verify-connectivity","title":"Step 1: Verify Connectivity","text":"<pre><code>ping 8.8.8.8\n# Should respond with pings (internet is up)\n</code></pre>"},{"location":"AOS-Startup-Procedure/#step-2-start-nanobot","title":"Step 2: Start nanobot","text":"<pre><code>nanobot gateway\n</code></pre> <p>Should show: <pre><code>Starting Nanobot Gateway v0.1.4+\nLLM Provider: openrouter \u2713 Connected\nDiscord: Connected \u2713\nSlack: Connected \u2713\nReady for messages\n</code></pre></p> <p>If provider fails: - Check <code>.env</code> or <code>config.json</code> for correct API key format - Verify key hasn't expired in your provider dashboard - If key is fresh, wait 1 minute and retry (API sync delay)</p>"},{"location":"AOS-Startup-Procedure/#step-3-discordslack-test","title":"Step 3: Discord/Slack Test","text":"<p>Send a test message in any channel where bot is installed: <pre><code>@BotName hello\n</code></pre></p> <p>Bot should respond within 5 seconds.</p> <p>If bot doesn't respond: - Verify bot is in the channel - Check bot has <code>Send Messages</code> and <code>Read Message History</code> permissions - Verify token in config matches what Discord/Slack shows - Check logs: <code>nanobot logs --last 50</code> to see errors</p>"},{"location":"AOS-Startup-Procedure/#step-4-obsidian-write-test-optional","title":"Step 4: Obsidian Write Test (Optional)","text":"<p>In Discord: <pre><code>@BotName write to Obsidian: \"Startup test at {{timestamp}}\" to 00-System/startup-log.md\n</code></pre></p> <p>Check Obsidian vault. File should appear in <code>00-System/startup-log.md</code>.</p>"},{"location":"AOS-Startup-Procedure/#validation-gate-a","title":"Validation Gate A","text":"<ul> <li>\u2713 nanobot gateway starts without errors</li> <li>\u2713 LLM provider connected</li> <li>\u2713 Bot responds to test message in Discord/Slack</li> <li>\u2713 Obsidian write succeeds (if enabled)</li> </ul>"},{"location":"AOS-Startup-Procedure/#path-b-advanced-startup-vps-local-ollama","title":"Path B: Advanced Startup (VPS + Local Ollama)","text":"<p>For: Using VPS-hosted nanobot with local Ollama inference. Architecture: VPS (gateway) \u2194\ufe0f Local Windows/Mac (Ollama) via Tailscale Time: ~15 minutes</p>"},{"location":"AOS-Startup-Procedure/#step-1-start-local-inference-node","title":"Step 1: Start Local Inference Node","text":"<p>On Windows/Mac (where Ollama is installed):</p> <pre><code>ollama serve\n</code></pre> <p>Keep this running in a terminal. Ollama should listen on <code>localhost:11434</code>.</p>"},{"location":"AOS-Startup-Procedure/#step-2-verify-ollama-is-running","title":"Step 2: Verify Ollama is Running","text":"<pre><code>curl http://localhost:11434/api/tags\n# Should return JSON list of models\n</code></pre>"},{"location":"AOS-Startup-Procedure/#step-3-connect-tailscale-both-machines","title":"Step 3: Connect Tailscale (Both Machines)","text":"<p>On Local Machine: <pre><code>tailscale up\n# Will print: Connected to tailnet as [device-name]\n# Note your local Tailscale IP (e.g., 100.123.45.67)\n</code></pre></p> <p>On VPS: <pre><code>tailscale up\n# Note VPS Tailscale IP (e.g., 100.87.123.45)\n</code></pre></p> <p>Enable MagicDNS in Tailscale admin panel (recommended): https://login.tailscale.com/admin/dns</p>"},{"location":"AOS-Startup-Procedure/#step-4-test-tailscale-path-from-vps","title":"Step 4: Test Tailscale Path (From VPS)","text":"<pre><code>curl http://100.123.45.67:11434/api/tags\n# Should return model list from local Ollama\n</code></pre> <p>If fails: - Check local firewall allows port 11434 (scope to Tailscale interface only) - Verify Ollama is running on local machine - Restart Tailscale on both sides and re-authenticate</p>"},{"location":"AOS-Startup-Procedure/#step-5-start-nanobot-on-vps","title":"Step 5: Start Nanobot on VPS","text":"<pre><code>ssh your-vps-user@your-vps-ip\n# Or use tailscale: ssh your-vps-name\n\n# Start nanobot\nnanobot gateway\n</code></pre> <p>Should show: <pre><code>Starting Nanobot Gateway v0.1.4+\nLLM Provider: ollama \u2713 Connected to http://100.123.45.67:11434\nDiscord: Connected \u2713\nReady for messages\n</code></pre></p>"},{"location":"AOS-Startup-Procedure/#step-6-test-end-to-end","title":"Step 6: Test End-to-End","text":"<p>From Discord/Slack, send: <pre><code>@BotName What is 2+2?\n</code></pre></p> <p>Expected flow: 1. Discord receives message 2. Nanobot (VPS) forwards to Ollama (Local) 3. Ollama generates response 4. Response posted back to Discord</p> <p>If no response: - Check VPS logs: <code>journalctl -u nanobot -n 50</code> (if using systemd service) - Verify Tailscale path again: <code>curl http://100.123.45.67:11434</code> from VPS - Check Ollama logs on local machine for errors - Verify nanobot config has correct Ollama endpoint</p>"},{"location":"AOS-Startup-Procedure/#validation-gate-b","title":"Validation Gate B","text":"<ul> <li>\u2713 Ollama running locally and responding to curl</li> <li>\u2713 Tailscale connected on both machines</li> <li>\u2713 VPS can reach local Ollama via Tailscale IP</li> <li>\u2713 Nanobot gateway starts on VPS</li> <li>\u2713 End-to-end message \u2192 Ollama \u2192 response works</li> <li>\u2713 Discord bot online and responding</li> </ul>"},{"location":"AOS-Startup-Procedure/#common-issues-fixes","title":"Common Issues &amp; Fixes","text":"Symptom Likely Cause Check Fix \"Provider disconnected\" API key invalid/expired Verify in <code>.env</code> and provider dashboard Rotate API key, update config, restart nanobot Bot offline in Discord Token wrong or permissions missing Check developer portal settings Verify token and Message Content Intent enabled Ollama unreachable Network/firewall issue <code>curl http://Local-IP:11434</code> from VPS Allow port 11434 on local firewall; check Tailscale route No response to test message Bot offline or wrong config Check logs and provider status See logs; verify config; restart gateway"},{"location":"AOS-Startup-Procedure/#post-startup-validation","title":"Post-Startup Validation","text":""},{"location":"AOS-Startup-Procedure/#quick-health-check","title":"Quick Health Check","text":"<pre><code>nanobot health\n</code></pre> <p>Expected output: <pre><code>\u2713 Gateway running\n\u2713 LLM provider connected\n\u2713 Discord online\n\u2713 Ollama reachable (if Path B)\n\u2713 Memory consolidation healthy\n</code></pre></p>"},{"location":"AOS-Startup-Procedure/#detailed-logs","title":"Detailed Logs","text":"<pre><code>nanobot logs --follow\n</code></pre> <p>Watch for: - Successful provider connections - Message ingestion from channels - Tool execution traces - Error or warnings</p>"},{"location":"AOS-Startup-Procedure/#startup-monitoring-optional","title":"Startup Monitoring (Optional)","text":""},{"location":"AOS-Startup-Procedure/#monitor-resource-usage","title":"Monitor Resource Usage","text":"<pre><code># On VPS or local machine\ntop\n# Look for: nanobot process CPU/memory usage\n# Should be low at idle (~1-5% CPU, &lt;200MB RAM)\n</code></pre>"},{"location":"AOS-Startup-Procedure/#check-service-persistence-advanced","title":"Check Service Persistence (Advanced)","text":"<p>If using systemd service on VPS: <pre><code>sudo systemctl status nanobot\nsudo systemctl restart nanobot\n# Service should restart cleanly without errors\n</code></pre></p>"},{"location":"AOS-Startup-Procedure/#shutdown-procedure-when-needed","title":"Shutdown Procedure (When Needed)","text":""},{"location":"AOS-Startup-Procedure/#simple-path","title":"Simple Path","text":"<pre><code># Gracefully stop nanobot (Ctrl+C in terminal)\nCtrl+C\n# Nanobot will finish current message and shut down\n</code></pre>"},{"location":"AOS-Startup-Procedure/#advanced-path-vps","title":"Advanced Path (VPS)","text":"<pre><code># Stop systemd service\nsudo systemctl stop nanobot\n\n# Or kill process\npkill -f nanobot\n</code></pre>"},{"location":"AOS-Startup-Procedure/#post-startup-notes","title":"Post-Startup Notes","text":"<p>After successful startup: - Monitor logs for first hour for any warnings - Test a real workflow (not just \"hello\") - Check Obsidian write-back if applicable - Verify cost tracking working (tokens logged, cost estimated) - Document any customizations for recovery purposes</p>"},{"location":"AOS-Startup-Procedure/#revision-history","title":"Revision History","text":"Date Version Change 2026-02-25 2.0.0 Complete rewrite: Added simple startup path (local + cloud API); advanced startup path (VPS + Ollama); split scenario-specific instructions; added detailed troubleshooting; removed WSL2 references Previous 1.1.0 WSL2-based startup procedure"},{"location":"Advanced-Skill-Development/","title":"Advanced Skill Development","text":"<p>Purpose: Create custom skills beyond pre-built capabilities. Build new commands, tools, and automations tailored to your deployment.</p>"},{"location":"Advanced-Skill-Development/#1-understanding-skills-architecture","title":"1. Understanding Skills Architecture","text":"<p>A Skill is an extension that adds new capabilities to your nanobot deployment. Unlike pre-built skills, custom skills are: - Created on-demand for your specific workflows - Hot-reloaded without system restart - Composable\u2014built from existing tools - Operator-injectable via chat interface</p>"},{"location":"Advanced-Skill-Development/#11-skill-types","title":"1.1 Skill Types","text":"Skill Type Best For Complexity Deploy Time Prompt-Only Reasoning, summarization, content generation Low &lt;5 min Tool-Based System integration, API calls, file operations Medium 15-30 min Orchestrated Multi-step workflows, delegated sub-tasks High 30+ min"},{"location":"Advanced-Skill-Development/#2-skill-file-structure","title":"2. Skill File Structure","text":"<p>Every skill needs this directory structure:</p> <pre><code>~/.nanobot/skills/my-custom-skill/\n\u251c\u2500\u2500 SKILL.md          # Metadata + logic (required)\n\u251c\u2500\u2500 README.md         # Usage guide (optional)\n\u251c\u2500\u2500 requirements.txt  # Python dependencies (if tool-based)\n\u2514\u2500\u2500 implementation.py # Python code (if tool-based)\n</code></pre>"},{"location":"Advanced-Skill-Development/#3-skillmd-format","title":"3. SKILL.md Format","text":"<p>The <code>SKILL.md</code> file defines your skill's metadata and behavior.</p>"},{"location":"Advanced-Skill-Development/#31-minimal-prompt-only-skill","title":"3.1 Minimal Prompt-Only Skill","text":"<p>Example: Daily Standup Generator</p> <pre><code>---\nname: standup\ndescription: Summarizes recent work into a standup report\nversion: 1.0.0\ncategory: reporting\nuser-invocable: true\n---\n\n# Purpose\nGenerate a concise standup summary from recent Obsidian logs.\n\n# Trigger\nUser types: `/standup` or mentions \"give me a standup\"\n\n# Workflow\n1. Search Obsidian vault for files modified in last 24 hours from `07-Projects/` folder\n2. Read the 3 most recent entries\n3. Extract \"Completed\", \"In Progress\", \"Blockers\" sections\n4. Format as brief standup (Yesterday \u2192 Today \u2192 Blockers)\n\n# Output Format\n**Yesterday:** [bullet list of completed items]\n**Today:** [planned work]\n**Blockers:** [any issues or blocked items]\n\n# Example Output\n**Yesterday:** \n- Reviewed PR #123\n- Updated cost calculator guide\n\n**Today:**\n- Finish skill development documentation\n- Deploy to staging\n\n**Blockers:**\n- Waiting on LLM provider API key response\n</code></pre>"},{"location":"Advanced-Skill-Development/#32-tool-based-skill-python","title":"3.2 Tool-Based Skill (Python)","text":"<p>Example: System Health Monitor</p> <pre><code>---\nname: health-check\ndescription: Monitor system resources and connection health\nversion: 1.0.0\ncategory: operations\ntype: tool-based\nentry-point: implementation.py::run_health_check\nuser-invocable: true\ntools-required: [shell_exec, message_send]\n---\n\n# Purpose\nCheck CPU, memory, disk, and network health. Alert if thresholds exceeded.\n\n# Trigger\nUser types: `/health` or automatic daily at 09:00 UTC\n\n# Metrics Checked\n- CPU usage &gt; 80% \u2192 WARN\n- Memory usage &gt; 85% \u2192 WARN\n- Disk usage &gt; 90% \u2192 CRITICAL\n- Nanobot process running \u2192 OK/FAIL\n- Connection to LLM provider \u2192 OK/FAIL\n\n# Output\nColor-coded status board (Slack/Discord format)\n\n# Configuration\nthreshold_cpu: 80\nthreshold_memory: 85\nthreshold_disk: 90\nalert_channel: #alerts\n</code></pre> <p>Associated <code>implementation.py</code>:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"Health check monitoring skill.\"\"\"\n\nimport psutil\nimport json\nfrom datetime import datetime\n\nasync def run_health_check(context):\n    \"\"\"Check system health and return status board.\"\"\"\n\n    metrics = {\n        \"timestamp\": datetime.utcnow().isoformat(),\n        \"cpu_percent\": psutil.cpu_percent(interval=1),\n        \"memory_percent\": psutil.virtual_memory().percent,\n        \"disk_percent\": psutil.disk_usage(\"/\").percent,\n        \"nanobot_running\": check_nanobot_process(),\n        \"llm_provider_healthy\": await check_llm_connection(),\n    }\n\n    # Determine status\n    status = \"\ud83d\udfe2 HEALTHY\"\n    if metrics[\"cpu_percent\"] &gt; 80 or metrics[\"memory_percent\"] &gt; 85:\n        status = \"\ud83d\udfe1 WARNING\"\n    if metrics[\"disk_percent\"] &gt; 90:\n        status = \"\ud83d\udd34 CRITICAL\"\n\n    # Format for Discord/Slack\n    message = format_status_board(metrics, status)\n\n    return {\n        \"status\": status,\n        \"metrics\": metrics,\n        \"message\": message\n    }\n\ndef check_nanobot_process():\n    \"\"\"Check if nanobot is running.\"\"\"\n    for proc in psutil.process_iter(['name']):\n        if 'nanobot' in proc.info['name'].lower():\n            return True\n    return False\n\nasync def check_llm_connection():\n    \"\"\"Verify LLM provider connectivity.\"\"\"\n    # Implementation depends on configured provider\n    # (OpenAI, Anthropic, local Ollama, etc.)\n    pass\n\ndef format_status_board(metrics, status):\n    \"\"\"Format metrics as readable board.\"\"\"\n    board = f\"\"\"\n**System Health Report** {status}\n\n**CPU:** {metrics['cpu_percent']}%\n**Memory:** {metrics['memory_percent']}%\n**Disk:** {metrics['disk_percent']}%\n\n**Services:**\n- Nanobot: {'\u2705 Running' if metrics['nanobot_running'] else '\u274c Down'}\n- LLM Provider: {'\u2705 Connected' if metrics['llm_provider_healthy'] else '\u274c Error'}\n\n*Updated: {metrics['timestamp']}*\n    \"\"\"\n    return board\n</code></pre>"},{"location":"Advanced-Skill-Development/#4-operator-injected-skills-discord","title":"4. Operator-Injected Skills (Discord)","text":"<p>You can inject new skills directly through Discord without touching terminals.</p>"},{"location":"Advanced-Skill-Development/#41-from-a-repository","title":"4.1 From a Repository","text":"<p>If you find a skill on GitHub or a skill marketplace:</p> <ol> <li> <p>Paste the link in Discord: <pre><code>@nanobot install skill: https://github.com/user/nanobot-skill-example\n</code></pre></p> </li> <li> <p>The bot will:</p> </li> <li>Analyze the SKILL.md file</li> <li>Check for security risks (shell_exec, file_write permissions)</li> <li> <p>Ask for confirmation: \"Install 'Example Skill' from user/nanobot-skill-example?\"</p> </li> <li> <p>Once approved:</p> </li> <li>Clones to <code>~/.nanobot/skills/</code></li> <li>Hot-reloads the gateway</li> <li>Confirms: \"Skill registered. Try <code>/example</code> to test.\"</li> </ol>"},{"location":"Advanced-Skill-Development/#42-create-a-new-skill-via-chat","title":"4.2 Create a New Skill via Chat","text":"<p>You can tell nanobot to write its own skill:</p> <pre><code>@nanobot create skill:\n- Name: task-tracker\n- Goal: Extract TODO items from my Discord messages\n- Action: Append them to Obsidian inbox.md\n- Trigger: Any message starting with \"TODO:\"\n</code></pre> <p>The bot will: 1. Draft the SKILL.md with appropriate metadata 2. Generate associated Python code (if tool-based) 3. Write files to the workspace 4. Ask for confirmation before activation 5. Test the new skill with a sample message</p>"},{"location":"Advanced-Skill-Development/#5-skill-lifecycle-management","title":"5. Skill Lifecycle Management","text":""},{"location":"Advanced-Skill-Development/#51-activation","title":"5.1 Activation","text":"<p>Once deployed, a skill is inactive by default. Enable it:</p> <pre><code>/skill enable task-tracker\n/skill list --enabled\n</code></pre>"},{"location":"Advanced-Skill-Development/#52-testing","title":"5.2 Testing","text":"<p>Before deploying to production:</p> <pre><code>/skill test task-tracker --sample \"TODO: Review PR #42\"\n</code></pre>"},{"location":"Advanced-Skill-Development/#53-monitoring","title":"5.3 Monitoring","text":"<p>Track how often your skills are used:</p> <pre><code>/skill stats --skill standup --days 7\n</code></pre> <p>Returns: Usage count, average execution time, error rate, tokens burned.</p>"},{"location":"Advanced-Skill-Development/#54-updates","title":"5.4 Updates","text":"<p>When you update a SKILL.md or implementation.py:</p> <pre><code>/skill reload task-tracker\n</code></pre> <p>No restart needed\u2014changes take effect immediately.</p>"},{"location":"Advanced-Skill-Development/#55-deactivation","title":"5.5 Deactivation","text":"<pre><code>/skill disable task-tracker\n/skill uninstall task-tracker  # Removes files from workspace\n</code></pre>"},{"location":"Advanced-Skill-Development/#6-security-permissions","title":"6. Security &amp; Permissions","text":"<p>Skills are sandboxed by default. Access to dangerous operations requires explicit allowlisting.</p>"},{"location":"Advanced-Skill-Development/#61-permission-tiers","title":"6.1 Permission Tiers","text":"Permission Description Risk Level Approval read_obsidian Read vault files Low Auto-allow write_obsidian Create/edit notes Medium Operator approval shell_exec Run system commands High Config allowlist file_write Write files outside Obsidian High Config allowlist mcp_call Access external APIs High Config allowlist message_send Send external messages Medium Config allowlist"},{"location":"Advanced-Skill-Development/#62-declaring-permissions","title":"6.2 Declaring Permissions","text":"<p>In your SKILL.md:</p> <pre><code>---\nname: advanced-task-processor\npermissions:\n  - read_obsidian\n  - write_obsidian\n  - shell_exec\n  - mcp_call\n---\n</code></pre> <p>When someone tries to enable this skill, nanobot will warn: <pre><code>\u26a0\ufe0f This skill requests:\n- Shell execution (HIGH RISK)\n- MCP integration (HIGH RISK)\n\nOnly enable if you trust the source and understand what it does.\n</code></pre></p>"},{"location":"Advanced-Skill-Development/#63-for-shared-deployments","title":"6.3 For Shared Deployments","text":"<p>If running nanobot across teams, restrict skill creation:</p> <pre><code># In nanobot.json\n\"skills\": {\n  \"allow_operator_injection\": true,      # Operators can create/inject\n  \"require_approval_for_dangerous\": true, # Shell/file access needs approval\n  \"sandbox_shell_commands\": true         # Isolate shell execution\n}\n</code></pre>"},{"location":"Advanced-Skill-Development/#7-real-world-examples","title":"7. Real-World Examples","text":""},{"location":"Advanced-Skill-Development/#71-obsidian-note-tagging-prompt-only","title":"7.1 Obsidian Note Tagging (Prompt-Only)","text":"<pre><code>---\nname: auto-tag\ndescription: Tag Obsidian notes based on Discord channel\nuser-invocable: false\ntrigger: on_note_create\n---\n\n# When triggered\nWhen a note is created from Discord message, automatically:\n1. Extract the source channel name\n2. Prepend tag: #channel-name\n3. Add to daily journal entry\n4. Link back to Discord message thread\n\n# Example\nDiscord: #prd-marketing channel\nMessage: \"New campaign idea: seasonal push\"\n\u2192 Obsidian note created with:\n  - Title: \"New campaign idea: seasonal push\"\n  - Tags: #prd-marketing\n  - Link: discord://channel/prd-marketing/msg_id\n</code></pre>"},{"location":"Advanced-Skill-Development/#72-weekly-digest-tool-based","title":"7.2 Weekly Digest (Tool-Based)","text":"<pre><code>---\nname: weekly-digest\ndescription: Compile week's work into formatted report\nversion: 1.0.0\ntype: tool-based\nentry-point: digest.py::generate_weekly_digest\ntrigger: manual or cron:0 9 * * 1  # Mon 9 AM\npermissions:\n  - read_obsidian\n  - write_obsidian\n  - message_send\n---\n\n# Workflow\n1. Search Obsidian for notes created/modified Mon-Fri\n2. Group by project/domain\n3. Count completions, blockers, metrics\n4. Generate formatted report\n5. Post to #weekly-digest Discord channel\n6. Archive report in Obsidian\n</code></pre>"},{"location":"Advanced-Skill-Development/#73-cost-tracker-integrated-with-llm-logging","title":"7.3 Cost Tracker (Integrated with LLM Logging)","text":"<pre><code>---\nname: cost-tracker\ndescription: Monitor daily spend across LLM providers\ntype: tool-based\npermissions:\n  - read_obsidian\ntrigger: cron:0 20 * * *  # 8 PM daily\n---\n\n# Pulls from\n- Nanobot's internal token ledger\n- Configured LLM provider rates\n- Project/channel cost breakdowns\n\n# Outputs\n- Daily cost report\n- Weekly forecast\n- Provider efficiency comparison\n- Alert if approaching daily cap\n</code></pre>"},{"location":"Advanced-Skill-Development/#8-best-practices","title":"8. Best Practices","text":""},{"location":"Advanced-Skill-Development/#81-skill-naming","title":"8.1 Skill Naming","text":"<p>Use consistent patterns: - Action verbs: <code>generate-</code>, <code>summarize-</code>, <code>fetch-</code>, <code>track-</code> - Domains: <code>obsidian-</code>, <code>discord-</code>, <code>github-</code>, <code>slack-</code> - Examples: <code>summarize-daily-logs</code>, <code>fetch-github-prs</code>, <code>track-costs</code></p>"},{"location":"Advanced-Skill-Development/#82-documentation","title":"8.2 Documentation","text":"<p>Every skill should include:</p> <pre><code># [Skill Name]\n\n**Purpose:** One-line description\n\n**Trigger:** How it's invoked (/command, automatic, manual)\n\n**Prerequisites:** Required tools, LLM providers, channels\n\n**Setup:** Step-by-step instructions\n\n**Example Usage:** Copy-paste example\n\n**Output:** What to expect\n\n**Troubleshooting:** Common issues and fixes\n\n**Cost:** Estimated tokens/month if applicable\n</code></pre>"},{"location":"Advanced-Skill-Development/#83-testing-before-deployment","title":"8.3 Testing Before Deployment","text":"<pre><code># Test locally\nnanobot skill test --skill my-skill --sample \"test input\" --verbose\n\n# Check for errors\nnanobot skill validate --skill my-skill\n\n# Review permissions\nnanobot skill inspect --skill my-skill --show-permissions\n</code></pre>"},{"location":"Advanced-Skill-Development/#84-version-management","title":"8.4 Version Management","text":"<p>Include version in SKILL.md metadata:</p> <pre><code>---\nversion: 1.0.0  # Semantic versioning\ncompatibility: \"nanobot &gt;= 0.1.4\"\nchangelog:\n  1.0.0: Initial release\n  0.9.0: Beta testing\n---\n</code></pre>"},{"location":"Advanced-Skill-Development/#9-extending-with-mcp-model-context-protocol","title":"9. Extending with MCP (Model Context Protocol)","text":"<p>Skills can integrate external tools via MCP\u2014databases, file systems, APIs, etc.</p>"},{"location":"Advanced-Skill-Development/#91-example-database-query-skill","title":"9.1 Example: Database Query Skill","text":"<pre><code>---\nname: query-database\ntype: tool-based\nmcp-tools:\n  - sqlite  # Built-in SQLite support\npermissions:\n  - mcp_call\n---\n\n# When user asks\n\"Show me all tasks from last 30 days\"\n\n# Skill processes\n1. Parse natural language for query intent\n2. Translate to SQL: SELECT * FROM tasks WHERE created &gt;= date('now', '-30 days')\n3. Execute via MCP sqlite provider\n4. Format results as table or summary\n5. Post to Discord\n</code></pre>"},{"location":"Advanced-Skill-Development/#10-troubleshooting","title":"10. Troubleshooting","text":"Problem Cause Solution Skill won't register Malformed SKILL.md metadata Run <code>nanobot skill validate</code> to check syntax Skill runs but no output Missing tool permissions Add to <code>permissions:</code> in SKILL.md High token usage Inefficient prompting Add context limits or break into sub-tasks Skill crashes silently Python dependency missing Add to <code>requirements.txt</code> and reinstall Changes don't take effect Skill not reloaded Run <code>/skill reload skillname</code>"},{"location":"Advanced-Skill-Development/#11-see-also","title":"11. See Also","text":"<ul> <li>Tools &amp; Skills Reference \u2014 Complete list of 14 built-in tools</li> <li>Governance Policies \u2014 Skill allowlisting for teams</li> <li>Workflow Examples \u2014 Real patterns you can adapt</li> <li>Cost Calculator \u2014 Estimate skill execution costs</li> </ul>"},{"location":"Cost-Calculator-and-Optimization/","title":"Cost Calculator &amp; Optimization Guide","text":"<p>Plan your nanobot deployment cost. Estimate monthly spend, optimize provider routing, and set budget controls.</p> <p>(A token \u2248 1 word. This guide helps you predict how much you'll spend.)</p>"},{"location":"Cost-Calculator-and-Optimization/#document-control","title":"Document Control","text":"<ul> <li>Owner:</li> <li>Version: 1.0.0</li> <li>Last Updated: 2026-02-25</li> <li>Status: Active</li> </ul>"},{"location":"Cost-Calculator-and-Optimization/#1-provider-cost-matrix","title":"1. Provider Cost Matrix","text":"Provider Model Example Cost/1K Tokens Latency Best For Notes OpenRouter GPT-4, Claude 3.5 $0.002-0.03 &lt;2s Cost-conscious mixed Best value for quality; supports 100+ models Anthropic Claude 3 Opus $0.015 &lt;3s Premium tasks Most capable; prompt caching reduces cost OpenAI GPT-4o $0.005 &lt;2s General purpose Reliable; expensive for high volume Qwen (via OpenRouter) Qwen2-72B $0.0005 &lt;4s Budget tier Cheapest option; good quality for cost DeepSeek DeepSeek-67B $0.0003 &lt;5s Ultra-budget Lowest cost; slower Ollama (local) Qwen2, Llama2 $0 2-10s Privacy-critical Free; needs local GPU/CPU Gemini Gemini Pro $0.0005 &lt;2s Google ecosystem Billed per request Cohere Command R $0.0003 &lt;3s Specialized use Command models; moderate cost <p>Cost Tier Summary: - Tier A (Premium): Claude Opus, GPT-4 \u2192 $0.015-0.03/1K tokens (use for high-value tasks requiring best quality) - Tier B (Balanced): Claude Haiku, GPT-4 Mini, Qwen-72B \u2192 $0.0005-0.005/1K tokens (good middle ground) - Tier C (Budget): DeepSeek, Gemini, Cohere \u2192 $0.0001-0.0005/1K tokens (cheapest cloud options) - Tier D (Free): Ollama local \u2192 $0 (you pay for your computer hardware, but no API charges)</p>"},{"location":"Cost-Calculator-and-Optimization/#2-monthly-cost-calculator","title":"2. Monthly Cost Calculator","text":""},{"location":"Cost-Calculator-and-Optimization/#step-1-estimate-daily-token-usage","title":"Step 1: Estimate Daily Token Usage","text":"<p>Typical token consumption per interaction: (Remember: tokens \u2248 words. Complex tasks use more tokens.) - Simple query (web search): 500 tokens (\u2b07\ufe0f low complexity) - Moderate complexity (multi-step analysis): 2,000 tokens (\u2b07\ufe0f medium) - Complex task (long analysis + synthesis): 5,000 tokens (\u2b06\ufe0f high complexity)</p> <p>Example team: - 5 users \u00d7 10 interactions/day = 50 total interactions/day - Average 2,000 tokens per interaction = 100,000 tokens/day</p>"},{"location":"Cost-Calculator-and-Optimization/#step-2-calculate-monthly-cost","title":"Step 2: Calculate Monthly Cost","text":"<p>Formula: <pre><code>(Daily tokens \u00d7 30 days) \u00d7 (Cost per 1K tokens / 1000) = Monthly cost\n</code></pre></p> <p>Examples (100,000 tokens/day):</p> Provider Cost Per Month Annual OpenRouter (Qwen) $1.50 $18 DeepSeek $0.90 $11 Ollama (local GPU cost) ~$50 $600 OpenRouter (Claude Haiku) $15 $180 OpenAI (GPT-4o) $15 $180 Claude Opus $45 $540 <p>Interactive Calculator:</p> <pre><code># Paste into nanobot test mode or Python script\ntokens_per_day = 100000\ncost_per_1k = 0.0005  # DeepSeek: $0.0005/1K\nmonthly_cost = (tokens_per_day * 30 * cost_per_1k) / 1000\nprint(f\"Monthly cost at {cost_per_1k}/1K tokens: ${monthly_cost:.2f}\")\n# Output: Monthly cost: $1.50\n</code></pre>"},{"location":"Cost-Calculator-and-Optimization/#3-multi-provider-routing-optimize-spend","title":"3. Multi-Provider Routing (Optimize Spend)","text":"<p>Route different tasks to different tiers based on complexity and value.</p>"},{"location":"Cost-Calculator-and-Optimization/#strategy-hybrid-multi-tier-routing","title":"Strategy: Hybrid Multi-Tier Routing","text":"<p>Tier Logic: - Tier A (Claude Opus) \u2190 10% of tasks (complex analysis, creative work) - Tier B (Claude Haiku, Qwen) \u2190 60% of tasks (general chat, moderate reasoning) - Tier C (DeepSeek, Budget Models) \u2190 30% of tasks (summarization, classification, routine)</p>"},{"location":"Cost-Calculator-and-Optimization/#implementation-config-example","title":"Implementation: Config Example","text":"<pre><code>{\n  \"llm\": {\n    \"routing\": {\n      \"default\": \"tier_b\",\n      \"rules\": [\n        {\n          \"channel\": \"#vip-*\",\n          \"provider\": \"openrouter\",\n          \"model\": \"claude-opus\",\n          \"tier\": \"a\"\n        },\n        {\n          \"channel\": \"#research-*\",\n          \"provider\": \"openrouter\",\n          \"model\": \"qwen2:72b\",\n          \"tier\": \"b\"\n        },\n        {\n          \"channel\": \"#bk-*\",\n          \"provider\": \"openrouter\",\n          \"model\": \"deepseek-67b\",\n          \"tier\": \"c\"\n        },\n        {\n          \"keyword\": \"urgent\",\n          \"provider\": \"anthropic\",\n          \"model\": \"claude-opus\",\n          \"tier\": \"a\"\n        }\n      ]\n    }\n  }\n}\n</code></pre> <p>Result:  - VIP channels always get Claude Opus (best quality) - Research uses Qwen (good quality, cheaper) - Backlog use DeepSeek (budget tier, adequate quality) - Urgent keyword triggers Opus regardless of channel</p> <p>Estimated Cost Saving: 60-70% vs. using Claude Opus for everything</p>"},{"location":"Cost-Calculator-and-Optimization/#4-cost-per-workflow-examples","title":"4. Cost Per Workflow Examples","text":"<p>Real-world costs for common nanobot tasks:</p>"},{"location":"Cost-Calculator-and-Optimization/#example-1-daily-knowledge-consolidation","title":"Example 1: Daily Knowledge Consolidation","text":"<p>Workflow: Cron job nightly; collect Discord messages from #prd channel; summarize + write to Obsidian</p> <p>Tokens consumed: - Read 50 messages: 10,000 tokens - Summarization: 5,000 tokens - Write Obsidian: 500 tokens - Total: ~15,000 tokens/day</p> <p>Cost (using Tier C): <pre><code>15,000 tokens/day \u00d7 30 days \u00d7 $0.0005/1K = $0.225/month\n</code></pre></p> <p>ROI: ~1 person-hour saved daily = Worth $500+ in labor, cost $0.23 \ud83c\udfaf</p>"},{"location":"Cost-Calculator-and-Optimization/#example-2-multi-channel-content-posting","title":"Example 2: Multi-Channel Content Posting","text":"<p>Workflow: User requests article post to Discord, Slack, Telegram simultaneously</p> <p>Tokens consumed: - Generate content: 3,000 tokens - Format for channels: 1,500 tokens - Post &amp; confirm: 500 tokens - Total: ~5,000 tokens per post</p> <p>Cost (using Tier B): <pre><code>5,000 tokens \u00d7 $0.002/1K = $0.01 per post\n</code></pre></p> <p>ROI: Saves 15 mins manual cross-posting, cost $0.01 \ud83c\udfaf</p>"},{"location":"Cost-Calculator-and-Optimization/#example-3-github-automation-daily","title":"Example 3: GitHub Automation (Daily)","text":"<p>Workflow: Cron job to scan issues, summarize PRs, post status to Discord</p> <p>Tokens consumed: - Fetch &amp; parse 10 PRs: 8,000 tokens - Summarize each: 4,000 tokens - Generate status report: 3,000 tokens - Total: ~15,000 tokens/day</p> <p>Cost (using Tier C): <pre><code>15,000 tokens/day \u00d7 30 days \u00d7 $0.0005/1K = $0.225/month\n</code></pre></p> <p>ROI: Saves ~30 mins team review time daily, cost $0.225 \ud83c\udfaf</p>"},{"location":"Cost-Calculator-and-Optimization/#example-4-customer-support-bot-high-volume","title":"Example 4: Customer Support Bot (High Volume)","text":"<p>Workflow: 100 support questions/day across Discord, Slack, Telegram</p> <p>Tokens consumed per day: - Answer questions: 100 \u00d7 1,500 tokens = 150,000 tokens - Total: ~150,000 tokens/day</p> <p>Cost Options: - Tier B (Qwen): 150,000 \u00d7 30 \u00d7 0.0005/1K = **2.25/month** - Tier A (Claude): 150,000 \u00d7 30 \u00d7 0.002/1K = **9/month**</p> <p>ROI: Deflects 50+ support tickets/month = Worth $1,000+ in labor\ud83c\udfaf</p>"},{"location":"Cost-Calculator-and-Optimization/#5-budget-caps-token-limits","title":"5. Budget Caps &amp; Token Limits","text":""},{"location":"Cost-Calculator-and-Optimization/#set-monthly-budget-cap","title":"Set Monthly Budget Cap","text":"<p>Config example:</p> <pre><code>{\n  \"costs\": {\n    \"monthly_budget\": 100.00,\n    \"alert_at_percent\": [50, 75, 90, 100],\n    \"action_on_exceed\": \"queue_lower_tier\"\n  }\n}\n</code></pre> <p>Behavior: - At 50%: Log warning message - At 75%: Downgrade new requests to Tier C only - At 90%: Downgrade to Tier C, alert ops team - At 100%: All new requests \u2192 local Ollama (free)</p>"},{"location":"Cost-Calculator-and-Optimization/#per-team-budget-allocation","title":"Per-Team Budget Allocation","text":"<p>For multi-team deployments:</p> <pre><code>{\n  \"teams\": {\n    \"prd\": {\n      \"monthly_budget\": 50,\n      \"tier\": \"b\"\n    },\n    \"research\": {\n      \"monthly_budget\": 30,\n      \"tier\": \"a\"\n    },\n    \"support\": {\n      \"monthly_budget\": 20,\n      \"tier\": \"c\"\n    }\n  }\n}\n</code></pre> <p>Each team gets its own pool. When exhausted: - Auto-fallback to local Ollama (if available) - Or queue requests for next billing cycle</p>"},{"location":"Cost-Calculator-and-Optimization/#token-usage-tracking","title":"Token Usage Tracking","text":"<pre><code># View current month spend\nnanobot cost report --this-month\n# Output:\n# Feb 2026: 3,000,000 tokens / $4.50 (Qwen tier)\n# Budget remaining: $95.50 / 30% of quota\n\n# View by channel\nnanobot cost report --by-channel\n# Output:\n# #prd: 1,500,000 tokens / $2.25\n# #research: 1,000,000 tokens / $1.50\n# #support: 500,000 tokens / $0.75\n</code></pre>"},{"location":"Cost-Calculator-and-Optimization/#6-optimization-strategies","title":"6. Optimization Strategies","text":""},{"location":"Cost-Calculator-and-Optimization/#strategy-1-batch-processing-save-40","title":"Strategy 1: Batch Processing (Save 40%)","text":"<p>Instead of 50 real-time requests daily, batch into: - Morning batch (8am): 30 requests - Afternoon batch (2pm): 20 requests</p> <p>Token reduction: Fewer context switches = shorter responses Estimated savings: 30-40%</p>"},{"location":"Cost-Calculator-and-Optimization/#strategy-2-cache-repetitive-prompts-save-20","title":"Strategy 2: Cache Repetitive Prompts (Save 20%)","text":"<p>If 30% of tasks use the same system prompt:</p> <pre><code>{\n  \"cache\": {\n    \"strategy\": \"claude_prompt_cache\",\n    \"system_prompts\": [\n      {\n        \"name\": \"support_bot\",\n        \"prompt\": \"You are a customer support agent...\",\n        \"ttl_hours\": 24\n      }\n    ]\n  }\n}\n</code></pre> <p>Cost reduction: Cached tokens cost 90% less (Anthropic)</p>"},{"location":"Cost-Calculator-and-Optimization/#strategy-3-local-ollama-for-off-peak-save-70","title":"Strategy 3: Local Ollama for Off-Peak (Save 70%)","text":"<p>Run expensive tasks during off-peak hours on local GPU:</p> <pre><code>{\n  \"scheduling\": {\n    \"research_summaries\": {\n      \"time\": \"02:00\",\n      \"provider\": \"ollama\",\n      \"model\": \"qwen2:72b\"\n    }\n  }\n}\n</code></pre> <p>Cost reduction: Free compute hours + cloud API for urgent tasks</p>"},{"location":"Cost-Calculator-and-Optimization/#strategy-4-summarize-long-conversations-save-30","title":"Strategy 4: Summarize Long Conversations (Save 30%)","text":"<p>Instead of feeding full history to LLM:</p> <pre><code># Every 20 messages, auto-summarize conversation history\n# Insert summary instead of full history\n</code></pre> <p>Token reduction: 20-30% fewer tokens per interaction</p>"},{"location":"Cost-Calculator-and-Optimization/#7-break-even-analysis-cloud-vs-self-hosted","title":"7. Break-Even Analysis: Cloud vs. Self-Hosted","text":""},{"location":"Cost-Calculator-and-Optimization/#scenario-team-of-10-people-50-daily-interactions","title":"Scenario: Team of 10 people, 50 daily interactions","text":"<p>Cloud (OpenRouter Qwen) approach: <pre><code>100,000 tokens/day \u00d7 30 \u00d7 $0.0005/1K = $1.50/month\nTeam cost: $1.50 + ZenDesk/Slack = $500/month\n</code></pre></p> <p>Self-Hosted (VPS + Ollama) approach: <pre><code>VPS: $20/month (4GB RAM, CPU)\nGPU compute (rented): $200/month (NVIDIA A100 sharing)\nOllama updates: $0\nTotal: $220/month\n</code></pre></p> <p>Break-even: Self-hosted cheaper at &gt;150k tokens/day consistently</p> <p>Recommendation: - &lt;50k tokens/day: Cloud only (too cheap to self-host) - 50k-200k tokens/day: Hybrid (cloud + local batching) - &gt;200k tokens/day: Self-hosted (ROI in 2-3 months)</p>"},{"location":"Cost-Calculator-and-Optimization/#8-cost-monitoring-checklist","title":"8. Cost Monitoring Checklist","text":"<p>Monthly review:</p> <ul> <li> Total tokens consumed vs. budget</li> <li> Cost per channel (is any team over-using?)</li> <li> Average tokens per interaction (trending up/down?)</li> <li> Tier distribution (are we using Tier A too often?)</li> <li> Cache hit rate (prompt caching effectiveness)</li> <li> Ollama uptime (if self-hosted; justify continued use?)</li> </ul> <pre><code># Generate comprehensive monthly report\nnanobot cost-report --detailed --month=feb\n</code></pre>"},{"location":"Cost-Calculator-and-Optimization/#9-cost-reduction-checklist","title":"9. Cost Reduction Checklist","text":"<p>Quick wins (easy, 10-30% savings): - [ ] Enable prompt caching (Anthropic) - [ ] Switch to Qwen for routine tasks - [ ] Batch non-urgent summarization to 2am window - [ ] Add tier-based routing by channel</p> <p>Medium effort (30-50% savings): - [ ] Set up conversation summarization every 20 messages - [ ] Implement local Ollama for off-peak batch jobs - [ ] Review and reduce system prompt verbosity</p> <p>Major changes (50-70% savings): - [ ] Deploy self-hosted VPS + Ollama for high volume - [ ] Migrate to on-device models (less privacy tradeoff) - [ ] Implement aggressive batching (hourly vs. real-time)</p>"},{"location":"Cost-Calculator-and-Optimization/#10-example-annual-budget-forecast","title":"10. Example Annual Budget Forecast","text":"<p>10-person team, 100,000 tokens/day:</p> Approach Monthly Annual Notes Cloud Only (Qwen) $1.50 $18 Cheapest; accept minimal latency Cloud + Caching $1.20 $14 With Anthropic prompt cache Hybrid (Cloud+Local) $40 $480 VPS $20 + part-time GPU $20 Full Self-Hosted $220 $2,640 VPS $20 + GPU $200 <p>Sweet spot for most teams: Cloud (Tier C/B) + local batching = $20-40/month</p>"},{"location":"Cost-Calculator-and-Optimization/#revision-history","title":"Revision History","text":"Date Version Change 2026-02-25 1.0.0 Initial cost calculator and optimization guide"},{"location":"Emergency-Recovery-and-Troubleshooting/","title":"Emergency Recovery and Troubleshooting","text":"<p>Purpose: Diagnose and recover from system failures, connection loss, or configuration corruption without losing data or requiring full rebuild.</p>"},{"location":"Emergency-Recovery-and-Troubleshooting/#1-system-health-diagnostics","title":"1. System Health Diagnostics","text":"<p>Before attempting recovery, understand the current state.</p>"},{"location":"Emergency-Recovery-and-Troubleshooting/#11-quick-status-check","title":"1.1 Quick Status Check","text":"<pre><code># pgrep searches for running processes (programs) by its name\n# -l displays both the process ID and name\n# This shows if nanobot is currently running\npgrep -l nanobot\n\n# Check if nanobot is running and report health status\nnanobot status --all\n\n# List all connected nodes (if you're running distributed system)\nnanobot nodes list\n\n# tail shows the last lines of a log file (detailed record of what happened)\n# -50 shows the 50 most recent lines\ntail -50 /var/log/nanobot/gateway.log\n</code></pre>"},{"location":"Emergency-Recovery-and-Troubleshooting/#12-connectivity-diagnostic","title":"1.2 Connectivity Diagnostic","text":"<pre><code># Test if nanobot can reach each LLM provider\n# Each provider has its own server; this verifies the connection works\nnanobot test-provider --provider openrouter\nnanobot test-provider --provider ollama --host localhost:11434\n\n# Test if nanobot can send and receive messages from chat platforms\nnanobot test-channel --channel discord\nnanobot test-channel --channel slack\n\n# Verify that nanobot can read/write to your Obsidian vault\nnanobot test-vault --path /path/to/vault\n</code></pre>"},{"location":"Emergency-Recovery-and-Troubleshooting/#13-configuration-validation","title":"1.3 Configuration Validation","text":"<pre><code># Check if configuration file has correct syntax (YAML/JSON formatting)\nnanobot config validate\n\n# Check for settings that are no longer supported (old deprecated features)\nnanobot config audit\n\n# Display the current configuration so you can review it\n# --include-secrets=false means DON'T show passwords/API keys (for security)\nnanobot config show --include-secrets=false  # Never include secrets\n</code></pre>"},{"location":"Emergency-Recovery-and-Troubleshooting/#2-common-issues-quick-fixes","title":"2. Common Issues &amp; Quick Fixes","text":""},{"location":"Emergency-Recovery-and-Troubleshooting/#21-cannot-connect-to-llm-provider","title":"2.1 \"Cannot connect to LLM provider\"","text":"<p>Symptoms: - Responses timeout - \"Provider unreachable\" errors - No tokens being consumed</p> <p>Diagnosis: <pre><code># curl -I sends a HEAD request (just check headers, not full page)\n# https://api.openrouter.ai is the OpenRouter server address\n# This shows if you can reach the OpenRouter servers\ncurl -I https://api.openrouter.ai  # For OpenRouter\n\n# ping sends test packets to a server to check if it's reachable\n# For local Ollama running on your computer\nping &lt;ollama-host&gt;                  # For local Ollama\n</code></pre></p> <p>Fix Options:</p> <p>Option A: Verify credentials (most common) <pre><code># The 'echo' command prints text to the terminal\n# This shows the current value of the OPENROUTER_API_KEY variable\n# (This is your API key for the server\u2014like a password)\necho $OPENROUTER_API_KEY\n\n# If the key is empty, reload it from your .env file (configuration file with secrets)\n# 'source' tells bash to read and execute commands from a file\nsource ~/.nanobot/.env\nnanobot gateway restart\n</code></pre></p> <p>Option B: Check firewall (VPS \u2192 cloud provider) <pre><code># ufw (Uncomplicated Firewall) is a tool that blocks/allows network traffic\n# 'status' shows which ports are open and which are blocked\nsudo ufw status\n\n# 'allow out 443' opens port 443 for outgoing traffic (HTTPS = secure web connection)\n# Cloud providers use port 443\nsudo ufw allow out 443  # HTTPS for cloud providers\n\n# 'allow in 11434' opens port 11434 for incoming traffic (where Ollama listens)\n# For Ollama on local network\nsudo ufw allow in 11434\n</code></pre></p> <p>Option C: Reset provider routing <pre><code># Temporarily use fallback provider\nnanobot config set llm.provider fallback\n\n# Test with a simple prompt\n/model test \"Say hello\"\n\n# Once working, switch back to preferred provider\nnanobot config set llm.provider openrouter\n</code></pre></p>"},{"location":"Emergency-Recovery-and-Troubleshooting/#22-connection-refused-from-discordslack","title":"2.2 \"Connection refused\" from Discord/Slack","text":"<p>Symptoms: - Messages sent to bot are ignored - \"Unauthorized\" errors in channel logs - Gateway won't start</p> <p>Diagnosis: <pre><code># netstat -tlnp shows all network connections and which programs are using them\n# | grep nanobot filters the output to show only nanobot connections\n# This verifies if the nanobot gateway is actually listening for connections\nnetstat -tlnp | grep nanobot\n\n# List all connected channels and show if their authentication tokens are valid\nnanobot channel list --show-auth-status\n</code></pre></p> <p>Fix:</p> <p>Option A: Regenerate channel token <pre><code># For Discord\nnanobot channel discord reset-token\n# Copy new token to Discord application settings\n\n# For Slack\nnanobot channel slack regenerate-token\n# Update Slack app credentials\n</code></pre></p> <p>Option B: Re-authorize channel <pre><code># Deactivate channel\nnanobot channel discord disable\n\n# Re-authenticate\nnanobot channel discord oauth --redirect http://localhost:8080\n# Follow the browser prompt\n\n# Reactivate\nnanobot channel discord enable\n</code></pre></p>"},{"location":"Emergency-Recovery-and-Troubleshooting/#23-obsidian-vault-locked-file-permission-denied","title":"2.3 \"Obsidian vault locked / file permission denied\"","text":"<p>Symptoms: - Cannot write to vault - \"Permission denied\" on vault paths - Notes saved to temp instead of vault</p> <p>Diagnosis: <pre><code># ls -la lists files in a directory with detailed information\n# Shows file sizes, dates, and most importantly: who owns it and what permissions exist\nls -la /path/to/obsidian/vault\n\n# stat shows detailed information about a file (permissions, ownership, timestamps)\n# This checks if nanobot process owner matches the vault owner\nstat /path/to/obsidian/vault\n</code></pre></p> <p>Fix:</p> <p>Option A: Fix permissions <pre><code># chmod changes permissions on files and folders\n# 755 = owner can read/write/execute, others can read/execute but not write\n# This allows nanobot (the process) to read and write to the vault\nchmod 755 /path/to/obsidian/vault\nchmod 644 /path/to/obsidian/vault/*.md\n\n# Alternatively: chown changes who owns the file/folder\n# sudo = run as administrator\n# nanobot:nanobot = set ownership to the nanobot user and nanobot group\n# -R = apply recursively to all files inside\nsudo chown -R nanobot:nanobot /path/to/obsidian/vault\n</code></pre></p> <p>Option B: Temporarily disable vault auto-save <pre><code>nanobot config set obsidian.auto_save false\n\n# Manually trigger saves when ready\nnanobot vault flush\n</code></pre></p> <p>Option C: Recover from backup <pre><code># If vault is corrupted, restore from backup\ncp -r /backup/obsidian/vault /path/to/obsidian/vault\n\n# Recrawl vault index\nnanobot vault reindex\n</code></pre></p>"},{"location":"Emergency-Recovery-and-Troubleshooting/#24-out-of-memory-vram-full-local-ollama","title":"2.4 \"Out of memory\" / VRAM full (local Ollama)","text":"<p>Symptoms: - Model unloads repeatedly - Slow responses - GPU errors in logs</p> <p>Diagnosis: <pre><code># nvidia-smi is a tool from NVIDIA that shows GPU memory usage\n# This tells you how much VRAM (video memory) is being used\nnvidia-smi\n\n# 'watch' reruns a command every 2 seconds so you can see changes in real-time\n# Ctrl+C to stop watching\nwatch nvidia-smi  # Ctrl+C to exit\n\n# Show memory settings for a specific model (Ollama= local AI tool)\nollama show llama2\n</code></pre></p> <p>Fix:</p> <p>Option A: Unload unused models <pre><code># List all AI models that are currently loaded in memory\nollama list\n\n# Free up VRAM by unloading all models\n# This clears out the GPU memory so nanobot can start fresh\nollama pull --unload-all\n\n# Load only the one model you need right now\nollama run mistral\n</code></pre></p> <p>Option B: Switch to smaller model (temporary) <pre><code># Switch from 70B to 8B to free VRAM\n/model set llama3:8b\n\n# Verify it's loaded\nnanobot model status\n\n# User can still access 70B with explicit request\n# /model force llama3:70b  (when more context needed)\n</code></pre></p> <p>Option C: Configure auto-unload <pre><code># Set timeout to auto-unload models when idle\nnanobot config set ollama.keep_alive 10m  # 10 minutes of idle time\n\n# Or disable auto-unload for intensive work\nnanobot config set ollama.keep_alive 0  # Never auto-unload\n</code></pre></p>"},{"location":"Emergency-Recovery-and-Troubleshooting/#3-recovery-procedures-multi-step","title":"3. Recovery Procedures (Multi-Step)","text":""},{"location":"Emergency-Recovery-and-Troubleshooting/#31-clean-restart-preserves-configuration","title":"3.1 Clean Restart (Preserves Configuration)","text":"<p>Use this when services are stuck or deadlocked.</p> <pre><code># Step 1: Graceful shutdown - tell nanobot to stop nicely\nnanobot gateway stop\nsleep 5  # sleep waits 5 seconds to ensure everything stops\n\n# Step 2: Verify all processes stopped\n# pgrep searches for running processes; || echo means \"if nothing found, print a message\"\npgrep -l nanobot || echo \"All nanobot processes stopped\"\n\n# Step 3: Clean temporary files\n# rm -rf removes files and directories; /tmp/nanobot_* targets temp files\n# ~/.nanobot/cache/* clears the cache (stored temporary data)\nrm -rf /tmp/nanobot_*\nrm -rf ~/.nanobot/cache/*\n\n# Step 4: Restart with diagnostic mode (verbose = show detailed logging)\nnanobot gateway run --verbose\n\n# Step 5: Test basic functionality\n# In another terminal:\nnanobot test-provider --provider openrouter\n</code></pre>"},{"location":"Emergency-Recovery-and-Troubleshooting/#32-configuration-corruption-recovery","title":"3.2 Configuration Corruption Recovery","text":"<p>Use this if <code>~/.nanobot/config.json</code> is invalid or corrupted.</p> <pre><code># Step 1: Backup corrupted config (cp = copy)\ncp ~/.nanobot/config.json ~/.nanobot/config.json.corrupt\n\n# Step 2: Restore from last known good (if available)\ncp ~/.nanobot/config.json.backup ~/.nanobot/config.json\n\n# Step 3: Validate restored config (check syntax)\nnanobot config validate\n\n# Step 4: Compare with corrupted version to check what was lost\n# diff shows differences between two files; -u shows context\ndiff -u ~/.nanobot/config.json.corrupt ~/.nanobot/config.json\n\n# Step 5: Re-apply any missing custom settings\n# (Edit manually or use CLI)\nnanobot config set llm.provider openrouter\nnanobot config set channels.discord.enabled true\n\n# Step 6: Restart and verify\nnanobot gateway restart\nnanobot status --all\n</code></pre>"},{"location":"Emergency-Recovery-and-Troubleshooting/#33-credential-reset-after-compromise-or-expiration","title":"3.3 Credential Reset (After Compromise or Expiration)","text":"<p>Use this if you suspect tokens/keys are compromised or tokens expired.</p> <pre><code># Step 1: Revoke old credentials from provider\n# For OpenRouter: Log in \u2192 API Settings \u2192 Delete old keys\n# For Anthropic: Console \u2192 Dashboard \u2192 Revoke key\n# For Discord: Server Settings \u2192 Integrations \u2192 OAuth2 \u2192 Reset\n\n# Step 2: Generate new credentials at provider\n\n# Step 3: Update .env file\nnano ~/.nanobot/.env\n# Update: OPENROUTER_API_KEY=&lt;new_key&gt;\n# Or: ANTHROPIC_API_KEY=&lt;new_key&gt;\n\n# Step 4: Reload environment\nsource ~/.nanobot/.env\n\n# Step 5: Test new credentials\nnanobot test-provider --provider openrouter\n\n# Step 6: Restart gateway to apply\nnanobot gateway restart\n\n# Step 7: Verify in channel\n# Send test message in Discord/Slack to confirm working\n</code></pre>"},{"location":"Emergency-Recovery-and-Troubleshooting/#34-vault-corruption-recovery","title":"3.4 Vault Corruption Recovery","text":"<p>Use this if notes are corrupted, links broken, or vault index outdated.</p> <pre><code># Step 1: Backup current vault\n# tar -czf creates a compressed backup file (.tar.gz = compressed archive)\n# $(date +%Y%m%d_%H%M%S) adds timestamp like 20240115_143022\ntar -czf ~/obsidian-backup-$(date +%Y%m%d_%H%M%S).tar.gz /path/to/vault\n\n# Step 2: Check vault integrity (scan for errors)\nnanobot vault check --full\n\n# Step 3: Reindex vault (rebuild the searchable index)\nnanobot vault reindex\n\n# Step 4: Verify recovery (test a search)\nnanobot vault search --test \"example query\"\n\n# Step 5: If still broken, restore from backup\n# Extract to temp directory first, don't overwrite immediately\nmkdir /tmp/vault-restore\n# tar -xzf extracts; -C specifies destination folder\ntar -xzf ~/obsidian-backup-&lt;date&gt;.tar.gz -C /tmp/vault-restore\n\n# Once verified, move to production\n# rm -rf removes a directory and all its contents\nrm -rf /path/to/vault\nmv /tmp/vault-restore/vault /path/to/vault\n\n# Step 6: Reindex restored vault\nnanobot vault reindex\n</code></pre>"},{"location":"Emergency-Recovery-and-Troubleshooting/#4-data-integrity-checks","title":"4. Data Integrity Checks","text":""},{"location":"Emergency-Recovery-and-Troubleshooting/#41-verify-recent-exports-backup-validation","title":"4.1 Verify Recent Exports (Backup Validation)","text":"<pre><code># Check when was the last successful backup\n# ls -lah lists files with human-readable sizes and hidden files\n# ~/ means your home directory\nls -lah ~/.nanobot/backups/\n\n# Validate backup integrity (don't extract, just list contents)\n# tar -tzf lists files inside a compressed archive without extracting\n# | head -20 shows only the first 20 files\ntar -tzf ~/.nanobot/backups/backup-latest.tar.gz | head -20\n\n# Test restore to temp location\nmkdir /tmp/backup-test\ntar -xzf ~/.nanobot/backups/backup-latest.tar.gz -C /tmp/backup-test\n\n# Verify key files exist\n# test -f checks if a file exists; test -d checks if a directory exists\n# &amp;&amp; echo prints success message if the test passes\ntest -f /tmp/backup-test/config.json &amp;&amp; echo \"Config backed up \u2713\"\ntest -d /tmp/backup-test/vault &amp;&amp; echo \"Vault backed up \u2713\"\ntest -d /tmp/backup-test/logs &amp;&amp; echo \"Logs backed up \u2713\"\n</code></pre>"},{"location":"Emergency-Recovery-and-Troubleshooting/#42-audit-log-verification","title":"4.2 Audit Log Verification","text":"<pre><code># Check if audit logs exist and recent\n# ls -lah shows file size and modification date (tells you if logs are current)\nls -lah ~/.nanobot/logs/audit.log\n\n# Verify recent entries\n# tail -30 shows the last 30 lines\n# grep -i searches for text (case-insensitive)\n# This filters for errors or warnings\ntail -30 ~/.nanobot/logs/audit.log | grep -i \"error\\|warning\"\n\n# Count errors in last 24h\n# date -d yesterday shows yesterday's date\n# wc -l counts lines\ngrep \"$(date -d yesterday +%Y-%m-%d)\" ~/.nanobot/logs/audit.log | grep -i error | wc -l\n\n# Export logs for external review (backup to a compressed archive)\ntar -czf ~/nanobot-logs-$(date +%Y%m%d).tar.gz ~/.nanobot/logs/\n</code></pre>"},{"location":"Emergency-Recovery-and-Troubleshooting/#5-troubleshooting-quick-reference","title":"5. Troubleshooting Quick Reference","text":"Symptom Likely Cause First Check Quick Fix No responses Provider offline or bad token <code>nanobot test-provider</code> Update token or switch provider Slow responses Out of memory or network latency <code>nvidia-smi</code> / <code>ping provider</code> Unload models or check network Bot unresponsive Gateway crashed <code>pgrep nanobot</code> <code>nanobot gateway restart</code> Obsidian errors Vault locked or permission denied <code>ls -la /vault/path</code> Fix permissions or disable auto-save High costs Expensive model routing <code>nanobot cost status</code> Switch to cheaper model tier Channel disconnected Auth token expired <code>nanobot channel list</code> Regenerate token Configuration lost File corrupted or deleted Check <code>.backup</code> suffixed files Restore from backup"},{"location":"Emergency-Recovery-and-Troubleshooting/#6-emergency-contact-list-template","title":"6. Emergency Contact List (Template)","text":"<p>Keep this updated with your actual contacts:</p> <pre><code># Emergency Contacts\n\n**Primary Provider Support:**\n- OpenRouter: support@openrouter.ai\n- Anthropic: help@anthropic.com\n- OpenAI: support@openai.com\n\n**Cloud Provider (if using VPS):**\n- Provider: [Your VPS Provider]\n- Support: [Support URL]\n- Account: [Your Account ID]\n\n**Internal Support:**\n- Primary Operator: [Your Name/Email]\n- Backup Operator: [Backup Person/Email]\n- On-Call: [Rotation Schedule]\n\n**Monitoring/Alerts:**\n- Critical Alert Channel: [Discord/Slack]\n- Email: [Your Alert Email]\n</code></pre>"},{"location":"Emergency-Recovery-and-Troubleshooting/#7-preventive-maintenance","title":"7. Preventive Maintenance","text":""},{"location":"Emergency-Recovery-and-Troubleshooting/#71-daily-checks","title":"7.1 Daily Checks","text":"<pre><code>#!/bin/bash\n# Save as ~/.nanobot/daily-check.sh\n\n# Check service health\nnanobot status --all\n\n# Monitor costs\nnanobot cost today\n\n# Verify connections\nnanobot test-provider --provider openrouter\nnanobot test-channel --channel discord\n\n# Show recent errors\ntail -20 /var/log/nanobot/gateway.log | grep -i error\n</code></pre>"},{"location":"Emergency-Recovery-and-Troubleshooting/#72-weekly-backup","title":"7.2 Weekly Backup","text":"<pre><code>#!/bin/bash\n# Run weekly: crontab -e \u2192 add: 0 0 * * 0 ~/.nanobot/weekly-backup.sh\n\nBACKUP_DIR=~/.nanobot/backups\nDATE=$(date +%Y%m%d)\n\n# Backup configuration\ntar -czf $BACKUP_DIR/config-$DATE.tar.gz ~/.nanobot/config.json\n\n# Backup vault\ntar -czf $BACKUP_DIR/vault-$DATE.tar.gz /path/to/obsidian/vault\n\n# Keep only last 4 weeks\nfind $BACKUP_DIR -name \"*.tar.gz\" -mtime +28 -delete\n\necho \"Backups completed: $(ls -1 $BACKUP_DIR | wc -l) files\"\n</code></pre>"},{"location":"Emergency-Recovery-and-Troubleshooting/#73-monthly-security-audit","title":"7.3 Monthly Security Audit","text":"<pre><code># Run monthly security checks\nnanobot security audit --full\n\n# Validate allowlists\nnanobot config show allowlist\n\n# Review recent API usage\nnanobot logs export --format json --days 30 &gt; api-usage-$(date +%Y%m).json\n\n# Update channel tokens if not rotated in 90 days\ngrep -r \"token_created\" ~/.nanobot/ | grep -v \"$(date -d '3 months ago' +%Y-%m)\"\n</code></pre>"},{"location":"Emergency-Recovery-and-Troubleshooting/#8-see-also","title":"8. See Also","text":"<ul> <li>Security Validation Runbook \u2014 Monthly security procedures</li> <li>Governance Policies \u2014 Access control and escalation</li> <li>AOS Startup Procedure \u2014 Initial setup and boot sequence</li> <li>Cost Calculator \u2014 Monitor spend to detect anomalies</li> </ul>"},{"location":"Essential-AOS-Skills/","title":"Essential AOS Skills","text":"<p>This document lists the 5 core skills (pre-built bundles) recommended for every Nanobot Agentic Operating System deployment. For complete reference including all 9 pre-built skills, 14 tools, and custom skill creation, see Tools &amp; Skills Reference.</p> <p>Plain-English Note: A skill is a pre-built bundle of tools configured for a specific business workflow. Think of skills as \"ready-to-use packages\" \u2014 install these five first, then add others as needed.</p>"},{"location":"Essential-AOS-Skills/#document-control","title":"Document Control","text":"<ul> <li>Owner:</li> <li>Version: 2.0.0</li> <li>Last Updated: 2026-02-25</li> <li>Status: Active</li> </ul>"},{"location":"Essential-AOS-Skills/#1-the-5-essential-skills","title":"1. The 5 Essential Skills","text":""},{"location":"Essential-AOS-Skills/#1-obsidian","title":"1. obsidian","text":"<p>Purpose: Read, write, and query Obsidian vault from nanobot Why Essential: Core memory plane; all AOS artifacts stored here for audit and recovery Install: Built-in or <code>nanobot skill add obsidian</code> Config: <pre><code>{\n  \"obsidianVaultPath\": \"~/Documents/ObsidianVault\",\n  \"obsidianRestEndpoint\": \"http://localhost:18790\",\n  \"obsidianRestToken\": \"token...\"\n}\n</code></pre></p>"},{"location":"Essential-AOS-Skills/#obsidian-local-rest-api-setup-required","title":"Obsidian Local REST API Setup (Required)","text":"<p>To enable nanobot \u2194 Obsidian communication, set up the Local REST API plugin. (REST API = a way for programs to talk to each other. This lets nanobot read and write to Obsidian.)</p> <p>Step 1: Enable Community Plugins 1. Open Obsidian \u2192 Settings \u2192 Community Plugins 2. Toggle Turn on community plugins (if not already on) 3. Search for \"Local REST API\" by Coremute 4. Click Install</p> <p>Step 2: Configure REST API 1. Go to Settings \u2192 Local REST API 2. Enable the plugin 3. Note the Ribbon Icon appears in left sidebar (scroll down to see it) 4. Click the icon to see your API details:    - Listening on: http://localhost:27123 (or another port)    - API Token: (long hex string)</p> <p>Step 3: Get Your Token 1. Click the REST API ribbon icon 2. Copy the access token shown</p> <p>Step 4: Update Nanobot Config <pre><code>{\n  \"obsidian\": {\n    \"vaultPath\": \"/Users/your-username/Documents/MyVault\",\n    \"restEndpoint\": \"http://localhost:27123\",\n    \"restToken\": \"&lt;paste-token-here&gt;\"\n  }\n}\n</code></pre></p> <p>Step 5: Test Connection <pre><code># In nanobot terminal, verify Obsidian is reachable\nnanobot test-vault --path /Users/your-username/Documents/MyVault\n\n# Should return: \u2705 Vault accessible\n</code></pre></p> <p>Step 6: Verify with a Simple Command <pre><code>User: \"@BotName read the file Getting-Started.md\"\n</code></pre></p> <p>If successful, the bot returns the file contents. If it fails: - Check Obsidian is running - Confirm REST API plugin is enabled - Verify vault path and token in config - Check firewall isn't blocking localhost:27123</p>"},{"location":"Essential-AOS-Skills/#storage-permissions","title":"Storage &amp; Permissions","text":"<p>Vault Location Best Practices: - Local machine: SSD for speed (e.g., <code>~/Documents/MyVault</code>) - NOT in OneDrive/Dropbox initially \u2014 File-locking can conflict with REST API - Network share: Only if using NFS / SMB (not recommended for reliability)</p> <p>File Permissions: <pre><code># Ensure nanobot process can read/write\nchmod 755 ~/Documents/MyVault\nchmod 644 ~/Documents/MyVault/*.md\n</code></pre></p> <p>Usage Examples: - <code>\"Read the Q1 roadmap from Strategy.md\"</code> - <code>\"Write a research summary to 08-Research/AI-Safety/findings.md\"</code> - <code>\"Query all notes tagged #decision\"</code></p>"},{"location":"Essential-AOS-Skills/#2-memory","title":"2. memory","text":"<p>Purpose: Automatic session management, memory consolidation, context optimization Why Essential: Enables long conversations without token explosion; automatic history summarization Install: Built-in Config: <pre><code>{\n  \"session\": {\n    \"memoryWindow\": 100,\n    \"maxSessionTokens\": 32000,\n    \"consolidationInterval\": 10\n  }\n}\n</code></pre> Automatic \u2014 No user interaction needed; agent manages conversation memory transparently.</p>"},{"location":"Essential-AOS-Skills/#3-cron","title":"3. cron","text":"<p>Purpose: Schedule tasks to run on recurring schedules Why Essential: Enables proactive, always-on operations (daily journal, health checks, backups) Install: <code>nanobot skill add cron</code> Examples: - <code>\"Schedule a health check every hour\"</code> - <code>\"Run daily journal summarizer at 23:50 every day\"</code> - <code>\"Backup workspace every Sunday at 2 AM\"</code></p>"},{"location":"Essential-AOS-Skills/#4-summarize","title":"4. summarize","text":"<p>Purpose: Condense long content while preserving key information Why Essential: Reduces token burn, improves clarity for reports and digests Install: Built-in Usage Examples: - <code>\"Summarize this 50-page PDF to 1 page\"</code> - <code>\"Create a 3-sentence summary of today's Discord activity\"</code> - <code>\"Condense research findings into key insights + citations\"</code></p>"},{"location":"Essential-AOS-Skills/#5-github","title":"5. github","text":"<p>Purpose: GitHub automation (search repos, create PRs, trigger workflows) Why Essential: Enables GitOps automation from chat; CI/CD triggers from Discord/Slack Install: Built-in; requires token Config: <pre><code>{\n  \"github\": {\n    \"token\": \"github_pat_...\",\n    \"defaultOrg\": \"your-org\",\n    \"allowFrom\": [\"OPERATOR_USER_ID\"]\n  }\n}\n</code></pre> Usage Examples: - <code>\"Search our backend repo for TypeScript errors\"</code> - <code>\"Create a PR to update dependencies in main branch\"</code> - <code>\"Trigger the 'deploy' workflow\"</code></p>"},{"location":"Essential-AOS-Skills/#2-installation-checklist","title":"2. Installation Checklist","text":"<ul> <li> obsidian - Configured with vault path and REST endpoint</li> <li> memory - Session consolidation enabled (default)</li> <li> cron - Installed and tested with one schedule</li> <li> summarize - Tested with a long document</li> <li> github - Token configured and tested with one search</li> </ul>"},{"location":"Essential-AOS-Skills/#3-daily-journal-example-using-cron-obsidian-summarize","title":"3. Daily Journal Example (Using cron + obsidian + summarize)","text":"<p>Combine three essential skills to automate daily operational journaling:</p> <p>Step 1: Set up Archivist personality</p> <p>Add to <code>config.json</code> or <code>~/.nanobot/agents/primary/SOUL.md</code>:</p> <pre><code># AOS Archivist Identity\n\nEvery night at 23:50, run this routine:\n\n1. **Analyze Discord history** from #aos-control and #general channels\n2. **Extract key metadata:** milestones, technical hurdles, model performance notes\n3. **Format for Obsidian** using structured template\n4. **Write to vault** at 00-System/AOS-Journal/{{date}}.md\n5. **Include metadata:** \n   - Model used today\n   - Context efficiency notes\n   - 3-sentence summary\n\n**Template:**\n# AOS Operational Journal: {{date}}\n\n## \ud83d\udee0 Technical Milestones\n* [List of tasks completed]\n\n## \ud83e\udde0 Model Context &amp; Performance\n* Model Used: {{primary_model}}\n* Context Efficiency: [Memory retention rating]\n\n## \ud83d\udcdd Summary\n[3-sentence summary of the day]\n</code></pre> <p>Step 2: Schedule the routine</p> <pre><code>User: \"@BotName schedule a task: Run the Archivist routine every day at 23:50\"\n</code></pre> <p>Step 3: Test manually</p> <pre><code>User: \"@BotName force-run Archivist routine for today\"\n</code></pre> <p>Expected: Bot replies with success, entry appears in Obsidian vault.</p>"},{"location":"Essential-AOS-Skills/#4-security-best-practices","title":"4. Security Best Practices","text":"<p>Tool Allowlisting: <pre><code>{\n  \"channels\": {\n    \"discord\": {\n      \"allowedTools\": {\n        \"#ctl-nanobot\": [\"shell\", \"mcp\", \"github\"],\n        \"#prd-*\": [\"web\", \"file\", \"message\"],\n        \"#bk-*\": [\"file\", \"message\", \"obsidian\"],\n        \"#res-*\": [\"web\", \"message\", \"obsidian\"],\n        \"default\": [\"web\", \"file\", \"message\"]\n      }\n    }\n  }\n}\n</code></pre></p> <p>Secret Management: - Never commit <code>.env</code> or config files with tokens - Store API keys in environment variables: <code>export GITHUB_TOKEN=...</code> - Use allowlists to restrict who can invoke sensitive skills</p>"},{"location":"Essential-AOS-Skills/#5-complete-skill-catalog","title":"5. Complete Skill Catalog","text":"<p>This document covers the 5 essential skills. Four more are available: - weather - Weather data retrieval - clawhub - Skill marketplace integration - skill-creator - Auto-generate skills from natural language - tmux - Terminal multiplexer control</p> <p>See Tools &amp; Skills Reference for: - All 14 built-in tools (web_search, file_*, shell, mcp, subagent_spawn, etc.) - All 9 pre-built skills with full examples - Cost/performance matrix - Creating custom tools and skills - Tool allowlisting patterns</p>"},{"location":"Essential-AOS-Skills/#6-troubleshooting","title":"6. Troubleshooting","text":"Issue Fix Skill not found Confirm installed: <code>nanobot skill list</code> Obsidian write fails Verify vault path and REST endpoint in config Cron task not running Check time format (24-hour) and time zone GitHub auth fails Verify token format and repo permissions"},{"location":"Essential-AOS-Skills/#7-revision-history","title":"7. Revision History","text":"Date Version Change 2026-02-25 2.0.0 Major simplification: 5 essential skills only; removed outdated references; added cross-references to comprehensive Tools &amp; Skills Reference; updated config examples and daily journal walkthrough Previous 1.x Outdated skill inventory and setup instructions"},{"location":"Glossary/","title":"Glossary of Terms","text":"<p>Quick reference for technical terms, acronyms, and concepts used throughout the Nanobot documentation.</p>"},{"location":"Glossary/#a","title":"A","text":"<p>Agent Orchestration - Splitting large tasks into smaller, specialized agents that work in parallel. Example: one agent researches competitors while another agent verifies the findings.</p> <p>Allowlist - A list of specific users, channels, or tools that are explicitly approved to use sensitive features. Only items on the allowlist are allowed; everything else is blocked.</p> <p>API (Application Programming Interface) - A way for different programs to talk to each other. Think of it as a standardized menu that one program offers, so other programs know exactly what requests to make.</p> <p>Artifacts - Files, notes, or records that the system creates and saves for later reference. In nanobot, artifacts are stored in Obsidian for audit trails and recovery.</p> <p>Auth / Authentication - Proving who you are. Usually done with a password or API key.</p>"},{"location":"Glossary/#b","title":"B","text":"<p>Bot - Short for robot. In this context, nanobot is a software bot that listens to messages and responds automatically.</p> <p>Bash - A common command-line language used on Linux, Mac, and Windows (via WSL or Git Bash). We use it for installation and troubleshooting commands.</p>"},{"location":"Glossary/#c","title":"C","text":"<p>Channel - A conversation space. Examples: Discord channel, Slack channel, Telegram group. Nanobot can listen to multiple channels at once.</p> <p>Channel-Agnostic - Works the same way no matter which chat platform you use (Discord, Slack, Telegram, etc.). You don't need different rules for each platform.</p> <p>CLI (Command-Line Interface) - A way to interact with a computer by typing commands instead of clicking buttons. All our installation and troubleshooting uses the CLI.</p> <p>Cron - A tool that runs tasks on a schedule (e.g., \"every day at 9 AM\"). Named after the Roman god of time.</p> <p>Config / Configuration - The settings file that tells nanobot how to behave (which channels to listen to, which LLM to use, etc.).</p> <p>Cost Ceiling - A hard limit on how much money the system will spend. Once the limit is reached, no more requests are processed until the budget resets.</p>"},{"location":"Glossary/#d","title":"D","text":"<p>Deprecated - Old technology that still works but is being phased out. Using deprecated features is not recommended.</p> <p>Dashboard - A display that shows the current status of your system (e.g., \"How many tasks completed today?\" or \"What's the CPU usage?\").</p> <p>Delegation - Asking someone (or something) else to do a task for you. Sub-agents delegate work to other agents.</p>"},{"location":"Glossary/#e","title":"E","text":"<p>Escalation - Sending a decision \"up the chain\" because it needs human approval. Example: a high-cost operation gets escalated to a finance team member.</p> <p>Executor - Something that runs commands. The nanobot executor handles web searches, file operations, shell commands, etc.</p>"},{"location":"Glossary/#f","title":"F","text":"<p>Fallback - A backup plan. If your first choice fails, the fallback is automatically used instead.</p> <p>Firewall - A security tool that controls which network traffic is allowed in and out of a computer.</p> <p>---## G</p> <p>Gateway - The main entry point for nanobot. It listens for incoming messages and routes them to the right handler.</p> <p>Governance - The rules and policies that control how nanobot operates (who can use what, approval workflows, cost limits, etc.).</p>"},{"location":"Glossary/#h","title":"H","text":"<p>Heartbeat - A periodic check to make sure the system is still alive and healthy. Like taking a pulse.</p> <p>Hot-Reload - Updating code or configuration without needing to restart the system. Changes take effect immediately.</p> <p>HTTPS - A secure version of HTTP (the protocol used to transfer web pages). The \"S\" stands for Secure.</p>"},{"location":"Glossary/#i","title":"I","text":"<p>Inference - When an AI model processes text and generates a response. \"Running inference\" means asking the AI a question.</p> <p>Injection - Adding code to the system dynamically (without restarting). You can \"inject\" a new skill via Discord.</p> <p>Integration - Connecting two systems so they can work together. Discord integration means nanobot can listen to Discord.</p>"},{"location":"Glossary/#j","title":"J","text":"<p>JSON (JavaScript Object Notation) - A standardized format for storing and sharing data. Looks like: <pre><code>{\n  \"name\": \"Alice\",\n  \"age\": 30\n}\n</code></pre></p>"},{"location":"Glossary/#k","title":"K","text":"<p>KPI (Key Performance Indicator) - A measurable way to track if something is working well. Examples: \"cost per successful task\" or \"errors per day.\"</p>"},{"location":"Glossary/#l","title":"L","text":"<p>LLM (Large Language Model) - A powerful AI trained on lots of text. Examples: Claude, GPT-4, Qwen. Nanobot uses LLMs to understand questions and generate responses.</p> <p>Log / Logging - Recording what happens in a system so you can review it later. Nanobot logs all requests for security and debugging.</p>"},{"location":"Glossary/#m","title":"M","text":"<p>MCP (Model Context Protocol) - A standard way to connect AI models to external tools (databases, file systems, APIs). Think of it as a universal connector.</p> <p>Memory Consolidation - Summarizing old conversations automatically, so the system doesn't get bogged down with endless history.</p> <p>Memory Plane - The part of nanobot that stores information for later use. Obsidian is the memory store.</p> <p>Middleware - Software that sits in the middle of two other systems and helps them communicate.</p> <p>Model Routing - Deciding which AI model to use for each task. \"Route this to Claude because it's complex\" or \"Route this to a cheap model because it's simple.\"</p>"},{"location":"Glossary/#n","title":"N","text":"<p>Node - A single computer in a network. A \"VPS node\" is a virtual computer in the cloud.</p> <p>Notification - A message sent to alert someone about something important.</p>"},{"location":"Glossary/#o","title":"O","text":"<p>OAuth - A secure way to log in with your existing account (e.g., \"Sign in with Discord\").</p> <p>Obsidian - A note-taking app used by nanobot to store memory, audit trails, and artifacts. It runs on your computer.</p> <p>Orchestration - Coordinating multiple agents or tasks to work together smoothly.</p> <p>Operator - A human user who controls nanobot. You're the operator.</p>"},{"location":"Glossary/#p","title":"P","text":"<p>Payload - The data being sent or received. E.g., the message content is the payload.</p> <p>Permission - The right to do something. \"Shell execute permission\" means you're allowed to run shell commands.</p> <p>Plane - A layer of the system. Nanobot has three planes: Control (channels), Policy (routing), Memory (Obsidian).</p> <p>Policy - A rule about how something should work. \"Require approval for costs over $50\" is a policy.</p> <p>Policy Plane - The part of nanobot that makes decisions about which model to use, when to escalate, cost limits, etc.</p> <p>PR (Pull Request) - A way to propose changes to code on GitHub. \"Create a PR\" means suggest a code change.</p>"},{"location":"Glossary/#q","title":"Q","text":"<p>Query - A question or search request.</p>"},{"location":"Glossary/#r","title":"R","text":"<p>RBAC (Role-Based Access Control) - A security system where people have roles (operator, reviewer, owner), and each role has different permissions.</p> <p>REST API - A standard way to request information from a program over the internet. Obsidian has a REST API so nanobot can read and write notes.</p> <p>Revert - Go back to a previous state. \"Revert this file\" means restore an old version.</p> <p>Recovery - Restoring a system after an error or crash. We have recovery procedures in the Emergency guide.</p>"},{"location":"Glossary/#s","title":"S","text":"<p>Sandbox - An isolated environment where untrusted code can run safely without affecting the rest of the system.</p> <p>Session - A conversation or work period. Each user gets their own session so conversations don't mix.</p> <p>Skill - A pre-built bundle of tools configured for a specific task. Example: the \"Obsidian\" skill reads/writes notes.</p> <p>SSH (Secure Shell) - A secure way to connect to and control a remote computer from your computer.</p> <p>Sub-Agent - An independent agent spawned to handle a specific part of a task.</p>"},{"location":"Glossary/#t","title":"T","text":"<p>Tailscale - A tool that creates a secure, private network between computers (even across the internet), so they can communicate safely.</p> <p>Token - A temporary code that proves you're authorized. \"API token\" proves you have permission to use an API.</p> <p>Tool - An action nanobot can perform. Examples: web search, file read, shell execute.</p> <p>Troubleshoot - Figure out what's wrong and fix it.</p>"},{"location":"Glossary/#u","title":"U","text":"<p>UFW (Uncomplicated Firewall) - A firewall used on Linux systems to control network traffic.</p> <p>Uptime - How long the system has been running without interruption. \"99% uptime\" means it's down for only 1% of the time.</p>"},{"location":"Glossary/#v","title":"V","text":"<p>Vault (Obsidian) - The folder where Obsidian stores all your notes.</p> <p>VPS (Virtual Private Server) - A rented computer in the cloud that you can control and customize.</p>"},{"location":"Glossary/#w","title":"W","text":"<p>Webhook - A way for one system to automatically send data to another system when something happens. Example: \"When a PR is created, send a message to Discord.\"</p> <p>Workspace - The folder where nanobot stores its files and configuration.</p>"},{"location":"Glossary/#x","title":"X","text":"<p>(Currently empty)</p>"},{"location":"Glossary/#y","title":"Y","text":"<p>(Currently empty)</p>"},{"location":"Glossary/#z","title":"Z","text":"<p>(Currently empty)</p>"},{"location":"Glossary/#common-acronyms-quick-reference","title":"Common Acronyms Quick Reference","text":"Acronym Meaning Used For API Application Programming Interface Connecting systems CLI Command-Line Interface Typing commands HTTP/HTTPS HyperText Transfer Protocol (Secure) Web communication JSON JavaScript Object Notation Data format KPI Key Performance Indicator Measuring success LLM Large Language Model AI model (Claude, GPT, etc.) MCP Model Context Protocol Connecting tools OAuth Open Authentication Secure login PR Pull Request Code changes on GitHub RBAC Role-Based Access Control User permissions SSH Secure Shell Remote computer access UFW Uncomplicated Firewall Network security VPS Virtual Private Server Cloud computer"},{"location":"Glossary/#useful-concepts-explained-simply","title":"Useful Concepts Explained Simply","text":"<p>What's an LLM? An LLM (Large Language Model) is artificial intelligence trained on massive amounts of text. It's really good at understanding language and writing. Claude, GPT-4, and Qwen are all LLMs.</p> <p>What's an API Key? An API key is like a password for a service. When you sign up for OpenAI, they give you an API key. You put that key in your config so OpenAI knows it's you making requests. Treat it like a password: don't share it.</p> <p>What's a VPS? A VPS (Virtual Private Server) is a computer you rent in the cloud. It's like having a dedicated computer running somewhere else. You can SSH into it and run nanobot on it 24/7.</p> <p>What's Obsidian? Obsidian is a note-taking app. It runs on your computer and stores notes as markdown files in a folder. Nanobot can read and write to Obsidian, so it remembers things across conversations.</p> <p>Have a term that's confusing? Submit an issue or let us know!</p>"},{"location":"Governance-Policies-and-Config-Examples/","title":"Governance Policies &amp; Config Examples","text":"<p>Enforce organizational guardrails, access control, and cost accountability. Templates and patterns for production deployments.</p>"},{"location":"Governance-Policies-and-Config-Examples/#document-control","title":"Document Control","text":"<ul> <li>Owner:</li> <li>Version: 1.0.0</li> <li>Last Updated: 2026-02-25</li> <li>Status: Active</li> </ul>"},{"location":"Governance-Policies-and-Config-Examples/#1-overview-the-3-plane-governance-model","title":"1. Overview: The 3-Plane Governance Model","text":"<p>Plane 1: Control \u2014 Who can do what? (access control, tool allowlisting) Plane 2: Policy \u2014 How are decisions made? (routing rules, escalation, approval flows) Plane 3: Memory \u2014 What does the system know? (vault scope, retention policies)</p> <p>All three planes are channel-aware (work in Discord, Slack, Telegram, etc.).</p>"},{"location":"Governance-Policies-and-Config-Examples/#2-access-control-patterns","title":"2. Access Control Patterns","text":""},{"location":"Governance-Policies-and-Config-Examples/#pattern-a-role-based-tool-allowlisting-rbac","title":"Pattern A: Role-Based Tool Allowlisting (RBAC)","text":"<p>RBAC = Role-Based Access Control. (Different people get different permissions based on their job role.)</p> <p>Use Case: Different teams get different tools.</p> <p>Config example:</p> <pre><code>{\n  \"teams\": {\n    \"engineering\": {\n      \"channels\": [\"#dev\", \"#devops\"],\n      \"allowed_tools\": [\n        \"web_search\",\n        \"github_*\",\n        \"shell_exec\",\n        \"file_*\",\n        \"mcp_call\",\n        \"cron_schedule\"\n      ],\n      \"forbidden_tools\": [\"shell_exec:rm\", \"shell_exec:sudo\"],\n      \"llm_tier\": \"b\"\n    },\n    \"marketing\": {\n      \"channels\": [\"#marketing\", \"#content-hub\"],\n      \"allowed_tools\": [\n        \"web_search\",\n        \"file_read\",\n        \"message_send\",\n        \"obsidian\"\n      ],\n      \"forbidden_tools\": [\"shell_exec\", \"github_*\"],\n      \"llm_tier\": \"c\"\n    },\n    \"executive\": {\n      \"channels\": [\"#exec\", \"#leadership\"],\n      \"allowed_tools\": [\n        \"web_search\",\n        \"file_read\",\n        \"message_send\",\n        \"summarize\"\n      ],\n      \"forbidden_tools\": [\"shell_exec\", \"cron\", \"mcp\"],\n      \"llm_tier\": \"a\",\n      \"escalation\": \"required\"\n    }\n  }\n}\n</code></pre> <p>Behavior:</p> Team Can use Cannot use LLM Engineering All tools except destructive shell rm, sudo, reboot Tier B Marketing Search, read, message, obsidian Shell, GitHub, MCP Tier C Executive Search, read, message, summarize Shell, GitHub, cron, MCP Tier A <p>Enforcement:</p> <p>If marketing user tries <code>@BotName shell_exec: ls /</code>: <pre><code>\u274c Tool 'shell_exec' not allowed for #marketing team.\n   Allowed tools: web_search, file_read, message_send, obsidian\n   Contact: @engineering-lead for access request\n</code></pre></p>"},{"location":"Governance-Policies-and-Config-Examples/#pattern-b-channel-level-tool-restrictions","title":"Pattern B: Channel-Level Tool Restrictions","text":"<p>Use Case: Public channels more restricted than private.</p> <pre><code>{\n  \"channels\": {\n    \"#general\": {\n      \"tools\": [\"web_search\", \"message_send\"],\n      \"visibility\": \"public\"\n    },\n    \"#dev\": {\n      \"tools\": [\"web_search\", \"shell_exec\", \"github_*\", \"mcp_call\"],\n      \"visibility\": \"team\"\n    },\n    \"#devops-secrets\": {\n      \"tools\": [\"shell_exec\", \"file_*\", \"mcp_call\"],\n      \"visibility\": \"restricted\",\n      \"requires_approval\": true,\n      \"approval_group\": \"@devops-leads\"\n    }\n  }\n}\n</code></pre> <p>Behavior:</p> <ul> <li><code>#general</code>: Only safe, read-only tools</li> <li><code>#dev</code>: Dev-friendly tools, no approval needed</li> <li><code>#devops-secrets</code>: Full power, but every action logged + approved</li> </ul>"},{"location":"Governance-Policies-and-Config-Examples/#pattern-c-per-user-rate-limiting","title":"Pattern C: Per-User Rate Limiting","text":"<p>Use Case: Prevent cost overruns and abuse.</p> <pre><code>{\n  \"rate_limits\": {\n    \"default_user\": {\n      \"tokens_per_day\": 50000,\n      \"requests_per_hour\": 60,\n      \"web_search_per_day\": 20\n    },\n    \"power_users\": {\n      \"tokens_per_day\": 200000,\n      \"requests_per_hour\": 300,\n      \"web_search_per_day\": 100\n    },\n    \"limited_users\": {\n      \"tokens_per_day\": 5000,\n      \"requests_per_hour\": 10,\n      \"web_search_per_day\": 5\n    }\n  },\n  \"team_quotas\": {\n    \"engineering\": {\n      \"daily_tokens\": 500000,\n      \"monthly_budget\": 100\n    },\n    \"marketing\": {\n      \"daily_tokens\": 100000,\n      \"monthly_budget\": 30\n    }\n  }\n}\n</code></pre> <p>Behavior:</p> <p>User exceeds daily limit: <pre><code>\u26a0\ufe0f Daily token limit reached (50,000/50,000)\n   Your limit resets tomorrow at 12:00am UTC\n   Need more capacity? Request upgrade: https://...\n</code></pre></p> <p>Team exceeds budget: <pre><code>\ud83d\udcb0 Team monthly budget exhausted ($100/$100)\n   Remaining requests will use local Ollama (free)\n   Budget resets in 5 days\n</code></pre></p>"},{"location":"Governance-Policies-and-Config-Examples/#3-risk-tier-framework-who-needs-approval","title":"3. Risk Tier Framework (Who Needs Approval?)","text":"<p>Goal: Classify actions by how easy they are to undo. (Reversibility = can you fix it if something goes wrong?)</p> <p>If an action is hard to undo or could cause problems, it needs human approval first.</p>"},{"location":"Governance-Policies-and-Config-Examples/#risk-tiers-overview","title":"Risk Tiers Overview","text":"<p>Risk is measured by Magnitude of Irreversibility. If an action is hard to undo or compromises core security, it's high-risk.</p> Tier Automation Description Examples Approval? Tier 0: Safe \u2705 Autonomous Read-only, internal logs, low-impact data Checking weather, reading Obsidian notes, summarizing public PDFs No Tier 1: Minor \u2705 Autonomous State changes with undo capability Creating folders, moving temp files, adding Discord reactions No (log only) Tier 2: Moderate \u26a0\ufe0f Soft-Pause Actions affecting external data or \"shadow\" systems Sending email to known contact, deleting temp folder, running scheduled reports Conditional* Tier 3: High \ud83d\uded1 Hard-Pause Actions affecting identity or security Modifying Discord permissions, changing .env files, new SSH (Secure Shell) node access Yes (Approver role) Tier 4: Critical \ud83d\udd12 Locked Destructive or system-wide changes Deleting database, mass-sending external messages, changing Primary Operator ID Yes (MFA/Admin only) <p>*Conditional = approved automatically if target is allowlisted; requires approval otherwise</p>"},{"location":"Governance-Policies-and-Config-Examples/#implementation-example","title":"Implementation Example","text":"<pre><code>{\n  \"risk_tiers\": {\n    \"tier_0\": {\n      \"automation\": \"autonomous\",\n      \"description\": \"Read-only, safe\",\n      \"examples\": [\"web_search\", \"obsidian_read\", \"summarize\"],\n      \"approval_required\": false\n    },\n    \"tier_1\": {\n      \"automation\": \"autonomous\", \n      \"description\": \"Minor changes, recoverable\",\n      \"examples\": [\"file_create\", \"folder_create\", \"message_react\"],\n      \"approval_required\": false,\n      \"audit_logging\": true\n    },\n    \"tier_2\": {\n      \"automation\": \"soft_pause\",\n      \"description\": \"External or shadow data impacts\",\n      \"examples\": [\"message_send:email\", \"file_delete:temp\", \"cron:schedule\"],\n      \"approval_required\": \"conditional\",\n      \"auto_approve_if\": \"target_in_allowlist\"\n    },\n    \"tier_3\": {\n      \"automation\": \"hard_pause\",\n      \"description\": \"Security/identity impacts\",\n      \"examples\": [\"permission_modify\", \"config_write:secrets\", \"node_authorize\"],\n      \"approval_required\": true,\n      \"approver_role\": \"AOS Approver\",\n      \"timeout_seconds\": 300\n    },\n    \"tier_4\": {\n      \"automation\": \"locked\",\n      \"description\": \"Destructive, system-wide\",\n      \"examples\": [\"database_truncate\", \"message_broadcast:external\", \"operator_change\"],\n      \"approval_required\": true,\n      \"approver_role\": \"Admin\",\n      \"requires_mfa\": true,\n      \"requires_human_review\": true\n    }\n  }\n}\n</code></pre>"},{"location":"Governance-Policies-and-Config-Examples/#how-tiers-trigger-approval-flows","title":"How Tiers Trigger Approval Flows","text":"<p>When user requests a Tier 3 action:</p> <pre><code>User: @BotName ssh authorize new-node 192.168.1.50\n\n\ud83d\uded1 HIGH-RISK ACTION: Node Authorization\n   Requested by: @alice (engineering team)\n   Action: Authorize new SSH access to 192.168.1.50\n\n   Risk Level: Tier 3 (security impact)\n   Reversibility: Revocable but requires cleanup\n\n   \u270b Approval Required from: @AOS-Approver role\n   Timeout: 5 minutes\n\n[Review Details] [Approve] [Deny]\n</code></pre> <p>When user requests a Tier 4 action:</p> <pre><code>User: @BotName database truncate production_logs\n\n\ud83d\udd12 CRITICAL ACTION: Database Truncate\n   Requested by: @alice\n   Action: PERMANENTLY DELETE production_logs\n\n   Risk Level: Tier 4 (destructive, irreversible)\n   Data Loss: Irreversible\n\n   \u26d4 LOCKED: Only Admin role with MFA can approve\n   Requires: Multi-factor authentication\n   Approval Timeout: 1 hour (imminent action warning)\n\n   WARNING: This action cannot be undone!\n   All audit trails will be deleted.\n\n[View Details] [Request Admin] [Cancel]\n</code></pre>"},{"location":"Governance-Policies-and-Config-Examples/#4-channel-naming-convention-governance","title":"4. Channel Naming Convention &amp; Governance","text":"<p>Goal: Channel names automatically enforce policy.</p>"},{"location":"Governance-Policies-and-Config-Examples/#standard-naming-scheme","title":"Standard Naming Scheme","text":"<pre><code>{scope}-{purpose}-{privacy}\n\nScope: prd, bk, res, ctl, fin, hr, lgl\nPurpose: any lowercase string\nPrivacy: none (public), -private, -secret\n</code></pre> <p>Examples:</p> Channel Scope Team Tools Allowed Privacy <code>#prd-architecture</code> prd engineering All dev tools Public <code>#prd-secrets</code> prd engineering Full power Restricted <code>#bk-payroll</code> bk hr Read-only files Restricted <code>#res-customer-data</code> res research Web search, file read Restricted <code>#ctl-emergency</code> ctl ops All tools, instant approval Restricted <code>#fin-quarterly</code> fin finance Summarize, search Private"},{"location":"Governance-Policies-and-Config-Examples/#config-based-routing","title":"Config-based Routing","text":"<pre><code>{\n  \"channel_policy\": {\n    \"naming_scheme\": \"{scope}-{purpose}[-{privacy}]\",\n    \"routing_rules\": [\n      {\n        \"pattern\": \"prd-*\",\n        \"team\": \"engineering\",\n        \"tools\": \"engineering_allowed\",\n        \"tier\": \"b\",\n        \"cost_center\": \"engineering\"\n      },\n      {\n        \"pattern\": \"bk-*\",\n        \"team\": \"operations\",\n        \"tools\": \"operations_allowed\",\n        \"tier\": \"c\",\n        \"cost_center\": \"operations\"\n      },\n      {\n        \"pattern\": \"*-secret\",\n        \"requires_approval\": true,\n        \"audit_level\": \"verbose\",\n        \"approval_group\": \"@security-team\"\n      },\n      {\n        \"pattern\": \"ctl-*\",\n        \"tier\": \"a\",\n        \"approval\": \"instant\",\n        \"cost_center\": \"operations\"\n      }\n    ]\n  }\n}\n</code></pre> <p>Behavior:</p> <p>When user creates channel <code>#prd-auth-secret</code>: <pre><code>\u2713 Channel created: #prd-auth-secret\n  Automatically assigned:\n  - Team: engineering\n  - Tools allowed: {engineering_allowed}\n  - Cost center: engineering\n  - LLM tier: b\n  - Approval required: Yes (contains 'secret')\n  - Audit logging: Verbose\n\n  Confirm policies? [Y/n]\n</code></pre></p>"},{"location":"Governance-Policies-and-Config-Examples/#5-provider-routing-by-workflow","title":"5. Provider Routing by Workflow","text":"<p>Goal: Smart cost optimization. Route by channel/keyword/priority.</p> <pre><code>{\n  \"llm_routing\": {\n    \"rules\": [\n      {\n        \"channel\": \"#prd-*\",\n        \"priority\": \"high\",\n        \"provider\": \"openrouter\",\n        \"model\": \"claude-opus\",\n        \"tier\": \"a\",\n        \"fallback\": \"openrouter-qwen\"\n      },\n      {\n        \"channel\": \"#research-*\",\n        \"priority\": \"medium\",\n        \"provider\": \"openrouter\",\n        \"model\": \"qwen2:72b\",\n        \"tier\": \"b\",\n        \"fallback\": \"openrouter-deepseek\"\n      },\n      {\n        \"channel\": \"#bk-*\",\n        \"priority\": \"low\",\n        \"provider\": \"openrouter\",\n        \"model\": \"deepseek-67b\",\n        \"tier\": \"c\",\n        \"fallback\": \"local-ollama\"\n      },\n      {\n        \"keyword\": \"urgent\",\n        \"priority\": \"critical\",\n        \"provider\": \"anthropic\",\n        \"model\": \"claude-opus\",\n        \"tier\": \"a\"\n      },\n      {\n        \"keyword\": \"batch\",\n        \"time_window\": \"02:00-06:00\",\n        \"provider\": \"local\",\n        \"model\": \"ollama-qwen\",\n        \"tier\": \"free\"\n      },\n      {\n        \"time\": \"22:00-08:00\",\n        \"default_tier\": \"c\",\n        \"reason\": \"off-peak budget mode\"\n      }\n    ]\n  }\n}\n</code></pre> <p>Examples:</p> <pre><code>User in #prd-architecture:\n@BotName: Design async connection pooling\n\n\u2192 Route: claude-opus (Tier A, $0.015/1K tokens)\nReason: High-priority engineering channel\n</code></pre> <pre><code>User in #bk-categorization:\n@BotName: Classify these 100 support tickets\n\n\u2192 Route: deepseek-67b (Tier C, $0.0003/1K tokens)\nReason: Backlog/batch, low priority\nCost estimate: ~$0.03 instead of $0.30 if using Opus\n</code></pre> <pre><code>User in #prd-emergency:\n@BotName urgent: Production database down, need immediate diagnosis\n\n\u2192 Route: claude-opus (Tier A, instant)\nReason: Keyword \"urgent\"\nBypass tier restrictions\n</code></pre>"},{"location":"Governance-Policies-and-Config-Examples/#6-approval-workflows-for-high-risk-actions","title":"6. Approval Workflows for High-Risk Actions","text":"<p>Goal: Prevent costly or dangerous operations without human review.</p> <pre><code>{\n  \"approval_required\": {\n    \"rules\": [\n      {\n        \"tool\": \"shell_exec\",\n        \"with_keywords\": [\"rm\", \"sudo\", \"chmod\", \"kill\"],\n        \"approvers\": [\"@security-team\"],\n        \"timeout\": 300\n      },\n      {\n        \"tool\": \"mcp_call\",\n        \"to_system\": [\"external_api\", \"database_write\"],\n        \"approvers\": [\"@devops-leads\"],\n        \"timeout\": 600\n      },\n      {\n        \"action\": \"cost_exceeds\",\n        \"threshold\": 50,\n        \"approvers\": [\"@finance-team\"],\n        \"timeout\": 3600\n      },\n      {\n        \"channel\": \"*-secret\",\n        \"any_tool\": true,\n        \"approvers\": [\"@security-team\"],\n        \"timeout\": 300\n      }\n    ]\n  }\n}\n</code></pre> <p>Example Flow:</p> <pre><code>User in #prd-database:\n@BotName shell_exec: rm -rf /data/cache/*\n\n\u274c APPROVAL REQUIRED\nSafe mode blocked destructive command: rm\n\nDescription: Remove all cache data\nRequested by: @alice\nApprovers needed: @security-team, @devops-leads\nApproval timeout: 5 minutes\n\nApproving this will:\n- Delete /data/cache\n- Cannot be undone\n- See audit trail: https://...\n\n[View Details] [Approve] [Deny]\n</code></pre> <p>If approved: <pre><code>\u2705 Approved by @eve (security-team)\n\u2705 Approved by @frank (devops-leads)\n\nExecuting: rm -rf /data/cache/*\n\nCommand output:\n[operation results]\n\nAudit entry created: ID-2026-0225-0447\n</code></pre></p>"},{"location":"Governance-Policies-and-Config-Examples/#7-escalation-workflows","title":"7. Escalation Workflows","text":"<p>Goal: Uncertain decisions bubble up to humans.</p> <pre><code>{\n  \"escalation\": {\n    \"rules\": [\n      {\n        \"confidence_below\": 0.70,\n        \"escalate_to\": \"@support-team\",\n        \"message\": \"Low confidence response; please review\"\n      },\n      {\n        \"cost_estimate_exceeds\": 100,\n        \"escalate_to\": \"@finance-team\",\n        \"message\": \"High-cost operation; needs approval\"\n      },\n      {\n        \"error_rate_above\": 0.10,\n        \"escalate_to\": \"@devops-team\",\n        \"message\": \"Tool failure rate elevated; investigate\"\n      },\n      {\n        \"channel\": \"#legal-*\",\n        \"any_question\": true,\n        \"escalate_to\": \"@legal-team\",\n        \"message\": \"All legal channel requests auto-escalate\"\n      }\n    ]\n  }\n}\n</code></pre> <p>Example:</p> <pre><code>User in #support:\n@BotName: What's our HIPAA compliance status?\n\n\ud83e\udd14 Low confidence response (58%)\nEscalating to human...\n\nConversation forwarded to: @support-team\nEstimated response: 15 mins\n\nCustomer message:\n\"Our specialist team is reviewing your question.\nYou'll get a detailed response shortly.\"\n</code></pre>"},{"location":"Governance-Policies-and-Config-Examples/#7-audit-logging-policies","title":"7. Audit &amp; Logging Policies","text":"<p>Goal: Track all actions for security and cost compliance.</p> <pre><code>{\n  \"audit\": {\n    \"log_level\": {\n      \"default\": \"info\",\n      \"*-secret\": \"verbose\",\n      \"mcp_call\": \"verbose\",\n      \"shell_exec\": \"verbose\",\n      \"github_*\": \"info\"\n    },\n    \"retention\": {\n      \"default\": 90,\n      \"*-secret\": 365,\n      \"security_events\": 730\n    },\n    \"fields\": [\n      \"timestamp\",\n      \"user_id\",\n      \"team\",\n      \"channel\",\n      \"tool_used\",\n      \"cost_incurred\",\n      \"tokens_consumed\",\n      \"success_or_error\",\n      \"approval_chain\"\n    ],\n    \"export\": {\n      \"frequency\": \"daily\",\n      \"format\": \"json\",\n      \"destination\": \"s3://audit-logs/\"\n    }\n  }\n}\n</code></pre> <p>Usage:</p> <pre><code># View audit logs for a user\nnanobot audit --user alice --since \"7 days ago\"\n\n# View by team\nnanobot audit --team engineering --since \"this month\"\n\n# View security events\nnanobot audit --event-type shell_exec,mcp_call --since \"30 days ago\"\n\n# Export for compliance\nnanobot audit export --format csv --destination ./audit-report.csv\n</code></pre>"},{"location":"Governance-Policies-and-Config-Examples/#8-cost-allocation-chargeback","title":"8. Cost Allocation &amp; Chargeback","text":"<p>Goal: Multi-team deployments need to track who spent what.</p> <pre><code>{\n  \"cost_allocation\": {\n    \"teams\": {\n      \"engineering\": {\n        \"cost_center\": \"eng-ops\",\n        \"monthly_budget\": 150,\n        \"alert_at\": 100,\n        \"override_contact\": \"alice@company.com\"\n      },\n      \"marketing\": {\n        \"cost_center\": \"mkt-ops\",\n        \"monthly_budget\": 50,\n        \"alert_at\": 35,\n        \"override_contact\": \"bob@company.com\"\n      },\n      \"research\": {\n        \"cost_center\": \"r-and-d\",\n        \"monthly_budget\": 200,\n        \"alert_at\": 150,\n        \"override_contact\": \"carol@company.com\"\n      }\n    },\n    \"reporting\": {\n      \"frequency\": \"weekly\",\n      \"recipients\": [\"cfo@company.com\", \"ops-team@company.com\"],\n      \"format\": \"html\"\n    }\n  }\n}\n</code></pre> <p>Weekly Report Example:</p> <pre><code>Cost Allocation Report - Week of Feb 24, 2026\n\nEngineering:\n  Budget: $150/month | Spent this week: $32.50 (22%)\n  YTD: $130 / Projected total: $520\n\nMarketing:\n  Budget: $50/month | Spent this week: $8.20 (16%)\n  YTD: $30 / Projected total: $120\n\nResearch:\n  Budget: $200/month | Spent this week: $45.80 (23%)\n  YTD: $190 / Projected total: $760 (ESTIMATE EXCEEDS)\n\n\u26a0\ufe0f Research team on track to exceed budget\n   Contact: @carol | Recommend: Increase budget or reduce scope\n</code></pre>"},{"location":"Governance-Policies-and-Config-Examples/#9-sample-complete-config-all-planes","title":"9. Sample Complete Config (All Planes)","text":"<p>Control Plane (Access):</p> <pre><code>{\n  \"access_control\": {\n    \"teams\": {\n      \"engineering\": {\n        \"channels\": [\"#dev\", \"#devops\", \"#prd-*\"],\n        \"allowed_tools\": [\"web_search\", \"shell_exec\", \"github_*\", \"file_*\", \"mcp_call\"],\n        \"excluded_tools\": [\"shell_exec:rm\", \"shell_exec:sudo\"]\n      }\n    }\n  }\n}\n</code></pre> <p>Policy Plane (Routing &amp; Approval):</p> <pre><code>{\n  \"routing\": {\n    \"default\": \"tier_b\",\n    \"rules\": [\n      { \"channel\": \"#prd-*\", \"tier\": \"a\", \"provider\": \"anthropic\" },\n      { \"channel\": \"#bk-*\", \"tier\": \"c\", \"provider\": \"openrouter-deepseek\" }\n    ]\n  },\n  \"approval\": {\n    \"rules\": [\n      { \"tool\": \"shell_exec\", \"with_keywords\": [\"rm\"], \"required\": true }\n    ]\n  }\n}\n</code></pre> <p>Memory Plane (Scope &amp; Retention):</p> <pre><code>{\n  \"memory\": {\n    \"vault_policies\": {\n      \"#dev\": { \"path\": \"/vault/dev\", \"retention\": 90 },\n      \"#secret\": { \"path\": \"/vault/secret\", \"retention\": 730, \"encrypted\": true }\n    }\n  }\n}\n</code></pre>"},{"location":"Governance-Policies-and-Config-Examples/#10-governance-checklist-deployment","title":"10. Governance Checklist (Deployment)","text":"<p>Before going live:</p> <p>Access Control: - [ ] Define teams and their allowed tools - [ ] Set per-user rate limits - [ ] Set team budgets - [ ] Publish channel naming convention</p> <p>Routing &amp; Cost: - [ ] Define tier assignments (A/B/C) by channel - [ ] Set provider fallback chain - [ ] Test multi-provider failover - [ ] Validate cost estimates</p> <p>Approval &amp; Escalation: - [ ] List high-risk tools requiring approval - [ ] Define escalation rules (confidence, cost) - [ ] Train approvers on response time - [ ] Test approval workflow end-to-end</p> <p>Audit &amp; Compliance: - [ ] Set log retention policy - [ ] Configure audit export - [ ] Set up weekly cost reports - [ ] Define compliance requirements</p> <p>Enforcement: - [ ] Test access denied scenario - [ ] Test approval workflow - [ ] Test escalation triggers - [ ] Monitor first week closely</p>"},{"location":"Governance-Policies-and-Config-Examples/#11-troubleshooting-governance-issues","title":"11. Troubleshooting Governance Issues","text":"Problem Symptom Solution User complains \"tool not allowed\" Tool blocked for user Check RBAC config; user in right team? Check channel policy Cost running over budget Monthly spend exceeds threshold Review routing rules; are low-priority tasks using high tiers? Approvals taking too long Users waiting for action Check approval timeout; add more approvers; use instant approval for low-risk Audit logs missing Cannot find historical actions Check log_level and retention; increase verbosity for critical tools Escalations not triggering Cases not bubbling to humans Verify escalation rules match actual thresholds; test with manual override"},{"location":"Governance-Policies-and-Config-Examples/#12-common-patterns-by-organization-type","title":"12. Common Patterns by Organization Type","text":""},{"location":"Governance-Policies-and-Config-Examples/#startup-lean-speed-focused","title":"Startup (Lean, Speed-Focused)","text":"<pre><code>{\n  \"teams\": [\"engineering\"],\n  \"policies\": \"minimal\",\n  \"approval\": \"self-approve\",\n  \"audit\": \"basic\",\n  \"budget\": \"flexible\"\n}\n</code></pre> <p>Philosophy: Move fast, minimal overhead.</p>"},{"location":"Governance-Policies-and-Config-Examples/#scale-up-multiple-teams","title":"Scale-Up (Multiple Teams)","text":"<pre><code>{\n  \"teams\": [\"engineering\", \"marketing\", \"operations\"],\n  \"policies\": \"channel-based\",\n  \"approval\": \"for high-risk + high-cost\",\n  \"audit\": \"weekly reports\",\n  \"budget\": \"per-team allocation\"\n}\n</code></pre> <p>Philosophy: Balance autonomy + accountability.</p>"},{"location":"Governance-Policies-and-Config-Examples/#enterprise-compliance-heavy","title":"Enterprise (Compliance-Heavy)","text":"<pre><code>{\n  \"teams\": [\"engineering\", \"marketing\", \"operations\", \"legal\", \"finance\"],\n  \"policies\": \"strict RBAC\",\n  \"approval\": \"required for all risky actions\",\n  \"audit\": \"verbose + compliance export\",\n  \"budget\": \"strict cost centers + chargeback\"\n}\n</code></pre> <p>Philosophy: Governance by default; audit everything.</p>"},{"location":"Governance-Policies-and-Config-Examples/#revision-history","title":"Revision History","text":"Date Version Change 2026-02-25 1.0.0 Initial governance policies and config examples"},{"location":"LLM-Provider-Setup-Guide/","title":"LLM Provider Setup Guide","text":"<p>Configure nanobot to use different AI (artificial intelligence) models based on workflow type, cost, and capability requirements.</p>"},{"location":"LLM-Provider-Setup-Guide/#document-control","title":"Document Control","text":"<ul> <li>Owner:</li> <li>Version: 1.0.0</li> <li>Last Updated: 2026-02-25</li> <li>Status: Active</li> </ul>"},{"location":"LLM-Provider-Setup-Guide/#1-overview","title":"1. Overview","text":"<p>Nanobot supports 100+ LLM (Large Language Model) models via unified configuration. Choose your provider based on: - Cost - Qwen, DeepSeek cheaper; Opus more expensive but capable - Latency - Local faster; cloud slightly slower - Capability - Opus best for complex reasoning; Haiku fastest - Data residency - Local Ollama for sensitive data</p>"},{"location":"LLM-Provider-Setup-Guide/#2-supported-providers","title":"2. Supported Providers","text":"Provider Models Setup Difficulty Cost Latency OpenRouter (Recommended) 100+ (Claude, GPT, Qwen, etc.) \u2b50 Easy $1-5/M Medium Anthropic Direct Claude Opus, Sonnet, Haiku \u2b50 Easy $3-15/M Medium OpenAI Direct GPT-4, GPT-4o, GPT-3.5 \u2b50 Easy $5-30/M Fast Local (Ollama) Llama, Mistral, etc. \u2b50\u2b50 Moderate $0 Fast DeepSeek DeepSeek-Chat, Code \u2b50 Easy $0.14/M Medium Qwen (Alibaba) Qwen-Plus, -Turbo \u2b50 Easy $0.008/M Medium Gemini (Google) Gemini Pro, Ultra \u2b50 Easy $0.5-10/M Medium Cohere Command R, R+ \u2b50 Easy $0.5-3/M Medium"},{"location":"LLM-Provider-Setup-Guide/#3-quick-setup-5-minutes","title":"3. Quick Setup (5 minutes)","text":""},{"location":"LLM-Provider-Setup-Guide/#option-a-openrouter-all-in-one","title":"Option A: OpenRouter (All-in-One)","text":"<p>OpenRouter gives you access to 100+ models with one API key. (An API key is like a password that lets nanobot connect to OpenRouter's servers.)</p> <p>Step 1: Get API Key - Visit https://openrouter.ai/keys - Sign up or log in - Copy your API key (this is your unique password\u2014keep it secret!)</p> <p>Step 2: Configure <pre><code>{\n  \"providers\": {\n    \"openrouter\": {\n      \"apiKey\": \"sk-or-v1-YOUR_KEY_HERE\"\n    }\n  },\n  \"agents\": {\n    \"defaults\": {\n      \"model\": \"anthropic/claude-opus-4-5\",\n      \"provider\": \"openrouter\"\n    }\n  }\n}\n</code></pre> Save to <code>~/.nanobot/config.json</code> (or set <code>OPENROUTER_API_KEY</code> environment variable\u2014this is a way to store the API key so programs can read it)</p> <p>Step 3: Test <pre><code># Start nanobot interactive mode and ask it a question\nnanobot agent\nask a question\n</code></pre></p>"},{"location":"LLM-Provider-Setup-Guide/#option-b-local-ollama","title":"Option B: Local Ollama","text":"<p>Perfect for sensitive data, no API costs. (You run the AI on your own computer instead of using a cloud service.)</p> <p>Step 1: Install Ollama - Download from https://ollama.ai - Install on your machine</p> <p>Step 2: Pull a Model <pre><code># 'ollama pull' downloads an AI model to your machine (like downloading a file)\n# 'mistral' is the name of the model\nollama pull mistral\n</code></pre></p> <p>Step 3: Configure nanobot <pre><code>{\n  \"providers\": {\n    \"ollama\": {\n      \"baseUrl\": \"http://localhost:11434\"\n    }\n  },\n  \"agents\": {\n    \"defaults\": {\n      \"model\": \"mistral\",\n      \"provider\": \"ollama\"\n    }\n  }\n}\n</code></pre></p> <p>Step 4: Start Ollama <pre><code># ollama serve starts the AI server on your machine\n# Keep this running in a terminal (it will listen for nanobot's requests)\nollama serve\n</code></pre> (Keep this running in background)</p> <p>Step 5: Test <pre><code>nanobot agent\nask a question\n</code></pre></p>"},{"location":"LLM-Provider-Setup-Guide/#option-c-direct-anthropic-claude","title":"Option C: Direct Anthropic (Claude)","text":"<p>Best if using Claude exclusively.</p> <p>Step 1: Get API Key - Visit https://console.anthropic.com - Create API key</p> <p>Step 2: Configure <pre><code>{\n  \"providers\": {\n    \"anthropic\": {\n      \"apiKey\": \"sk-ant-YOUR_KEY_HERE\"\n    }\n  },\n  \"agents\": {\n    \"defaults\": {\n      \"model\": \"claude-opus-4-5\",\n      \"provider\": \"anthropic\"\n    }\n  }\n}\n</code></pre></p>"},{"location":"LLM-Provider-Setup-Guide/#4-multi-provider-setup-cost-optimization","title":"4. Multi-Provider Setup (Cost Optimization)","text":"<p>Use different models for different workflows:</p> <pre><code>{\n  \"providers\": {\n    \"openrouter\": {\n      \"apiKey\": \"sk-or-v1-...\"\n    }\n  },\n  \"agents\": {\n    \"default\": {\n      \"model\": \"openai/gpt-4-turbo\",\n      \"provider\": \"openrouter\"\n    },\n    \"research\": {\n      \"model\": \"anthropic/claude-opus-4-5\",\n      \"provider\": \"openrouter\"\n    },\n    \"bookkeeping\": {\n      \"model\": \"qwen/qwen-plus\",\n      \"provider\": \"openrouter\"\n    },\n    \"fast-response\": {\n      \"model\": \"anthropic/claude-haiku\",\n      \"provider\": \"openrouter\"\n    }\n  }\n}\n</code></pre> <p>Then in Discord/Slack policy: Route <code>#bk-*</code> to bookkeeping agent, <code>#res-*</code> to research agent, etc.</p>"},{"location":"LLM-Provider-Setup-Guide/#5-token-budgeting-cost-control","title":"5. Token Budgeting &amp; Cost Control","text":"<p>Configure per-request and per-agent limits. (Tokens = words, roughly. This controls how long responses can be.)</p> <pre><code>{\n  \"agents\": {\n    \"defaults\": {\n      \"maxInputTokens\": 8000,\n      \"maxOutputTokens\": 4096,\n      \"temperature\": 0.1,\n      \"maxIterations\": 40\n    },\n    \"research\": {\n      \"maxInputTokens\": 32000,\n      \"maxOutputTokens\": 8192,\n      \"temperature\": 0.3,\n      \"maxIterations\": 40\n    }\n  }\n}\n</code></pre> <p>What each means: - maxInputTokens = Maximum words/context to send to AI (8000 \u2248 6,000 words) - maxOutputTokens = Maximum words in response (4096 \u2248 3,000 words) - temperature = How \"creative\" the AI is (0.1 = logical, 1.0 = random) - maxIterations = How many times AI can self-correct (higher = more thinking, more cost)</p>"},{"location":"LLM-Provider-Setup-Guide/#6-prompt-caching-cost-optimization","title":"6. Prompt Caching (Cost Optimization)","text":"<p>Anthropic Claude supports prompt caching. (Caching = saving frequently-used context so you don't re-send it every time. This saves money!) Enable to reduce costs on repeated queries:</p> <pre><code>{\n  \"providers\": {\n    \"anthropic\": {\n      \"apiKey\": \"sk-ant-...\",\n      \"cacheControl\": true\n    }\n  }\n}\n</code></pre> <p>This re-uses cached prompts for 5 minutes, reducing cost by ~10%.</p>"},{"location":"LLM-Provider-Setup-Guide/#7-environment-variable-override","title":"7. Environment Variable Override","text":"<p>Set a model for a single command: <pre><code>NANOBOT_MODEL=openai/gpt-4 nanobot agent\n</code></pre></p>"},{"location":"LLM-Provider-Setup-Guide/#8-web-search-api-brave","title":"8. Web Search API (Brave)","text":"<p>To enable web search, add Brave API key:</p> <pre><code>{\n  \"braveApiKey\": \"YOUR_BRAVE_API_KEY\"\n}\n</code></pre> <p>Get key from https://api.search.brave.com/</p>"},{"location":"LLM-Provider-Setup-Guide/#9-fallback-degraded-mode","title":"9. Fallback &amp; Degraded Mode","text":"<p>If primary provider fails, fall back to secondary:</p> <pre><code>{\n  \"agents\": {\n    \"defaults\": {\n      \"fallbackChain\": [\n        \"openrouter\",\n        \"anthropic\",\n        \"ollama\"\n      ]\n    }\n  }\n}\n</code></pre> <p>Nanobot tries first provider, falls back to next on error.</p>"},{"location":"LLM-Provider-Setup-Guide/#10-testing-troubleshooting","title":"10. Testing &amp; Troubleshooting","text":"<p>Test provider connection: <pre><code>nanobot doctor\n</code></pre></p> <p>Expected output: <pre><code>Provider: openrouter \u2713 Connected\nModel: claude-opus-4-5 \u2713 Available\nTokens available: Yes \u2713\n</code></pre></p> Issue Check <code>401 Unauthorized</code> Verify API key format and validity <code>Model not found</code> Confirm model name is correct for provider <code>Rate limited</code> Wait or upgrade API plan <code>Timeout</code> Check network connection or try different model"},{"location":"LLM-Provider-Setup-Guide/#11-aos-integration","title":"11. AOS Integration","text":"<p>Map channels to cost-tier models:</p> <ul> <li><code>#bk-*</code> \u2192 Qwen (cheapest, bookkeeping is lower-risk)</li> <li><code>#prd-*-analytics</code> \u2192 Claude Haiku (fast, moderate cost)</li> <li><code>#prd-*-marketing</code> \u2192 Claude Opus (high quality, moderate cost)</li> <li><code>#res-*</code> \u2192 Claude Opus (complex synthesis)</li> <li><code>#res-* (escalated)</code> \u2192 Claude Opus (no cost cap)</li> </ul> <p>Implement this via LLM policy document governing which agent routes to which provider.</p>"},{"location":"LLM-Provider-Setup-Guide/#12-revision-history","title":"12. Revision History","text":"Date Version Change 2026-02-25 1.0.0 Initial guide covering 8 major providers, multi-provider setup, cost controls, and caching"},{"location":"Master-Index/","title":"Nanobot Agentic Operating System Master Index","text":"<p>Repository: HKUDS/nanobot For Nanobot Version: v0.1.4 and later Last Updated: February 25, 2026</p>"},{"location":"Master-Index/#1-purpose","title":"1. Purpose","text":"<p>This document is the control index for the Nanobot documentation set. It explains how multiple communication channels, LLM (Large Language Model) governance, and Obsidian memory work together as one coordinated system\u2014independent of which chat platform (Discord, Slack, Telegram, Feishu, etc.) you use.</p>"},{"location":"Master-Index/#11-executive-summary-one-page","title":"1.1 Executive Summary (One-Page)","text":"<p>The Nanobot Agentic Operating System is a three-plane, channel-agnostic operating model: - Control Plane (Multi-Channel): workflow intake via Discord, Slack, Telegram, Feishu, or other platforms; approvals and operator visibility. - Policy Plane (LLM Governance): model routing (Claude, GPT, Qwen, Ollama, etc.), risk gates, budget controls, and cost optimization. - Memory Plane (Obsidian): durable records, audit trails, recovery evidence, and long-term knowledge indexing.</p> <p>Nanobot is the orchestration engine that powers the system. It listens to messages from any integrated channel, routes them through your policies, executes tasks (shell commands, file operations, web research, API calls, MCP (Model Context Protocol) tools, scheduled jobs), remembers what it learns, and sends results back to your chosen chat platform.</p> <p>How it works in practice: 1. Operator sends request in a policy-approved channel (e.g., Discord #prd-widget-marketing, Slack #prd-widget-marketing, Telegram group, or any supported platform). 2. Nanobot receives the message via channel integration. 3. LLM policy routes to appropriate model class (Claude, GPT, local Ollama, etc.) with cost/security constraints. 4. Nanobot executes tasks: web search (Brave API), file read/write/edit, shell commands, GitHub automation, weather data, MCP tool calls, cron tasks, or spawns parallel subagents. 5. Results are logged with structured metadata (request_id, project_id, tokens, cost, timing). 6. Response is posted back to the requesting channel with citations, confidence notes, and references. 7. Structured artifacts are written to Obsidian for replay, audit, and recovery.</p>"},{"location":"Master-Index/#example-scenario-product-campaign-research-to-action-channel-independent","title":"Example Scenario: Product Campaign Research to Action (Channel-Independent)","text":"<ol> <li>Operator asks in Slack #prd-widget-marketing: \"Find 3 competitor campaigns this week and propose one test we can run.\"</li> <li>Nanobot receives message via Slack channel integration.</li> <li>Policy routes to model trained on current data (e.g., Claude Opus via OpenRouter).</li> <li>Nanobot invokes: web_search tool (Brave API) \u2192 retrieves competitor campaign data with cost/context controls.</li> <li>Web results \u2192 summarize skill \u2192 synthesizes findings with citations.</li> <li>Nanobot posts back to Slack with recommendation, source links, and confidence assessment.</li> <li>Nanobot writes structured artifact to Obsidian: request_id, project_id, sources, reasoning, next steps.</li> <li>Operator approves test \u2192 change logged in Obsidian for compliance/audit trail.</li> </ol>"},{"location":"Master-Index/#12-nanobot-core-capabilities","title":"1.2 Nanobot Core Capabilities","text":"<p>Nanobot ships with these built-in features:</p> <p>LLM Provider Routing: (Choose which AI model to use for each task) - Cloud providers: OpenAI (GPT-4, etc.), Anthropic (Claude), Google Gemini, Cohere, Mistral, DeepSeek, Qwen, Moonshot, MiniMax, VolcEngine - Local inference via vLLM or Ollama (free, runs on your computer) - Custom provider support for proprietary models - Prompt caching (Anthropic) to save on costs - Automatic cost estimation and token budgeting</p> <p>Multi-Channel Integration: (Listen on any chat platform) - Discord, Slack, Telegram, Feishu, DingTalk, WhatsApp, Email, QQ, Matrix/Element, Mochat, CLI (local terminal) - Control who can use nanobot in each channel - Send and receive media and files - Handle long messages automatically (Discord splitting, Slack threading, etc.)</p> <p>Tool System: (Actions nanobot can perform) - Web Search &amp; Fetch - Find current information using Brave Search, download full pages - File Operations - Read, write, edit, list files (safely sandboxed) - Shell Commands - Run system commands (restricted, logged, operator-approved) - Message/Notifications - Send alerts and updates across channels - Scheduling (Cron) - Run tasks on a schedule (e.g., \"every day at 9 AM\") - MCP (Model Context Protocol) - Connect to external databases, file systems, and APIs - Subagents - Launch parallel workers to handle parts of complex tasks - GitHub Automation - Search code repositories, create pull requests (PRs), manage issues - Custom Tools - Build your own extensions</p> <p>Pre-Built Skills: (Ready-to-use bundles) - Obsidian - Read and write notes, search knowledge base - Summarize - Condense long content while keeping the important parts - Memory - Manage conversations, automatically summarize old history - Cron - Schedule recurring tasks - Weather - Fetch weather data - Skill Creator - Write new skills from natural language descriptions - ClawHub - Find and install community-created skills - TMUX - Control terminal sessions for advanced automation</p> <p>Reliability &amp; Optimization: - Session continuity with automatic memory consolidation - Heartbeat system for connection health monitoring - Retry/fallback strategies with degraded mode - Tool-call validation and error handling - Structured logging for debugging and audit</p>"},{"location":"Master-Index/#13-cost-control-summary","title":"1.3 Cost Control Summary","text":"<p>Ways to control spending and prevent bill shock: - Tiered model routing (Class A/B/C) - Use cheap models for simple tasks, expensive ones for complex work - Budget caps - Set spending limits by request, channel, or project - Approval gates - Require human sign-off before expensive operations - Smart context - Automatically summarize old conversations to reduce token use - Provider choice - Use budget-friendly models (Qwen, DeepSeek) for routine work; save Claude Opus for complex problems - Safety limits - Automatically stop runaway requests and prevent unexpected charges - Weekly reviews - Track spending patterns and watch for anomalies</p>"},{"location":"Master-Index/#14-security-compliance-baseline","title":"1.4 Security &amp; Compliance Baseline","text":"<p>How we keep your system safe: - Channel isolation - Teams can't see each other's conversations - Role-based access - Different users have different permissions (Operator, Reviewer, Owner) - Sandbox - Nanobot can only access files in its workspace, can't escape to system files - Allowlist - Only approved people can use dangerous tools (shell commands, APIs, GitHub automation) - Audit log - Every action is recorded with who did it, when, and what it cost - Monthly security checks - Run <code>nanobot security audit --deep</code> to verify everything is locked down - Separate sessions - Each user gets their own isolated workspace - Secret protection - API keys and tokens stored securely in <code>.env</code> files, never saved in code</p>"},{"location":"Master-Index/#15-small-business-enterprise-support-examples","title":"1.5 Small Business &amp; Enterprise Support Examples","text":"<p>Example ways this AOS supports organizations: - Bookkeeping: Ingest expense receipts, reconcile transactions, categorize spending, publish month-end summaries to Obsidian\u2014 all with traceable request_id chains for audit. - Product Marketing: Run product-scoped Slack/Discord/Telegram channels, auto-generate content drafts, run competitor research, report KPI deltas with cost-controlled model routing. - Research &amp; Development: Capture source links, synthesize findings with citations, evolve ideas through staged approval gates (hypothesis \u2192 design \u2192 test \u2192 post-mortem), all archived in Obsidian. - Customer Support: Automate FAQ routing, search knowledge base, generate pre-approval responses, escalate complex cases to humans with full context. - Operations/DevOps: Automate GitHub workflow triggers, monitor system health via cron jobs, log incidents with evidence, execute runbooks via shell tools.</p>"},{"location":"Master-Index/#2-getting-started-roadmap","title":"2. Getting Started Roadmap","text":"<p>Choose your path based on your goal:</p>"},{"location":"Master-Index/#21-quick-trial-5-10-minutes","title":"2.1 Quick Trial (5-10 minutes)","text":"<p>Goal: Try nanobot immediately with minimal setup.</p> <ol> <li>Master Index (this file) - Understand what you're building (3 planes, capabilities, tools)</li> <li>Nanobot Quick Install &amp; Setup - Install and test with default config</li> <li>LLM Provider Setup - Add one LLM provider (e.g., OpenRouter or local Ollama)</li> <li>Multi-Channel Integration - Connect one chat platform (Discord or Slack)</li> <li>Workflow Examples - Copy and run a simple workflow</li> </ol> <p>Result: Functional nanobot in &lt;15 minutes. Explore, test, then decide to scale.</p>"},{"location":"Master-Index/#22-production-setup-1-2-hours","title":"2.2 Production Setup (1-2 hours)","text":"<p>Goal: Deploy a professional system with cost controls, governance, and reliability.</p> <ol> <li>Master Index - Understand 3-plane model, RACI roles, cost controls</li> <li>Cost Calculator - Plan monthly spend, choose provider routing strategy</li> <li>Nanobot Build Procedure - Choose Path A (local + cloud LLM) or Path B (VPS + Ollama), deploy</li> <li>LLM Provider Setup - Configure all providers you'll use (multi-provider routing)</li> <li>Multi-Channel Integration - Set up all communication channels (Discord, Slack, Telegram, etc.)</li> <li>Essential AOS Skills - Install core skills (obsidian, memory, summarize, github, cron)</li> <li>AOS Startup Procedure - Start the system and verify health</li> <li>Tools &amp; Skills Reference - Learn what 14 tools and 9 skills you have available</li> <li>Workflow Examples - Implement 1-2 real workflows for your use case</li> <li>Governance Policies - Set up access control, allowlists, cost caps (optional for solo users; required for teams)</li> </ol> <p>Result: Production-grade nanobot with cost controls, memory/audit trails, and multi-channel support.</p>"},{"location":"Master-Index/#23-multi-team-deployment-2-4-hours-ongoing","title":"2.3 Multi-Team Deployment (2-4 hours + ongoing)","text":"<p>Goal: Deploy across teams with role-based access, approval workflows, and cost chargeback.</p> <p>Follow Production Setup path above, then:</p> <ol> <li>Governance Policies - Configure RBAC (Owner, Reviewer, Operator roles), channel namespacing, approval gates, cost allocation</li> <li>Cost Calculator - Set up cost chargeback by team/project</li> <li>Security Validation Runbook - Run monthly security audit, validate allowlists and tool restrictions</li> </ol> <p>Result: Nanobot operates safely across multiple teams with clear governance, spending transparency, and audit trails.</p>"},{"location":"Master-Index/#3-core-documents-reference","title":"3. Core Documents (Reference)","text":"<p>Use these docs as references when following one of the three roadmaps above.</p>"},{"location":"Master-Index/#setup-installation","title":"Setup &amp; Installation","text":"<ul> <li>Nanobot Quick Install &amp; Setup - Install nanobot, configure LLM provider, verify setup</li> <li>LLM Provider Setup Guide - Configure Claude, GPT, local Ollama, Qwen, and other models</li> <li>Multi-Channel Integration Guide - Set up Discord, Slack, Telegram, Feishu, or other platforms</li> </ul>"},{"location":"Master-Index/#operations-deployment","title":"Operations &amp; Deployment","text":"<ul> <li>Nanobot Build Procedure - Deploy to local or VPS (simple and advanced paths)</li> <li>AOS Startup Procedure - Bring system from power-down to fully operational</li> </ul>"},{"location":"Master-Index/#features-extensibility","title":"Features &amp; Extensibility","text":"<ul> <li>Tools &amp; Skills Reference - All built-in tools, pre-built skills, and how to create custom tools/skills</li> <li>Essential AOS Skills - Recommended pre-built skills for every deployment</li> <li>Advanced Skill Development - Create custom skills beyond pre-built capabilities; operator-injectable skills via Discord</li> </ul>"},{"location":"Master-Index/#workflows-examples","title":"Workflows &amp; Examples","text":"<ul> <li>Workflow Examples &amp; Recipes - Real-world workflows: knowledge consolidation, multi-channel posting, customer support bot, research agent, GitHub automation</li> <li>Cost Calculator &amp; Optimization Guide - Monthly cost estimation, provider routing for cost savings, budget caps and tracking</li> </ul>"},{"location":"Master-Index/#governance-policy","title":"Governance &amp; Policy","text":"<ul> <li>Governance Policies &amp; Config Examples - Role-based access control, channel allowlisting, approval workflows, escalation rules, audit logging, multi-team cost allocation</li> </ul>"},{"location":"Master-Index/#security-compliance","title":"Security &amp; Compliance","text":"<ul> <li>Nanobot Agentic Operating System Security Validation Runbook - Monthly security audit, hardening steps, incident response</li> <li>Emergency Recovery and Troubleshooting - System diagnostics, recovery procedures, troubleshooting quick reference</li> </ul>"},{"location":"Master-Index/#4-interoperability-summary","title":"4. Interoperability Summary","text":""},{"location":"Master-Index/#41-system-handshake-channel-independent","title":"4.1 System Handshake (Channel-Independent)","text":"<ol> <li>Operator sends request in any integrated channel (Discord, Slack, Telegram, Feishu, etc.) using chat interface.</li> <li>Channel Integration receives message and forwards to Nanobot via message bus event (InboundMessage).</li> <li>Agent Loop receives event; builds context: conversation history, user permissions, LLM policy, available tools.</li> <li>LLM Routing applies policy: selects model (Claude, GPT, local Ollama, etc.), enforces cost/risk constraints, prepares context.</li> <li>Tool Execution loop (up to 40 iterations):</li> <li>LLM returns tool calls (web search, file read, shell command, MCP call, spawn subagent, etc.)</li> <li>Each tool executes; results logged with request_id, tokens, latency, cost</li> <li>Tool outputs returned to LLM for next iteration</li> <li>LLM returns final response or tool error handling</li> <li>Response Composition - Nanobot formats response with citations, confidence, metadata, next steps</li> <li>Memory Logging - Structured metadata written to Obsidian: request_id, project_id, workflow_domain, tokens, cost, tools used</li> <li>Channel Output - Response posted back to original channel (Discord, Slack, Telegram, etc.) with reference links</li> </ol>"},{"location":"Master-Index/#42-shared-control-principles","title":"4.2 Shared Control Principles","text":"<ul> <li>Channel agnostic - Governance works the same regardless of communication platform.</li> <li>Least privilege - Bot and user permissions restricted to required channels/tools; operator role gates sensitive actions.</li> <li>Context isolation - Separate sessions by user; channel family prevents cross-project data leakage.</li> <li>Structured logging - All requests logged with consistent metadata for tracing, cost accounting, and compliance.</li> <li>Model routing - Cost-optimal model selection per workflow type; expensive models (Opus) reserved for high-complexity work.</li> <li>Tool constraints - Workspace-scoped filesystem, allowlist-gated shell/MCP/GitHub tools, sensitive action approvals.</li> <li>Durable audit trail - Obsidian artifacts provide replay, recovery, and compliance evidence.</li> <li>Restore drills - Periodic validation that artifacts can be replayed and systems recovered.</li> </ul>"},{"location":"Master-Index/#43-security-baseline-cross-doc","title":"4.3 Security Baseline (Cross-Doc)","text":"<ul> <li>Configuration-driven access control - Allowlist of users/channels per tool in <code>config.json</code> or environment.</li> <li>Remote access - VPS-based agent uses SSH + Tailscale tunnel OR public cloud API auth (no direct public exposure).</li> <li>Session isolation - Each user gets independent session; no cross-user context bleed.</li> <li>Workspace binding - Agent sandbox respects workspace root; cannot escape to parent directories or system files.</li> <li>MCP security - Custom auth headers supported for external tool connections; credentials stored in secrets, not code.</li> <li>Tool opt-in - Tools disabled by default; operator explicitly enables (web search, shell, MCP, etc.) per deployment.</li> <li>Monthly audit - Run <code>nanobot security audit --deep</code> to validate allowlists, disabled tools, workspace constraints, and access logs.</li> <li>Incident response - Failed security checks automatically escalate; sensitive operations require explicit approval.</li> <li>Secret management - API keys, model credentials, MCP auth stored in <code>.env</code>, never committed to version control.</li> </ul>"},{"location":"Master-Index/#5-shared-data-contract-cross-doc","title":"5. Shared Data Contract (Cross-Doc)","text":"<p>Use these fields consistently across Discord logs, LLM telemetry, and Obsidian notes: - request_id - project_id - workflow_domain - owner or requester - status - timestamp_utc - model_class and model_name (when applicable) - input_tokens / output_tokens / estimated_cost (LLM executions) - reference (link to note/runbook/output)</p> <p>Plain-English Note: Using the same core fields across systems makes tracing and recovery much faster.</p>"},{"location":"Master-Index/#6-naming-and-path-standards","title":"6. Naming and Path Standards","text":""},{"location":"Master-Index/#61-multi-channel-naming-convention","title":"6.1 Multi-Channel Naming Convention","text":"<p>Use consistent naming across all integrated channels (Discord, Slack, Telegram, Feishu, etc.) for easy operator recognition: - Product channels: <code>prd-&lt;project_id&gt;-marketing</code>, <code>prd-&lt;project_id&gt;-sales</code>, <code>prd-&lt;project_id&gt;-analytics</code> - Bookkeeping channels: <code>bk-&lt;project_id&gt;-inbox</code>, <code>bk-&lt;project_id&gt;-reconcile</code>, <code>bk-&lt;project_id&gt;-reporting</code> - Research channels: <code>res-&lt;project_id&gt;-inbox</code>, <code>res-&lt;topic&gt;</code>, <code>res-syntheses</code> - Control/Admin channels: <code>ctl-nanobot-commands</code>, <code>ctl-nanobot-alerts</code>, <code>ctl-nanobot-audit</code></p> <p>Note: Exact channel naming syntax varies by platform (Discord uses <code>#</code>, Slack uses <code>#</code>, Telegram uses group names, Feishu uses channel topics, etc.), but adopt this semantic naming across all platforms.</p>"},{"location":"Master-Index/#62-obsidian-vault-structure-v1","title":"6.2 Obsidian Vault Structure (v1)","text":"<ul> <li>02-Ideas// - Proposals, hypotheses, early-stage concepts <li>08-Research/// - Research artifacts, syntheses, cited sources <li>07-Operations/Change-Records// - Approved changes, executions, outcomes <li>07-Operations/Recovery-Drills/ - Drill evidence, restoration success logs</li> <li>00-System/AOS-Journal/ - Daily operational journaling (if journaler skill is enabled)</li> <li>00-System/Audit-Logs/ - Monthly security audit results and remediation</li>"},{"location":"Master-Index/#63-web-research-tier-mapping-channel-model-class","title":"6.3 Web Research Tier Mapping (Channel \u2192 Model Class)","text":"<p>When enabling web search (Brave API), use these tier guidelines to balance cost and depth:</p> Channel Family Research Depth Cost Tier Model Tier Notes <code>#bk-*</code> Metadata only R1 A Snippet-level financial data, no full-page retrieval <code>#prd-*-analytics</code> Bounded data R1 A Industry metrics, light competitive analysis <code>#prd-*-marketing</code> Full-page R2 B Content research, campaign analysis, limited depth <code>#res-*</code> Deep research R2 B Multi-source synthesis, citations required <code>#res-* (escalated)</code> Exhaustive R3 C Comprehensive analysis; requires Owner approval <code>#ctl-*</code> Policy-limited Restricted A only Control channel; internet access optional <p>Plain-English Note: R1 = cheap/shallow, R2 = moderate cost/depth, R3 = expensive/comprehensive. Model tier (A/B/C) controls which LLM is used; escalate to higher-cost models only for complex work.</p>"},{"location":"Master-Index/#7-raci-snapshot-who-owns-what","title":"7. RACI Snapshot (Who Owns What)","text":"Area Owner Operator Reviewer Discord channel policy Owner Operator Reviewer LLM routing and budgets Owner Operator Reviewer Obsidian metadata and retention Owner Operator Reviewer Incident response execution Owner Operator Reviewer Recovery drill governance Owner Operator Reviewer"},{"location":"Master-Index/#8-review-cadence","title":"8. Review Cadence","text":"<ul> <li>Daily: alerts, budget anomalies, failed runs.</li> <li>Weekly: KPI and cost review, blocked workflow review.</li> <li>Monthly: restore drill and policy adjustments.</li> <li>Quarterly: channel cleanup, model portfolio review, disaster drill.</li> </ul>"},{"location":"Master-Index/#8-change-management-flow","title":"8. Change Management Flow","text":"<ol> <li>Propose change in Discord change-review channel.</li> <li>Assess risk, cost impact, and rollback plan.</li> <li>Update affected docs (Discord/LLM/Obsidian/Procedure).</li> <li>Execute controlled test.</li> <li>Approve and promote to active.</li> <li>Log outcome and references in Obsidian change records.</li> </ol>"},{"location":"Master-Index/#9-interoperability-health-checklist","title":"9. Interoperability Health Checklist","text":"<ul> <li> Channel naming follows the project_id pattern.</li> <li> Each active channel family maps to an Obsidian path.</li> <li> Each workflow domain maps to a default LLM class.</li> <li> Escalation and fallback are configured and tested.</li> <li> Required shared metadata fields appear in logs/notes.</li> <li> Monthly restore drill completed with evidence.</li> <li> Gateway loopback and remote-access hardening are validated.</li> <li> DM pairing policy and allowlists are active and tested.</li> <li> Trust-boundary and sandbox policies are validated for shared channels.</li> <li> Monthly security audit findings are logged and remediated.</li> </ul>"},{"location":"Master-Index/#10-current-status-notes","title":"10. Current Status Notes","text":"<ul> <li>Document orchestration links exist across Discord, LLM, and Obsidian guides.</li> <li>Discord and Obsidian path placeholders have been aligned to project_id and vault v1 structure.</li> <li>Remaining work is execution readiness (creating starter MOCs/notes and running first drill).</li> </ul>"},{"location":"Master-Index/#11-revision-history","title":"11. Revision History","text":"Date Version Change 2026-02-25 2.0.0 Major update: Made AOS system channel-agnostic (Discord/Slack/Telegram/Feishu/etc.); documented all actual nanobot capabilities (LLM routing, tools, skills, MCP, web search, subagents, cron); updated Core Documents section with new guides; expanded security baseline to cover all deployment scenarios; clarified 3-plane governance model applies to any channel 2026-02-24 1.1.10 Added Discord Messaging Setup Guide to core docs for onboarding field collection and allowlist formatting 2026-02-24 1.1.9 Added Nanobot Onboarding Guide link for manual-mode local-gateway onboarding standard 2026-02-23 1.1.8 Added AOS Project Startup Guide for standardized new-project onboarding 2026-02-23 1.1.7 Renamed document title to \"Nanobot Agentic Operating System Master Index\" for project-name consistency 2026-02-23 1.1.6 Added explicit Nanobot orchestration-runtime role statement to Executive Summary 2026-02-23 1.1.5 Added concrete \"How it works in practice\" scenario for product campaign research-to-action flow 2026-02-23 1.1.4 Added executive summary with operating model, cost controls, security protocol overview, and small-business support examples 2026-02-23 1.1.3 Added compact R1/R2/R3 internet research tier mapping table for operator quick reference 2026-02-23 1.1.2 Added Master Index reference to LLM Internet Research Policy controls 2026-02-23 1.1.1 Added Security Validation Runbook to core document set 2026-02-23 1.1.0 Security Hardening v1: added cross-doc security baseline and enforcement checklist items 2026-02-23 1.0.0 Initial master index: interoperability map, shared contract, standards, and review cadence"},{"location":"Multi-Channel-Integration-Guide/","title":"Multi-Channel Integration Guide","text":"<p>Connect nanobot to Discord, Slack, Telegram, Feishu, or other chat platforms.</p>"},{"location":"Multi-Channel-Integration-Guide/#document-control","title":"Document Control","text":"<ul> <li>Owner:</li> <li>Version: 1.0.0</li> <li>Last Updated: 2026-02-25</li> <li>Status: Active</li> </ul>"},{"location":"Multi-Channel-Integration-Guide/#1-overview","title":"1. Overview","text":"<p>Nanobot works across 12+ chat platforms with unified governance. Same policy, security model, and memory apply regardless of which channel operators use.</p> <p>Supported Channels: Discord, Slack, Telegram, Feishu, DingTalk, WhatsApp, Email, QQ, Matrix/Element, Mochat</p>"},{"location":"Multi-Channel-Integration-Guide/#2-discord-setup-5-minutes","title":"2. Discord Setup (5 minutes)","text":""},{"location":"Multi-Channel-Integration-Guide/#step-1-create-bot-in-developer-portal","title":"Step 1: Create Bot in Developer Portal","text":"<ol> <li>Visit https://discord.com/developers/applications</li> <li>Click New Application</li> <li>Name: <code>My Nanobot</code> (or your preference)</li> <li>Go to Bot tab \u2192 Add Bot</li> <li>Copy bot TOKEN (a unique password for your bot\u2014keep it secret!)</li> </ol>"},{"location":"Multi-Channel-Integration-Guide/#step-2-configure-bot-settings","title":"Step 2: Configure Bot Settings","text":"<p>In Discord Developer Portal, under Bot: - Toggle Message Content Intent ON (required so bot can read message text) - Permissions: <code>Send Messages</code>, <code>Read Message History</code> (minimal required permissions) - Intents: <code>Message Content</code>, <code>Direct Messages</code> (events the bot should listen for)</p>"},{"location":"Multi-Channel-Integration-Guide/#step-3-invite-bot-to-server","title":"Step 3: Invite Bot to Server","text":"<ol> <li>Go to OAuth2 \u2192 URL Generator (OAuth2 = a standard way to give apps permission to access accounts)</li> <li>Select Scopes: <code>bot</code> (tells Discord: this request is for a bot)</li> <li>Select Permissions: <code>Send Messages</code>, <code>Read Message History</code> (what the bot is allowed to do)</li> <li>Copy generated URL</li> <li>Open URL, select your Discord server, authorize</li> </ol>"},{"location":"Multi-Channel-Integration-Guide/#step-4-configure-nanobot","title":"Step 4: Configure nanobot","text":"<p>Add to <code>~/.nanobot/config.json</code>: <pre><code>{\n  \"channels\": {\n    \"discord\": {\n      \"enabled\": true,\n      \"token\": \"YOUR_BOT_TOKEN\",\n      \"allowFrom\": [\"YOUR_USER_ID_HERE\"]\n    }\n  }\n}\n</code></pre></p> <p>Get your Discord User ID: In Discord, enable Developer Mode (Settings \u2192 Advanced), right-click your name, Copy User ID.</p>"},{"location":"Multi-Channel-Integration-Guide/#step-5-run-nanobot","title":"Step 5: Run nanobot","text":"<pre><code>nanobot gateway\n</code></pre> <p>Should show: <code>Discord: Connected</code></p>"},{"location":"Multi-Channel-Integration-Guide/#step-6-test","title":"Step 6: Test","text":"<p>Type in any channel the bot is in: <code>@MyNanobot hello</code></p> <p>Bot should respond.</p>"},{"location":"Multi-Channel-Integration-Guide/#3-slack-setup-5-minutes","title":"3. Slack Setup (5 minutes)","text":""},{"location":"Multi-Channel-Integration-Guide/#step-1-create-app","title":"Step 1: Create App","text":"<ol> <li>Visit https://api.slack.com/apps</li> <li>Create New App \u2192 From scratch</li> <li>App Name: <code>Nanobot</code></li> <li>Pick your workspace</li> </ol>"},{"location":"Multi-Channel-Integration-Guide/#step-2-configure-permissions-scopes","title":"Step 2: Configure Permissions (Scopes)","text":"<p>In OAuth &amp; Permissions, add these Scopes (permissions the bot needs): - <code>chat:write</code> (permission to send messages) - <code>channels:read</code> (permission to see list of channels) - <code>users:read</code> (permission to read user information) - <code>files:read</code> (permission to read files)</p>"},{"location":"Multi-Channel-Integration-Guide/#step-3-install-app","title":"Step 3: Install App","text":"<p>Click Install to Workspace \u2192 Authorize</p> <p>Copy Bot User OAuth Token (starts with <code>xoxb-</code>, this is like a password for the bot)</p>"},{"location":"Multi-Channel-Integration-Guide/#step-4-configure-nanobot_1","title":"Step 4: Configure nanobot","text":"<pre><code>{\n  \"channels\": {\n    \"slack\": {\n      \"enabled\": true,\n      \"botToken\": \"xoxb-YOUR_TOKEN\",\n      \"appToken\": \"xapp-YOUR_APP_TOKEN\",\n      \"allowFrom\": []\n    }\n  }\n}\n</code></pre> <p>Get App Token: App Level Tokens tab, create token with <code>connections:write</code> scope.</p>"},{"location":"Multi-Channel-Integration-Guide/#step-5-run-test","title":"Step 5: Run &amp; Test","text":"<pre><code>nanobot gateway\n</code></pre> <p>In a Slack channel, mention the bot: <code>@Nanobot hello</code></p>"},{"location":"Multi-Channel-Integration-Guide/#4-telegram-setup-5-minutes","title":"4. Telegram Setup (5 minutes)","text":""},{"location":"Multi-Channel-Integration-Guide/#step-1-create-bot","title":"Step 1: Create Bot","text":"<ol> <li>Open Telegram, search <code>@BotFather</code></li> <li>Send <code>/newbot</code></li> <li>Follow prompts, get TOKEN</li> </ol>"},{"location":"Multi-Channel-Integration-Guide/#step-2-configure-nanobot","title":"Step 2: Configure nanobot","text":"<pre><code>{\n  \"channels\": {\n    \"telegram\": {\n      \"enabled\": true,\n      \"token\": \"YOUR_BOT_TOKEN\",\n      \"allowFrom\": [\"YOUR_USER_ID\"]\n    }\n  }\n}\n</code></pre> <p>Get your Telegram User ID: Search <code>@userinfobot</code>, send <code>/start</code>, note your ID.</p>"},{"location":"Multi-Channel-Integration-Guide/#step-3-run-test","title":"Step 3: Run &amp; Test","text":"<pre><code>nanobot gateway\n</code></pre> <p>Message your bot on Telegram.</p>"},{"location":"Multi-Channel-Integration-Guide/#5-feishu-setup-5-minutes","title":"5. Feishu Setup (5 minutes)","text":"<p>Feishu (\u98de\u4e66) is popular in China. Uses WebSocket\u2014no public IP needed!</p>"},{"location":"Multi-Channel-Integration-Guide/#step-1-create-bot-app","title":"Step 1: Create Bot App","text":"<ol> <li>Visit https://open.feishu.cn/app</li> <li>Create App \u2192 Bot</li> <li>Get App ID and App Secret</li> </ol>"},{"location":"Multi-Channel-Integration-Guide/#step-2-configure-permissions","title":"Step 2: Configure Permissions","text":"<ul> <li>Permissions: <code>im:message</code> (send/receive messages)</li> <li>Events: <code>im.message.receive_v1</code> (Long Connection mode recommended)</li> </ul>"},{"location":"Multi-Channel-Integration-Guide/#step-3-configure-nanobot","title":"Step 3: Configure nanobot","text":"<pre><code>{\n  \"channels\": {\n    \"feishu\": {\n      \"enabled\": true,\n      \"appId\": \"cli_...\",\n      \"appSecret\": \"...\",\n      \"allowFrom\": []\n    }\n  }\n}\n</code></pre>"},{"location":"Multi-Channel-Integration-Guide/#step-4-run","title":"Step 4: Run","text":"<pre><code>nanobot gateway\n</code></pre> <p>Long Connection mode: Bot establishes WebSocket to Feishu, receives events immediately. No webhook/port forwarding needed!</p>"},{"location":"Multi-Channel-Integration-Guide/#6-multi-channel-aos-configuration","title":"6. Multi-Channel AOS Configuration","text":"<p>Enable multiple channels simultaneously with unified allowlist:</p> <pre><code>{\n  \"channels\": {\n    \"discord\": {\n      \"enabled\": true,\n      \"token\": \"...\",\n      \"allowFrom\": [\"YOUR_DISCORD_ID\"]\n    },\n    \"slack\": {\n      \"enabled\": true,\n      \"botToken\": \"...\",\n      \"allowFrom\": []\n    },\n    \"telegram\": {\n      \"enabled\": true,\n      \"token\": \"...\",\n      \"allowFrom\": [\"YOUR_TELEGRAM_ID\"]\n    }\n  }\n}\n</code></pre> <p>Same sessions, memory, and tools work across all channels!</p>"},{"location":"Multi-Channel-Integration-Guide/#7-channel-level-access-control","title":"7. Channel-Level Access Control","text":"<p>Restrict certain channels to sensitive tools:</p> <pre><code>{\n  \"channels\": {\n    \"discord\": {\n      \"allowed_tools\": {\n        \"#ctl-nanobot-commands\": [\"shell\", \"mcp\", \"github\"],\n        \"#prd-*\": [\"web\", \"file\", \"message\"],\n        \"#bk-*\": [\"file\", \"message\"],\n        \"default\": [\"web\", \"file\", \"message\"]\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"Multi-Channel-Integration-Guide/#8-multi-channel-naming-convention","title":"8. Multi-Channel Naming Convention","text":"<p>For consistency across platforms, use same channel naming:</p> Workspace Domain Discord Slack Telegram Feishu Product <code>#prd-widget-marketing</code> <code>#prd-widget-marketing</code> <code>Prd Widget Marketing</code> Product \u2192 Widget Marketing Bookkeeping <code>#bk-proj-reconcile</code> <code>#bk-proj-reconcile</code> <code>Bk Proj Reconcile</code> Bookkeeping \u2192 Proj Reconcile Research <code>#res-ai-synthesis</code> <code>#res-ai-synthesis</code> <code>Res AI Synthesis</code> Research \u2192 AI Synthesis <p>Operators recognize the same workflow context across platforms.</p>"},{"location":"Multi-Channel-Integration-Guide/#9-testing-channel-connectivity","title":"9. Testing Channel Connectivity","text":"<pre><code>nanobot doctor\n</code></pre> <p>Output shows which channels are connected: <pre><code>Discord: Connected \u2713\nSlack: Connected \u2713\nTelegram: Connected \u2713\nFeishu: Connected \u2713\n</code></pre></p>"},{"location":"Multi-Channel-Integration-Guide/#10-troubleshooting","title":"10. Troubleshooting","text":"Symptom Fix Bot offline in one channel Check token/credentials and re-authenticate Bot doesn't respond to mentions Verify Message Content Intent (Discord) or permissions (Slack) Rate limited in Slack Upgrade Slack plan or reduce message frequency Feishu not receiving messages Check Long Connection mode is enabled in Feishu app settings"},{"location":"Multi-Channel-Integration-Guide/#11-security-best-practices","title":"11. Security Best Practices","text":"<ul> <li>Never commit tokens to version control; use <code>.env</code> files</li> <li>Rotate tokens periodically (quarterly minimum)</li> <li>Use allowlists to restrict who can invoke commands</li> <li>Log all interactions via Obsidian for audit</li> <li>Monitor rate limits to catch abuse early</li> </ul>"},{"location":"Multi-Channel-Integration-Guide/#12-revision-history","title":"12. Revision History","text":"Date Version Change 2026-02-25 1.0.0 Initial guide covering Discord, Slack, Telegram, Feishu; multi-channel setup; AOS naming conventions"},{"location":"Nanobot-Build-Procedure/","title":"Nanobot Build Procedure","text":"<p>Build and configure nanobot for deployment. For simple quick-start in 5 minutes, see Nanobot Quick Install &amp; Setup.</p>"},{"location":"Nanobot-Build-Procedure/#document-control","title":"Document Control","text":"<ul> <li>Owner:</li> <li>Version: 2.0.0</li> <li>Last Updated: 2026-02-25</li> <li>Status: Active</li> </ul>"},{"location":"Nanobot-Build-Procedure/#overview","title":"Overview","text":"<p>Two deployment scenarios:</p> <ol> <li>Simple Build (5 min) - Local pip install + cloud LLM (easiest)</li> <li>Advanced Build (30 min) - VPS (Virtual Private Server) infrastructure + local Ollama inference</li> </ol> <p>This document covers nanobot build/config steps. For VPS infrastructure (Tailscale, firewall, SSH keys), see your VPS provider's setup guide.</p>"},{"location":"Nanobot-Build-Procedure/#path-a-simple-build-local-cloud-llm","title":"Path A: Simple Build (Local + Cloud LLM)","text":"<p>For: Personal/team use with OpenRouter, Anthropic, OpenAI, or compatible cloud provider. Prerequisites: Python \u22653.11, pip, internet connection Time: 5 minutes</p>"},{"location":"Nanobot-Build-Procedure/#step-1-install-nanobot","title":"Step 1: Install nanobot","text":"<pre><code># pip (Python package installer) downloads and installs nanobot\npip install nanobot-ai\n</code></pre> <p>Verify installation worked: <pre><code># nanobot version shows which version is installed (should be 0.1.4 or newer)\nnanobot version\n# Output: nanobot v0.1.4+ (or higher)\n\n# nanobot health checks if everything is set up correctly\nnanobot health\n# Output: Checking installation...\n</code></pre></p>"},{"location":"Nanobot-Build-Procedure/#step-2-initialize-config","title":"Step 2: Initialize Config","text":"<pre><code>nanobot init\n</code></pre> <p>Interactive prompt will ask: - LLM provider? \u2192 Choose cloud provider (openrouter, anthropic, openai, qwen, deepseek) - API key? \u2192 Paste from provider dashboard - Discord token? \u2192 (or Slack, Telegram\u2014choose your channel) - Default channel? \u2192 e.g., #general or DM - Obsidian vault path? \u2192 (optional; press Enter to skip)</p> <p>Config saved to: - Linux/Mac: <code>~/.nanobot/config.json</code> - Windows: <code>%APPDATA%\\nanobot\\config.json</code></p>"},{"location":"Nanobot-Build-Procedure/#step-3-test-installation","title":"Step 3: Test Installation","text":"<pre><code># nanobot test starts an interactive test session (type commands, see responses)\n# This ensures everything is working before you deploy it\nnanobot test\n</code></pre> <p>Should start interactive test mode: <pre><code>Nanobot Test Mode (type 'exit' to quit)\nLoading config: \u2713\nStarting LLM (Large Language Model) provider: openrouter \u2713\nConnected to: Discord \u2713\n\nnanobot&gt; hello\n[LLM response]\n\nnanobot&gt; web_search: python async patterns\n[web search results]\n\nnanobot&gt; exit\n</code></pre></p>"},{"location":"Nanobot-Build-Procedure/#validation-gate-a","title":"Validation Gate A","text":"<ul> <li>\u2713 <code>nanobot version</code> returns v0.1.4+</li> <li>\u2713 <code>nanobot init</code> completes without errors</li> <li>\u2713 Config file exists and is valid JSON</li> <li>\u2713 <code>nanobot test</code> returns responses from LLM</li> <li>\u2713 Web search, tool execution work in test mode</li> </ul>"},{"location":"Nanobot-Build-Procedure/#deployment-simple-build","title":"Deployment: Simple Build","text":"<p>Once validated, start the gateway:</p> <pre><code>nanobot gateway\n</code></pre> <p>Nanobot will now listen to Discord, Slack, or other configured channels and respond to messages.</p> <p>To run in background (Linux/Mac): <pre><code># The &amp; symbol means \"run this command in the background\"\n# This lets you keep using the terminal while nanobot runs\nnanobot gateway &amp;\n# Or use systemd (see Advanced Build)\n</code></pre></p> <p>To run in background (Windows): Use Task Scheduler or Windows Service installer: <pre><code>nanobot install-service\n# Then: Net Start Nanobot\n</code></pre></p>"},{"location":"Nanobot-Build-Procedure/#path-b-advanced-build-vps-local-ollama","title":"Path B: Advanced Build (VPS + Local Ollama)","text":"<p>For: Self-hosted inference, privacy-critical workflows, cost optimization with local models. Architecture: VPS (Virtual Private Server) (gateway + routing) \u2194\ufe0f Local machine (Ollama inference) via Tailscale-encrypted tunnel Time: ~30 minutes for build; ~15 minutes for startup Prerequisites: VPS access, local machine with Ollama, Tailscale account</p>"},{"location":"Nanobot-Build-Procedure/#prerequisites-checklist","title":"Prerequisites Checklist","text":"<ul> <li> VPS (Virtual Private Server) deployed (Ubuntu 22.04+ recommended)</li> <li> SSH (Secure Shell) access to VPS</li> <li> Local machine with Ollama installed (Windows/Mac/Linux)</li> <li> Tailscale account (free tier OK)</li> <li> Discord/Slack token ready</li> <li> API keys for fallback provider (OpenRouter recommended)</li> </ul>"},{"location":"Nanobot-Build-Procedure/#phase-a-vps-preparation-15-min","title":"Phase A: VPS Preparation (15 min)","text":""},{"location":"Nanobot-Build-Procedure/#step-1-connect-to-vps","title":"Step 1: Connect to VPS","text":"<pre><code># ssh (Secure Shell) is how you remotely access a server\n# Replace your-vps-user (e.g., 'ubuntu') and your-vps-ip (e.g., '192.168.1.100')\nssh your-vps-user@your-vps-ip\n# Or configure SSH key for passwordless access\n</code></pre>"},{"location":"Nanobot-Build-Procedure/#step-2-system-updates","title":"Step 2: System Updates","text":"<pre><code># apt is the package manager for Ubuntu (like 'store' for software)\n# update checks for new versions of everything\n# upgrade installs those new versions\n# -y means \"yes automatically, don't ask\"\nsudo apt update &amp;&amp; sudo apt upgrade -y\n\n# Install programs nanobot needs (Python, build tools, etc.)\n# &amp;&amp; means \"if that worked, then run this next command\"\nsudo apt install -y python3.11 python3.11-venv python3-pip build-essential\n</code></pre>"},{"location":"Nanobot-Build-Procedure/#step-3-install-tailscale","title":"Step 3: Install Tailscale","text":"<pre><code># curl -fsSL downloads and runs the Tailscale installer script\n# | sh pipes (sends) the output to shell to execute it\ncurl -fsSL https://tailscale.com/install.sh | sh\n\n# Start Tailscale (secure network tunnel)\n# This creates an encrypted connection between your machines\nsudo tailscale up\n# Will print auth URL; open in browser; authenticate\n</code></pre> <p>After auth, note your VPS Tailscale IP (e.g., <code>100.87.123.45</code>). Print it: <pre><code># Show your Tailscale IP address (the address other machines will use to find you)\ntailscale ip -4\n</code></pre></p>"},{"location":"Nanobot-Build-Procedure/#step-4-create-nanobot-user-optional-but-recommended","title":"Step 4: Create nanobot User (Optional but Recommended)","text":"<pre><code># useradd -m creates a new user account named 'nanobot'\n# -s /bin/bash sets bash as the default shell\nsudo useradd -m -s /bin/bash nanobot\n\n# su - nanobot \"switches user\" to nanobot (logs in as that user)\nsudo su - nanobot\n# Now running as nanobot user for isolation\n</code></pre>"},{"location":"Nanobot-Build-Procedure/#validation-vps-ready","title":"Validation: VPS Ready","text":"<ul> <li>\u2713 SSH access works</li> <li>\u2713 Python 3.11+ installed</li> <li>\u2713 Tailscale running and connected</li> <li>\u2713 Nanobot user created (optional)</li> </ul>"},{"location":"Nanobot-Build-Procedure/#phase-b-local-ollama-configuration-10-min","title":"Phase B: Local Ollama Configuration (10 min)","text":"<p>On your local machine (where Ollama will run):</p>"},{"location":"Nanobot-Build-Procedure/#step-1-install-ollama","title":"Step 1: Install Ollama","text":"<p>Download from: https://ollama.ai</p>"},{"location":"Nanobot-Build-Procedure/#step-2-set-ollama-listen-address","title":"Step 2: Set Ollama Listen Address","text":"<p>Allow remote connections via Tailscale. Edit Ollama systemd unit or set environment:</p> <p>Linux/Mac: <pre><code>export OLLAMA_HOST=0.0.0.0:11434\nollama serve\n</code></pre></p> <p>Windows: <pre><code>setx OLLAMA_HOST 0.0.0.0:11434\n# Restart Ollama from system tray\n</code></pre></p>"},{"location":"Nanobot-Build-Procedure/#step-3-connect-tailscale-locally","title":"Step 3: Connect Tailscale Locally","text":"<pre><code>tailscale up\n# Note your local Tailscale IP (e.g., 100.123.45.67)\ntailscale ip -4\n</code></pre>"},{"location":"Nanobot-Build-Procedure/#step-4-install-model","title":"Step 4: Install Model","text":"<pre><code>ollama pull qwen2:latest\n# Or: ollama pull llama2, mistral, neural-chat, etc.\n</code></pre>"},{"location":"Nanobot-Build-Procedure/#step-5-test-local-ollama","title":"Step 5: Test Local Ollama","text":"<pre><code>curl http://localhost:11434/api/tags\n# Should return JSON with model list\n</code></pre>"},{"location":"Nanobot-Build-Procedure/#validation-ollama-ready","title":"Validation: Ollama Ready","text":"<ul> <li>\u2713 Ollama running</li> <li>\u2713 Tailscale connected locally</li> <li>\u2713 Model downloaded</li> <li>\u2713 Local curl responds with model list</li> </ul>"},{"location":"Nanobot-Build-Procedure/#phase-c-tailscale-tunnel-validation-5-min","title":"Phase C: Tailscale Tunnel Validation (5 min)","text":"<p>From VPS, test reaching local Ollama through Tailscale:</p> <pre><code># SSH into VPS\nssh your-vps-user@your-vps-ip\n\n# Test connectivity (replace 100.123.45.67 with your local Tailscale IP)\ncurl http://100.123.45.67:11434/api/tags\n# Should return JSON model list\n</code></pre> <p>If failed: - Verify Ollama listening on <code>0.0.0.0:11434</code> (not just <code>localhost</code>) - Check local firewall allows port 11434 - Verify both machines on same Tailscale network - Restart Tailscale on both sides</p>"},{"location":"Nanobot-Build-Procedure/#validation-tunnel-ready","title":"Validation: Tunnel Ready","text":"<ul> <li>\u2713 VPS can curl to local Ollama endpoint</li> <li>\u2713 Response includes model names</li> </ul>"},{"location":"Nanobot-Build-Procedure/#phase-d-nanobot-installation-vps","title":"Phase D: Nanobot Installation (VPS)","text":"<p>On VPS:</p>"},{"location":"Nanobot-Build-Procedure/#step-1-install-nanobot_1","title":"Step 1: Install nanobot","text":"<pre><code>pip install nanobot-ai\nnanobot version\n# Should print: nanobot v0.1.4+\n</code></pre>"},{"location":"Nanobot-Build-Procedure/#step-2-create-config-file","title":"Step 2: Create Config File","text":"<pre><code># Create config directory\nmkdir -p ~/.nanobot\nnano ~/.nanobot/config.json\n</code></pre> <p>Minimal config for ollama + discord: <pre><code>{\n  \"llm\": {\n    \"provider\": \"ollama\",\n    \"model\": \"qwen2:latest\",\n    \"endpoint\": \"http://100.123.45.67:11434\",\n    \"fallback_provider\": \"openrouter\",\n    \"fallback_key\": \"sk-or-xxxxx\"\n  },\n  \"channels\": {\n    \"discord\": {\n      \"enabled\": true,\n      \"token\": \"your-discord-bot-token\"\n    }\n  },\n  \"skills\": {\n    \"obsidian\": {\n      \"enabled\": true,\n      \"vault_path\": \"/path/to/obsidian/vault\"\n    }\n  }\n}\n</code></pre></p> <p>Key values: - <code>endpoint</code>: Use local Tailscale IP (e.g., <code>http://100.123.45.67:11434</code>) - <code>discord.token</code>: Get from Discord Developer Portal - <code>vault_path</code>: Absolute path to Obsidian vault (if applicable) - <code>fallback_key</code>: OpenRouter API key for fallback when Ollama down</p>"},{"location":"Nanobot-Build-Procedure/#step-3-test-configuration","title":"Step 3: Test Configuration","text":"<pre><code>nanobot health\n# Output should show: ollama \u2713 connected, discord \u2713 ready\n</code></pre>"},{"location":"Nanobot-Build-Procedure/#validation-nanobot-config-valid","title":"Validation: Nanobot Config Valid","text":"<ul> <li>\u2713 Config file parses (valid JSON)</li> <li>\u2713 <code>nanobot health</code> shows all components connected</li> <li>\u2713 Ollama endpoint reachable from VPS</li> </ul>"},{"location":"Nanobot-Build-Procedure/#phase-e-systemd-service-optional-but-recommended","title":"Phase E: Systemd Service (Optional but Recommended)","text":"<p>To auto-start nanobot on VPS reboot:</p>"},{"location":"Nanobot-Build-Procedure/#step-1-create-service-file","title":"Step 1: Create Service File","text":"<pre><code>sudo nano /etc/systemd/system/nanobot.service\n</code></pre> <p>Paste: <pre><code>[Unit]\nDescription=Nanobot Agentic Operating System\nAfter=network.target\n\n[Service]\nType=simple\nUser=nanobot\nWorkingDirectory=/home/nanobot\nExecStart=/usr/bin/python3 -m nanobot.gateway\nRestart=on-failure\nRestartSec=10\nEnvironment=\"PATH=/home/nanobot/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin\"\n\n[Install]\nWantedBy=multi-user.target\n</code></pre></p>"},{"location":"Nanobot-Build-Procedure/#step-2-enable-start","title":"Step 2: Enable &amp; Start","text":"<pre><code>sudo systemctl daemon-reload\nsudo systemctl enable nanobot\nsudo systemctl start nanobot\nsudo systemctl status nanobot\n# Should show: active (running)\n</code></pre>"},{"location":"Nanobot-Build-Procedure/#step-3-view-logs","title":"Step 3: View Logs","text":"<pre><code>sudo journalctl -u nanobot -f\n# Ctrl+C to exit\n</code></pre>"},{"location":"Nanobot-Build-Procedure/#phase-f-startup-validation-full-end-to-end-test","title":"Phase F: Startup Validation (Full End-to-End Test)","text":"<p>Follow AOS Startup Procedure (Path B section) for detailed startup testing.</p> <p>Quick version: 1. Local machine: Start Ollama (<code>ollama serve</code>) 2. VPS: Start nanobot (<code>nanobot gateway</code> or <code>systemctl start nanobot</code>) 3. Discord: Send test message <code>@BotName hello</code> 4. Expected: Response from local Ollama model (via Tailscale tunnel)</p>"},{"location":"Nanobot-Build-Procedure/#cost-performance-reference","title":"Cost &amp; Performance Reference","text":"Component Resource Cost Performance Notes Local Inference (Ollama) 1x GPU/CPU Latency 2-10s Fine for async workflows; not real-time chat Cloud LLM (OpenRouter) $0.001-0.01 per msg Latency &lt;1s Fast; pay per request; good for hybrid VPS (minimal) $5-20/month Constant Tailscale ingress is free; only covers VPS uptime Total (Advanced) VPS + Cloud fallback Best UX Ollama primary; cloud as fallback if local down"},{"location":"Nanobot-Build-Procedure/#post-build-verification-checklist","title":"Post-Build Verification Checklist","text":"<p>After build completion:</p> <ul> <li> <code>nanobot version</code> returns v0.1.4+</li> <li> Config file exists at expected location</li> <li> <code>nanobot health</code> all components green</li> <li> Test message in Discord/Slack gets response</li> <li> Tool execution works (web_search, file operations)</li> <li> Obsidian write-back functional (if enabled)</li> <li> Systemd service auto-restarts on crash (advanced only)</li> <li> Cost tracking working (tokens logged, cost estimated)</li> </ul>"},{"location":"Nanobot-Build-Procedure/#troubleshooting-build-issues","title":"Troubleshooting Build Issues","text":"Problem Symptom Solution Python version mismatch <code>Error: nanobot-ai requires Python \u22653.11</code> <code>python3 --version</code>; upgrade Python; use <code>python3.11</code> explicitly Config parsing error <code>Config validation failed: ...</code> Use JSON validator (jsonlint); check quote marks and commas Ollama unreachable <code>Ollama connection refused</code> Verify Ollama running; check endpoint URL; verify Tailscale tunnel Discord token invalid <code>Discord authentication failed</code> Re-generate token in Developer Portal; verify it's bot token, not user token Dependency conflict <code>pip install nanobot-ai</code> fails Clean environment: <code>pip install --upgrade pip setuptools wheel</code> then retry"},{"location":"Nanobot-Build-Procedure/#build-paths-decision-tree","title":"Build Paths Decision Tree","text":"<pre><code>Are you okay with API costs (OpenRouter/Anthropic/OpenAI)?\n\u251c\u2500 YES \u2192 Use Simple Build (Path A)\n\u2502        5 minutes to deployment\n\u2502        Cost: $0.01-0.10 per conversation\n\u2502        Easiest for teams\n\u2502\n\u2514\u2500 NO \u2192 Are you willing to manage VPS + Ollama?\n         \u251c\u2500 YES \u2192 Use Advanced Build (Path B)\n         \u2502        30 minutes setup\n         \u2502        Cost: $5-20/month VPS + cloud fallback\n         \u2502        Best for privacy/control\n         \u2502\n         \u2514\u2500 NO \u2192 Use Simple Build anyway\n                  OpenRouter is cheapest cloud option\n                  Fallback to free Ollama if costs high\n</code></pre>"},{"location":"Nanobot-Build-Procedure/#revision-history","title":"Revision History","text":"Date Version Changes 2026-02-25 2.0.0 Complete rewrite: Split simple (Path A: pip install) vs. advanced (Path B: VPS+Ollama); removed npm/pnpm references; added systemd examples; added Tailscale tunnel validation; reduced from 796 to ~400 lines Previous 1.1.0 Monolithic VPS-focused build procedure"},{"location":"Nanobot-Quick-Install-Setup/","title":"Nanobot Quick Install &amp; Setup","text":"<p>Start here if you're new to nanobot. This guide gets you a working AI assistant in 5 minutes.</p>"},{"location":"Nanobot-Quick-Install-Setup/#document-control","title":"Document Control","text":"<ul> <li>Owner:</li> <li>Version: 1.0.0  </li> <li>Last Updated: 2026-02-25</li> <li>Status: Active</li> </ul>"},{"location":"Nanobot-Quick-Install-Setup/#1-objective","title":"1. Objective","text":"<p>Get nanobot installed, configured with an LLM provider, and working end-to-end in minimal time.</p>"},{"location":"Nanobot-Quick-Install-Setup/#2-quick-prerequisites","title":"2. Quick Prerequisites","text":"<ul> <li>Python 3.11+ installed</li> <li>An LLM API key (or local Ollama running)</li> <li>Intending to use CLI, Discord, Slack, or another channel</li> </ul>"},{"location":"Nanobot-Quick-Install-Setup/#3-install-2-minutes","title":"3. Install (2 minutes)","text":""},{"location":"Nanobot-Quick-Install-Setup/#option-a-via-pip-recommended","title":"Option A: via pip (Recommended)","text":"<pre><code>pip install nanobot-ai\n</code></pre>"},{"location":"Nanobot-Quick-Install-Setup/#option-b-via-uv-fast","title":"Option B: via uv (Fast)","text":"<pre><code>uv tool install nanobot-ai\n</code></pre>"},{"location":"Nanobot-Quick-Install-Setup/#option-c-from-source","title":"Option C: From source","text":"<pre><code>git clone https://github.com/HKUDS/nanobot.git\ncd nanobot\npip install -e .\n</code></pre>"},{"location":"Nanobot-Quick-Install-Setup/#4-first-run-interactive-setup-2-minutes","title":"4. First Run: Interactive Setup (2 minutes)","text":"<pre><code>nanobot onboard\n</code></pre> <p>This launches an interactive wizard. Answer these key questions:</p> Question Answer API key or local? Paste your API key (e.g., OpenRouter, OpenAI, Anthropic) OR leave blank for local Ollama Which channels? Choose Discord, Slack, Telegram, Feishu, or CLI (local chat) Model to start with? anthropic/claude-opus-4-5 (via OpenRouter) OR llama2 (local) <p>The wizard creates <code>~/.nanobot/config.json</code> with your choices.</p>"},{"location":"Nanobot-Quick-Install-Setup/#5-test-it-1-minute","title":"5. Test It (1 minute)","text":""},{"location":"Nanobot-Quick-Install-Setup/#cli-test-easiest","title":"CLI Test (Easiest)","text":"<p><pre><code>nanobot agent\n</code></pre> Type a question. Hit Enter. You should get a response.</p>"},{"location":"Nanobot-Quick-Install-Setup/#discordslacktelegram-test","title":"Discord/Slack/Telegram Test","text":"<p>The wizard output shows your bot token and setup instructions for your chosen channel. Paste the token into Discord/Slack/etc. settings, then send a message in a channel the bot is in.</p>"},{"location":"Nanobot-Quick-Install-Setup/#6-next-steps","title":"6. Next Steps","text":"<p>For AOS-style governance: - See LLM Provider Setup Guide for multiple model routing - See Multi-Channel Integration Guide for channel policies - See Tools &amp; Skills Reference for what nanobot can do</p> <p>For advanced (VPS + Ollama + Tailscale): - See Nanobot Build Procedure</p>"},{"location":"Nanobot-Quick-Install-Setup/#7-common-issues","title":"7. Common Issues","text":"Symptom Fix <code>ModuleNotFoundError: nanobot</code> Reinstall: <code>pip install nanobot-ai --force-reinstall</code> API key rejected Verify key format and expiry in your API provider dashboard No response in CLI Check internet connection and model availability Discord bot offline Paste correct bot token and check Message Content Intent is enabled"},{"location":"Nanobot-Quick-Install-Setup/#8-what-nanobot-can-do-out-of-the-box","title":"8. What Nanobot Can Do (Out of the Box)","text":"<p>\u2705 Web Search - Real-time information via Brave API \u2705 File Ops - Read, write, edit files (workspace-scoped) \u2705 Shell - Execute commands (with allowlist) \u2705 GitHub - Search repos, manage PRs/issues \u2705 Scheduling - Run tasks on cron schedule \u2705 Memory - Remember conversation context \u2705 MCP Tools - Integrate external services  </p> <p>See Tools &amp; Skills Reference for details.</p>"},{"location":"Nanobot-Quick-Install-Setup/#9-revision-history","title":"9. Revision History","text":"Date Version Change 2026-02-25 1.0.0 Initial quick-install guide for nanobot v0.1.4+"},{"location":"Security-Validation-Runbook/","title":"Nanobot Agentic Operating System Security Validation Runbook","text":""},{"location":"Security-Validation-Runbook/#1-purpose","title":"1. Purpose","text":"<p>This runbook defines the recurring security validation steps for the Nanobot Agentic Operating System.</p>"},{"location":"Security-Validation-Runbook/#2-frequency-and-ownership","title":"2. Frequency and Ownership","text":"<ul> <li>Frequency: Monthly (minimum), and after major config changes</li> <li>Owner: Security/Platform Owner</li> <li>Operator: Assigned Operator</li> <li>Reviewer: Assigned Reviewer</li> </ul>"},{"location":"Security-Validation-Runbook/#3-preconditions","title":"3. Preconditions","text":"<ul> <li>Access to gateway host</li> <li>Access to Discord server settings</li> <li>Access to Nanobot config and logs</li> <li>Access to Obsidian operational records</li> </ul>"},{"location":"Security-Validation-Runbook/#4-validation-sequence","title":"4. Validation Sequence","text":"<p>Execute in this order to ensure consistent evidence collection.</p>"},{"location":"Security-Validation-Runbook/#step-1-gateway-exposure-check","title":"Step 1: Gateway Exposure Check","text":"<ul> <li>Verify gateway bind is loopback-only. (Loopback = only accessible from this computer)</li> <li>Confirm no unintended public bind (0.0.0.0\u2014which means \"accessible to the whole internet\") is active.</li> <li>Validate remote access path is SSH (Secure Shell\u2014encrypted remote access) tunnel or Tailscale network-based.</li> <li>Validate Ollama on local Windows host is reachable from VPS (Virtual Private Server) only via trusted Tailscale path and is not publicly exposed.</li> </ul> <p>Pass Criteria - Gateway is loopback-bound and remote access is controlled.</p> <p>Fail Criteria - Any direct public exposure without approved exception.</p>"},{"location":"Security-Validation-Runbook/#step-2-dm-policy-and-allowlist-check","title":"Step 2: DM Policy and Allowlist Check","text":"<ul> <li>Verify DM (Direct Message\u2014private messages to the bot) policy is pairing mode by default.</li> <li>Validate unknown sender behavior (no command execution before approval).</li> <li>Verify allowlist entries are current and minimal. (Allowlist = list of approved people/channels)</li> </ul> <p>Pass Criteria - DM pairing flow works and allowlist scope is least-privilege.</p>"},{"location":"Security-Validation-Runbook/#step-3-trust-boundary-check","title":"Step 3: Trust Boundary Check","text":"<ul> <li>Confirm no mutually untrusted operator groups share one gateway trust boundary.</li> <li>Validate separation model (separate gateway/host/OS user) where required.</li> </ul> <p>Pass Criteria - Trust boundaries are documented and enforced.</p>"},{"location":"Security-Validation-Runbook/#step-4-sandbox-policy-check","title":"Step 4: Sandbox Policy Check","text":"<ul> <li>Verify non-main/shared channels run under sandbox profile where required.</li> <li>Confirm high-risk tools are not broadly exposed in shared contexts.</li> </ul> <p>Pass Criteria - Sandbox rules match policy for shared/non-main sessions.</p>"},{"location":"Security-Validation-Runbook/#step-5-security-audit-execution","title":"Step 5: Security Audit Execution","text":"<ul> <li>Run <code>nanobot security audit --deep</code> (automated security check for vulnerabilities)</li> <li>Verify deployed Nanobot version is 2026.2.23 or later. (Newer versions have security fixes)</li> <li>Review latest Nanobot security advisories and confirm no unpatched High/Critical findings apply to deployed version.</li> <li>Capture findings and classify severity. (Severity = how serious the issue is)</li> <li>Confirm critical findings have immediate mitigation plan.</li> </ul> <p>Pass Criteria - No unresolved critical findings. - Deployed version is at or above the current patched minimum for published advisories.</p>"},{"location":"Security-Validation-Runbook/#step-6-secrets-and-token-hygiene","title":"Step 6: Secrets and Token Hygiene","text":"<ul> <li>Confirm tokens/secrets are in .env (configuration file with secrets\u2014NOT shared in code) or approved secret store only.</li> <li>Confirm no secrets (API keys, passwords) are present in notes, docs, or source-controlled config.</li> <li>Validate token rotation readiness and last rotation date. (Rotation = changing tokens regularly, like changing passwords)</li> </ul> <p>Pass Criteria - Secret handling policy is fully compliant.</p>"},{"location":"Security-Validation-Runbook/#step-7-logging-and-evidence-integrity","title":"Step 7: Logging and Evidence Integrity","text":"<ul> <li>Confirm required telemetry fields exist (request_id, project_id, workflow_domain, status, timestamps, model/cost fields where applicable).</li> <li>Confirm incident and change records are persisted to Obsidian.</li> </ul> <p>Pass Criteria - Security-relevant logs are complete and traceable end-to-end.</p>"},{"location":"Security-Validation-Runbook/#5-evidence-to-capture","title":"5. Evidence to Capture","text":"<ul> <li>Command output snippets (including security audit)</li> <li>Nanobot version output (Nanobot --version) and advisory review date</li> <li>Config screenshots or sanitized config excerpts</li> <li>Allowlist review record</li> <li>Sandbox policy verification record</li> <li>Remediation tickets with owners and due dates</li> </ul>"},{"location":"Security-Validation-Runbook/#6-remediation-sla","title":"6. Remediation SLA","text":"<ul> <li>Critical: immediate containment + fix plan same day</li> <li>High: remediation within 7 days</li> <li>Medium: remediation within 30 days</li> <li>Low: backlog with documented rationale</li> </ul>"},{"location":"Security-Validation-Runbook/#7-runbook-output-record-template","title":"7. Runbook Output Record Template","text":"<pre><code># Security Validation Report - &lt;YYYY-MM-DD&gt;\n- Run ID:\n- Owner:\n- Operator:\n- Reviewer:\n- Environment:\n\n## Results by Step\n1. Gateway Exposure Check: Pass/Fail\n2. DM Policy and Allowlist Check: Pass/Fail\n3. Trust Boundary Check: Pass/Fail\n4. Sandbox Policy Check: Pass/Fail\n5. Security Audit Execution: Pass/Fail\n6. Secrets and Token Hygiene: Pass/Fail\n7. Logging and Evidence Integrity: Pass/Fail\n\n## Findings\n- Critical:\n- High:\n- Medium:\n- Low:\n\n## Remediation Plan\n- Item:\n  - Owner:\n  - Due Date:\n  - Status:\n\n## Final Decision\n- Overall Status: Pass / Conditional Pass / Fail\n- Next Review Date:\n</code></pre>"},{"location":"Security-Validation-Runbook/#8-gono-go-rule","title":"8. Go/No-Go Rule","text":"<ul> <li>Go: all critical controls pass and no unresolved critical findings.</li> <li>No-Go: any unresolved critical finding or trust-boundary violation.</li> </ul>"},{"location":"Security-Validation-Runbook/#9-related-documents","title":"9. Related Documents","text":"<ul> <li>Nanobot Build Procedure</li> <li>Master Index</li> <li>Tools &amp; Skills Reference</li> <li>Governance Policies &amp; Config Examples</li> </ul>"},{"location":"Security-Validation-Runbook/#10-revision-history","title":"10. Revision History","text":"Date Version Change 2026-02-24 1.1.1 Added explicit Nanobot minimum patched-version check and latest-advisory verification step 2026-02-24 1.1.0 Added explicit Windows-host Ollama exposure validation to Step 1 for native-Windows inference architecture alignment 2026-02-23 1.0.0 Initial monthly security validation runbook for Nanobot Agentic Operating System"},{"location":"Tools-and-Skills-Reference/","title":"Tools &amp; Skills Reference","text":"<p>Complete reference for all built-in tools and pre-built skills in nanobot, plus how to create custom tools/skills.</p>"},{"location":"Tools-and-Skills-Reference/#document-control","title":"Document Control","text":"<ul> <li>Owner:</li> <li>Version: 1.0.0</li> <li>Last Updated: 2026-02-25</li> <li>Status: Active</li> </ul>"},{"location":"Tools-and-Skills-Reference/#1-tools-overview","title":"1. Tools Overview","text":"<p>Tools are the executable actions nanobot can perform. All tools are opt-in and can be allowlisted (approved) per channel.</p> <p>What's a Tool? Like an extension or app\u2014it's a single action the bot can do (search the web, write a file, run a command, etc.)</p>"},{"location":"Tools-and-Skills-Reference/#quick-tool-matrix","title":"Quick Tool Matrix","text":"Tool Purpose Risk Tier Notes web_search Real-time web search (Brave API) Low Requires Brave API key web_fetch Retrieve &amp; parse full web pages Low Limited by rate limits &amp; context file_read Read files (workspace-scoped) Low Sandbox-enforced; no parent dir escape file_write Create/overwrite files Medium Audit-logged; idempotent support file_edit Edit specific lines in files Medium Line-based for precision; audit-logged file_list List directory contents Low Only workspace-visible directories shell_exec Execute shell commands High Operator-restricted; all commands logged message_send Send alerts/notifications Low Cross-channel notifications possible mcp_call Call MCP server tools High Custom auth headers supported cron_schedule Schedule recurring tasks Medium Cron syntax; can be expensive at scale subagent_spawn Launch parallel agents High Spawned agents have own context/memory github_search Search GitHub repos Low No auth needed; public access github_pr_create Create pull requests High Requires GitHub token; write access github_action_trigger Trigger workflows High Requires org/repo permissions"},{"location":"Tools-and-Skills-Reference/#2-tool-details-configuration","title":"2. Tool Details &amp; Configuration","text":""},{"location":"Tools-and-Skills-Reference/#web_search","title":"web_search","text":"<p>Purpose: Real-time search via Brave Search API Required API Key: Yes (Brave) Cost: ~$0.01-0.05 per search Config: <pre><code>{\n  \"braveApiKey\": \"YOUR_BRAVE_KEY\"\n}\n</code></pre> Usage: <code>nanobot: \"Find 3 articles about AI safety from this week\"</code></p>"},{"location":"Tools-and-Skills-Reference/#web_fetch","title":"web_fetch","text":"<p>Purpose: Download and parse web pages full-text Required API Key: No Cost: None Config: Built-in, no config needed Usage: <code>nanobot: \"Summarize this page: https://example.com/article\"</code></p>"},{"location":"Tools-and-Skills-Reference/#file_read-file_write-file_edit-file_list","title":"file_read / file_write / file_edit / file_list","text":"<p>Purpose: Access workspace files Workspace Scope: All paths are relative to agent workspace (e.g., <code>~/.nanobot/workspace/</code>) Security: Cannot escape workspace root (e.g., cannot read <code>/etc/passwd</code>) Config: No special config; enabled by default with workspace binding Usage Examples: <pre><code>\"Read the project README\"\n\"Create a deployment checklist in deploy-checklist.md\"\n\"Update line 10 in config.json to set debug=true\"\n\"List all Python files in src/\"\n</code></pre></p>"},{"location":"Tools-and-Skills-Reference/#shell_exec","title":"shell_exec","text":"<p>Purpose: Execute OS commands Risk Tier: High Restrictions: - Only operators with explicit allowlist can invoke - All commands logged with timestamp, operator, exit code, output - Dangerous commands (rm -rf /, sudo) can be blocklisted Config: <pre><code>{\n  \"tools\": {\n    \"shell\": {\n      \"enabled\": true,\n      \"allowFrom\": [\"USER_ID_1\", \"USER_ID_2\"],\n      \"timeout\": 30,\n      \"blocklist\": [\"rm -rf\", \"sudo dd\"]\n    }\n  }\n}\n</code></pre> Usage: <code>nanobot: \"Deploy the latest build: make deploy\"</code></p>"},{"location":"Tools-and-Skills-Reference/#message_send","title":"message_send","text":"<p>Purpose: Send cross-channel alerts, escalations, notifications Config: Built-in Usage Examples: <pre><code>\"Alert team in #incidents that model latency &gt; 5s\"\n\"Send daily summary to #ops-digest\"\n\"Notify owner in #alerts about high spend ($50/day)\"\n</code></pre></p>"},{"location":"Tools-and-Skills-Reference/#mcp_call","title":"mcp_call","text":"<p>Purpose: Call MCP (Model Context Protocol\u2014a standard way to connect tools/services) server tools Purpose: Call externally hosted MCP (Model Context Protocol) tools Examples of MCP Tools:  - Filesystem operations on remote systems - Database queries - API calls to internal services - Custom business logic tools Config: <pre><code>{\n  \"mcpServers\": {\n    \"mydb\": {\n      \"command\": \"python\",\n      \"args\": [\"/path/to/db_mcp_server.py\"],\n      \"customHeaders\": {\n        \"Authorization\": \"Bearer YOUR_TOKEN\"\n      }\n    }\n  }\n}\n</code></pre> Docs: https://modelcontextprotocol.io</p>"},{"location":"Tools-and-Skills-Reference/#cron_schedule","title":"cron_schedule","text":"<p>Purpose: Schedule tasks to run on recurring schedule Syntax: Standard cron (minute hour day month weekday) Examples: <pre><code>\"0 9 * * 1-5\" \u2192 Every weekday at 9 AM\n\"0 * * * *\" \u2192 Every hour\n\"*/15 * * * *\" \u2192 Every 15 minutes\n\"0 23 * * *\" \u2192 Daily at 11 PM\n</code></pre> Config: No special config; enabled via Cron skill Usage: <code>nanobot: \"Schedule a daily digest at 23:50 every day\"</code></p>"},{"location":"Tools-and-Skills-Reference/#subagent_spawn","title":"subagent_spawn","text":"<p>Purpose: Launch independent agents for parallel work Use Cases:  - Parallel research across multiple sources - Delegated tasks (e.g., \"research this, fix that, monitor that\") - Complex multi-step workflows - Fact-checking and verification sub-processes Config: No special config; built-in Usage: <pre><code>\"Spawn 3 agents to each research a different competitor, then synthesize findings\"\n\"Spawn agent to monitor GitHub repo for issues while you work on design doc\"\n</code></pre></p>"},{"location":"Tools-and-Skills-Reference/#sub-agent-orchestration-advanced-pattern","title":"Sub-Agent Orchestration (Advanced Pattern)","text":"<p>Modern deployments use Agent Orchestration to decompose complex tasks into specialized sub-agents:</p> <p>Architecture:</p> Component Role Model Priority Focus Manager Agent Primary orchestrator Fast (e.g., Sonnet) Planning, coordination, synthesis Fact-Checker Sub-Agent Verification &amp; auditing Smart (e.g., local 70B) Technical accuracy, hallucination detection Researcher Sub-Agent Information gathering Fast (e.g., 8B) Web search, data collection <p>Example Workflow:</p> <pre><code>User: \"Research competitors and tell me 3 novel features we could implement\"\n\n1. Manager Agent receives request\n2. Manager spawns Researcher: \"Find top 5 competitors in our space\"\n3. Manager spawns Analyzer: \"Extract novel features from their product\"\n4. Manager spawns Fact-Checker: \"Verify these features are real and current\"\n5. Manager synthesizes: \"Here are 3 novel features we don't have yet\"\n</code></pre> <p>Configuration:</p> <pre><code>{\n  \"orchestration\": {\n    \"maxSpawnDepth\": 2,\n    \"maxConcurrentAgents\": 5,\n    \"costCeiling\": 5.00,\n    \"subagentDefaults\": {\n      \"model_fast\": \"qwen-2-72b\",\n      \"model_smart\": \"claude-opus\",\n      \"timeout_seconds\": 300\n    }\n  }\n}\n</code></pre> <p>Safety Controls:</p> <ul> <li>maxSpawnDepth: Prevents infinite recursion (agents spawning agents spawning agents...)</li> <li>maxConcurrentAgents: Limits parallel spawns to prevent resource exhaustion</li> <li>costCeiling: Daily budget cap for sub-agent API calls</li> <li>timeout_seconds: Hard kill timeout for stuck sub-agents</li> </ul> <p>Manual Invocation (Discord/Slack):</p> <pre><code>@BotName spawn fact-checker to verify: \"The RTX 4090 has 24GB VRAM\"\n\n\u2192 Creates isolated agent with:\n   - Access to web search + knowledge base\n   - Specific verification prompt\n   - Confidence scoring\n   - Source citations\n\nResult: \n\u2705 VERIFIED (98% confidence)\nSource: NVIDIA official specs\nDetails: RTX 4090 has 24GB GDDR6X memory\n</code></pre> <p>Cost Optimization Tip:</p> <p>Pair expensive orchestration with cheap models: - Use Tier C model (fast, cheap) for initial research - Use Tier A model (slow, powerful) for final synthesis/verification only - Example: 3 parallel Tier C searches \u2192 1 Tier A synthesis = $0.05 total vs. $0.45 for direct Tier A</p> <p>See Also: Advanced Skill Development for custom orchestration patterns.</p>"},{"location":"Tools-and-Skills-Reference/#github_search-github_pr_create-github_action_trigger","title":"github_search / github_pr_create / github_action_trigger","text":"<p>Purpose: Automate GitHub workflows Required: GitHub personal access token (for create/trigger) Config: <pre><code>{\n  \"tools\": {\n    \"github\": {\n      \"token\": \"github_pat_...\",\n      \"allowFrom\": [\"USER_ID\"]\n    }\n  }\n}\n</code></pre> Usage Examples: <pre><code>\"Search nanobot repo for issues tagged 'bug'\"\n\"Create a PR to add docstrings to parser.py\"\n\"Trigger the 'deploy' workflow in main branch\"\n</code></pre></p>"},{"location":"Tools-and-Skills-Reference/#3-skills-overview","title":"3. Skills Overview","text":"<p>Skills are pre-built, opinionated bundles of tools configured for specific business functions. (Think of a skill as a \"ready-to-use package\" that combines multiple tools to solve a specific problem.)</p>"},{"location":"Tools-and-Skills-Reference/#built-in-skills","title":"Built-In Skills","text":""},{"location":"Tools-and-Skills-Reference/#1-obsidian","title":"1. obsidian","text":"<p>Purpose: Read, write, and query Obsidian vault from nanobot Install: <code>nanobot skill add obsidian</code> (or included by default) Config: <pre><code>{\n  \"obsidianVaultPath\": \"~/Documents/ObsidianVault\",\n  \"obsidianRestEndpoint\": \"http://localhost:18790\",\n  \"obsidianRestToken\": \"token...\"\n}\n</code></pre> Usage: <pre><code>\"Read the project roadmap from Roadmap.md\"\n\"Write a research summary to 08-Research/AI-Safety/2026-02.md\"\n\"Query all notes tagged with #decision\"\n</code></pre></p>"},{"location":"Tools-and-Skills-Reference/#2-memory","title":"2. memory","text":"<p>Purpose: Manage conversation sessions and memory consolidation Install: Built-in Features: - Automatic memory consolidation for long conversations - Session isolation per user - Token budget enforcement - Retention policies Usage: Automatic; configure via: <pre><code>{\n  \"session\": {\n    \"memoryWindow\": 100,\n    \"maxSessionTokens\": 32000\n  }\n}\n</code></pre></p>"},{"location":"Tools-and-Skills-Reference/#3-summarize","title":"3. summarize","text":"<p>Purpose: Condense long content while preserving key information Install: Built-in Config: No special config Usage: <pre><code>\"Summarize this 50-page PDF to 1 page\"\n\"Create a 3-sentence summary of today's Discord activity\"\n\"Condense this research into key findings + citations\"\n</code></pre></p>"},{"location":"Tools-and-Skills-Reference/#4-cron-scheduler","title":"4. cron (Scheduler)","text":"<p>Purpose: Run tasks on recurring schedules Install: <code>nanobot skill add cron</code> Config: <pre><code>{\n  \"cron\": {\n    \"enabled\": true,\n    \"allowedJobs\": [\"daily_digest\", \"backup\", \"health_check\"]\n  }\n}\n</code></pre> Usage Examples: <pre><code>\"Schedule a health check every hour\"\n\"Run a daily journal summarizer at 23:50\"\n\"Backup workspace every Sunday at 2 AM\"\n</code></pre></p>"},{"location":"Tools-and-Skills-Reference/#5-weather","title":"5. weather","text":"<p>Purpose: Fetch current and forecast weather data Install: <code>nanobot skill add weather</code> Config: No API key needed (free service) Usage: <pre><code>\"What's the weather in San Francisco?\"\n\"Get 5-day forecast for New York\"\n</code></pre></p>"},{"location":"Tools-and-Skills-Reference/#6-clawhub","title":"6. clawhub","text":"<p>Purpose: Search and install public skills from ClawHub marketplace Install: <code>nanobot skill add clawhub</code> Usage: <pre><code>\"Search ClawHub for 'email' skills\"\n\"Install the 'LinkedIn Poster' skill from ClawHub\"\n</code></pre> Note: ClawHub is a skill marketplace; vet all skills before installing.</p>"},{"location":"Tools-and-Skills-Reference/#7-skill-creator","title":"7. skill-creator","text":"<p>Purpose: Auto-generate new skills from natural language descriptions Install: <code>nanobot skill add skill-creator</code> Usage: <pre><code>\"Create a new skill: read financial PDFs and extract quarterly earnings\"\n\"Generate a skill for checking DNS records\"\n</code></pre></p>"},{"location":"Tools-and-Skills-Reference/#8-tmux","title":"8. tmux","text":"<p>Purpose: Control terminal multiplexer for advanced automation Install: <code>nanobot skill add tmux</code> Config: <pre><code>{\n  \"tmux\": {\n    \"defaultSession\": \"main\",\n    \"allowFrom\": [\"TRUSTED_USER_ID\"]\n  }\n}\n</code></pre> Usage: <code>\"Start a tmux session 'dev' and run my build script\"</code></p>"},{"location":"Tools-and-Skills-Reference/#9-github","title":"9. github","text":"<p>Purpose: GitHub automation (search, create PRs, trigger workflows) Install: Built-in Config: <pre><code>{\n  \"github\": {\n    \"token\": \"github_pat_...\",\n    \"defaultOrg\": \"your-org\"\n  }\n}\n</code></pre> Usage: <pre><code>\"Search our 'frontend' repo for TypeScript issues\"\n\"Create a PR to update dependencies\"\n\"Trigger 'test' workflow\"\n</code></pre></p>"},{"location":"Tools-and-Skills-Reference/#4-custom-tools","title":"4. Custom Tools","text":"<p>Add custom tool implementations to extend nanobot:</p> <p>Example: Custom Weather Tool <pre><code># ~/.nanobot/tools/custom_weather.py\nfrom nanobot.agent.tools import BaseTool\n\nclass CustomWeatherTool(BaseTool):\n    name = \"custom_weather\"\n    description = \"Fetch weather from internal weather service\"\n\n    async def execute(self, location: str) -&gt; dict:\n        # Your custom logic here\n        return {\"temperature\": 72, \"condition\": \"sunny\"}\n</code></pre></p> <p>Register in config: <pre><code>{\n  \"customTools\": [\n    \"~/.nanobot/tools/custom_weather\"\n  ]\n}\n</code></pre></p>"},{"location":"Tools-and-Skills-Reference/#5-custom-skills","title":"5. Custom Skills","text":"<p>Create a new skill by bundling tools with business logic:</p> <p>Example: Bookkeeping Reconciliation Skill <pre><code># ~/.nanobot/skills/bk_reconcile.py\nfrom nanobot.agent.skills import BaseSkill\n\nclass BookkeepingReconcileSkill(BaseSkill):\n    id = \"bk_reconcile\"\n    description = \"Reconcile transactions against ledger\"\n\n    async def execute(self, csv_file: str, ledger_date: str) -&gt; dict:\n        # 1. Read CSV via file_read tool\n        # 2. Parse transactions\n        # 3. Query ledger (via MCP or database tool)\n        # 4. identify discrepancies\n        # 5. Write summary to Obsidian\n        return {\"status\": \"reconciled\", \"discrepancies\": [...]}\n</code></pre></p> <p>Install: <pre><code>nanobot skill add ~/.nanobot/skills/bk_reconcile\n</code></pre></p>"},{"location":"Tools-and-Skills-Reference/#6-tool-allowlisting-aos-security","title":"6. Tool Allowlisting (AOS Security)","text":"<p>Restrict tools per channel:</p> <pre><code>{\n  \"channels\": {\n    \"discord\": {\n      \"allowedTools\": {\n        \"#ctl-nanobot\": [\"shell\", \"mcp\", \"github\"],\n        \"#prd-*\": [\"web\", \"file\", \"message\"],\n        \"#bk-*\": [\"file\", \"message\", \"obsidian\"],\n        \"#res-*\": [\"web\", \"message\", \"obsidian\"],\n        \"default\": [\"web\", \"file\", \"message\"]\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"Tools-and-Skills-Reference/#7-tool-cost-performance-reference","title":"7. Tool Cost &amp; Performance Reference","text":"Tool Latency Cost/Call Context Impact web_search 2-5s ~$0.01 5-10KB web_fetch 1-3s None 10-50KB file_* &lt;100ms None &lt;1KB shell_exec 1-30s None Varies message_send &lt;100ms None &lt;1KB mcp_call Varies Varies Depends cron_schedule N/A None None subagent_spawn High +cost per agent +memory github_* 1-5s None &lt;5KB"},{"location":"Tools-and-Skills-Reference/#8-troubleshooting-tools","title":"8. Troubleshooting Tools","text":"<p>Tool disabled error: <pre><code>\"web_search\" tool not available in #bk-finances\n</code></pre> Fix: Add <code>web</code> to allowed tools for that channel.</p> <p>Tool timeout: <pre><code>shell_exec timed out after 30s\n</code></pre> Fix: Increase <code>timeout</code> config or optimize command.</p> <p>MCP connection failed: <pre><code>Cannot connect to MCP server: mydb\n</code></pre> Fix: Verify MCP server is running and auth headers are correct.</p>"},{"location":"Tools-and-Skills-Reference/#9-revision-history","title":"9. Revision History","text":"Date Version Change 2026-02-25 1.0.0 Initial comprehensive reference for 14 tools and 9 pre-built skills"},{"location":"Workflow-Examples-and-Recipes/","title":"Workflow Examples &amp; Recipes","text":"<p>Real-world nanobot workflows. Copy, customize, and deploy.</p>"},{"location":"Workflow-Examples-and-Recipes/#document-control","title":"Document Control","text":"<ul> <li>Owner:</li> <li>Version: 1.0.0</li> <li>Last Updated: 2026-02-25</li> <li>Status: Active</li> </ul>"},{"location":"Workflow-Examples-and-Recipes/#1-daily-knowledge-consolidation-obsidian-cron-summarize","title":"1. Daily Knowledge Consolidation (Obsidian + Cron + Summarize)","text":"<p>Goal: Every night at 2am, summarize yesterday's Discord #prd channel into Obsidian vault.</p> <p>Tools used: cron_schedule, file_read, file_write, shell_exec (python + summarize skill)</p> <p>Why useful: Engineering teams generate insights constantly; capturing them prevents loss.</p>"},{"location":"Workflow-Examples-and-Recipes/#setup","title":"Setup","text":"<p>1.1 Config (in ~/.nanobot/config.json):</p> <pre><code>{\n  \"channels\": {\n    \"discord\": {\n      \"enabled\": true,\n      \"token\": \"your-discord-token\",\n      \"listen_channels\": [\"prd\"]\n    }\n  },\n  \"skills\": {\n    \"obsidian\": {\n      \"enabled\": true,\n      \"vault_path\": \"/path/to/obsidian/vault\"\n    },\n    \"summarize\": {\n      \"enabled\": true,\n      \"model\": \"qwen2:latest\"\n    },\n    \"cron\": {\n      \"enabled\": true\n    }\n  }\n}\n</code></pre> <p>1.2 Create Cron Job (in Discord):</p> <p>Send this message to trigger scheduled job creation:</p> <pre><code>@BotName cron create: nightly_prd_summary\n  schedule: \"0 2 * * *\"\n  action: \"Summarize Discord #prd from yesterday and write to Obsidian daily-standup/{date}.md\"\n  provider: qwen2:latest\n  output_format: markdown\n</code></pre> <p>1.3 Check Job Created:</p> <pre><code>@BotName cron list\n</code></pre> <p>Output: <pre><code>\u2713 nightly_prd_summary (0 2 * * *) - Last run: 2026-02-25 02:01\n</code></pre></p>"},{"location":"Workflow-Examples-and-Recipes/#execution-automatic-every-night","title":"Execution (Automatic Every Night)","text":"<p>What happens at 2am:</p> <ol> <li>Nanobot reads last 24h of #prd messages</li> <li>Runs summarize skill: \"Extract key decisions, blockers, and discussions\"</li> <li>Formats as Markdown with timestamps and attributions</li> <li>Writes to: <code>Obsidian/01-Daily/2026-02-25.md</code></li> <li>Posts confirmation to #prd: \"Summary written \u2713\"</li> </ol>"},{"location":"Workflow-Examples-and-Recipes/#sample-output","title":"Sample Output","text":"<p>File: <code>/Obsidian/01-Daily/2026-02-25.md</code></p> <pre><code># Daily Standup - Feb 25, 2026\n\n## Key Decisions\n- **Design System:** Approved new component library (Alex, 2:15pm)\n- **Timeline:** Sprint ends Friday with demo Friday 4pm (Sara, 3:22pm)\n\n## Blockers\n- S3 integration failing with session token expiration (James, 1:45pm)\n  - Action: James to investigate IAM policy with DevOps team\n\n## Technical Discussions\n- Python async patterns for high-concurrency services (3 messages)\n- Caching strategy for API responses (2 threads)\n\n## Attendees\n- @alex, @sara, @james, @yuki, @alex\n\n## Full Transcript\n[link to Discord thread]\n</code></pre>"},{"location":"Workflow-Examples-and-Recipes/#customization-ideas","title":"Customization Ideas","text":"<p>Variation 1: Weekly Executive Summary</p> <pre><code>schedule: \"0 8 * * 1\"  // Monday 8am\nformat: executive_brief  // Shorter, business-focused\nchannels: [\"prd\", \"exec\", \"strategy\"]  // Multiple channels\n</code></pre> <p>Variation 2: Per-Team Summaries</p> <pre><code>{\n  \"cron_jobs\": [\n    { \"channel\": \"prd\", \"team\": \"engineering\", \"time\": \"8am\" },\n    { \"channel\": \"marketing\", \"team\": \"marketing\", \"time\": \"9am\" },\n    { \"channel\": \"sales\", \"team\": \"sales\", \"time\": \"10am\" }\n  ]\n}\n</code></pre> <p>Variation 3: Slack Instead of Obsidian</p> <pre><code>action: \"Summarize and post to Slack #daily-standup\"\n</code></pre>"},{"location":"Workflow-Examples-and-Recipes/#2-multi-channel-content-distribution","title":"2. Multi-Channel Content Distribution","text":"<p>Goal: User writes article in Discord. Automatically posts to Discord, Slack, Telegram with platform-specific formatting.</p> <p>Tools used: message_send (with channel routing), file_read, shell_exec (for formatting)</p> <p>Why useful: Marketing teams write once, distribute everywhere. No copy-pasting errors.</p>"},{"location":"Workflow-Examples-and-Recipes/#setup_1","title":"Setup","text":"<p>2.1 Config:</p> <pre><code>{\n  \"channels\": {\n    \"discord\": { \"enabled\": true },\n    \"slack\": { \"enabled\": true },\n    \"telegram\": { \"enabled\": true }\n  },\n  \"tools\": {\n    \"message_send\": {\n      \"enabled\": true,\n      \"default_channel\": \"discord\",\n      \"routing\": {\n        \"twitter\": \"telegram\",\n        \"blog\": [\"discord\", \"slack\"],\n        \"announcement\": [\"discord\", \"slack\", \"telegram\"]\n      }\n    }\n  }\n}\n</code></pre> <p>2.2 Trigger in Discord:</p> <p>User post in #content-hub:</p> <pre><code>@BotName post:\nTitle: \"5 Nanobot Best Practices\"\nBody: &gt; Best practices for deploying nanobot at scale...\n[full article text]\n\nDistribute to: announcement\n</code></pre>"},{"location":"Workflow-Examples-and-Recipes/#execution","title":"Execution","text":"<p>What Bot Does:</p> <ol> <li>Format for Discord:</li> <li>Embed with title + body + author</li> <li>Link to full document</li> <li> <p>Reactions for feedback</p> </li> <li> <p>Format for Slack:</p> </li> <li>Slack blocks layout</li> <li>Threading support</li> <li> <p>Mention relevant team members</p> </li> <li> <p>Format for Telegram:</p> </li> <li>Plain text (Telegram markdown)</li> <li>Link in thread</li> </ol>"},{"location":"Workflow-Examples-and-Recipes/#sample-output_1","title":"Sample Output","text":"<p>Discord: <pre><code>\ud83d\udcf0 5 Nanobot Best Practices\nby @alice | #content-hub\n\nBest practices for deploying nanobot at scale...\n[Read Full Article](link)\n\n\ud83d\udc4d \u2764\ufe0f \ud83d\udd17\n</code></pre></p> <p>Slack: <pre><code>5 Nanobot Best Practices\nPosted by alice in #content-hub\n\nBest practices for deploying nanobot at scale...\nRead Full Article: [link]\n\n\nThread: 0 replies | 2 emoji reactions\n</code></pre></p> <p>Telegram: <pre><code>\ud83d\udcf0 5 Nanobot Best Practices\n@alice\n\nBest practices for deploying nanobot...\n\nRead: [link]\n</code></pre></p>"},{"location":"Workflow-Examples-and-Recipes/#cost-0005-per-distribution-tier-b","title":"Cost: ~$0.005 per distribution (Tier B)","text":""},{"location":"Workflow-Examples-and-Recipes/#3-customer-support-bot-multi-channel","title":"3. Customer Support Bot (Multi-Channel)","text":"<p>Goal: Answer customer questions in Discord, Slack, Telegram. Route to human if confidence &lt;70%.</p> <p>Tools used: web_search, file_read (knowledge base), message_send, mcp_call (to ticket system)</p> <p>Why useful: 24/7 support, reduce ticket volume by 50-60%, instant answers.</p>"},{"location":"Workflow-Examples-and-Recipes/#setup_2","title":"Setup","text":"<p>3.1 Config:</p> <pre><code>{\n  \"channels\": {\n    \"discord\": { \"enabled\": true, \"channels\": [\"#support\"] },\n    \"slack\": { \"enabled\": true, \"channels\": [\"#help\"] },\n    \"telegram\": { \"enabled\": true }\n  },\n  \"tools\": {\n    \"web_search\": { \"enabled\": true, \"api_key\": \"brave_key\" },\n    \"file_read\": { \"enabled\": true }\n  },\n  \"skills\": {\n    \"memory\": {\n      \"enabled\": true,\n      \"knowledge_base\": \"/path/to/support-docs\"\n    }\n  },\n  \"routing\": {\n    \"confidence_threshold\": 0.70,\n    \"low_confidence_action\": \"escalate_to_human\"\n  }\n}\n</code></pre> <p>3.2 Knowledge Base File Structure:</p> <pre><code>/knowledge-base/\n\u251c\u2500\u2500 faq.md (Common questions &amp; answers)\n\u251c\u2500\u2500 troubleshooting.md (Error codes + fixes)\n\u251c\u2500\u2500 api-docs.md (API reference)\n\u2514\u2500\u2500 pricing.md (Pricing &amp; billing)\n</code></pre>"},{"location":"Workflow-Examples-and-Recipes/#execution_1","title":"Execution","text":"<p>User in Discord #support:</p> <pre><code>@BotName: How do I enable multi-channel support?\n</code></pre> <p>Bot Process:</p> <ol> <li>Search knowledge base for \"multi-channel\"</li> <li>Search web if not found locally</li> <li>Generate answer with confidence score</li> <li>If confidence &gt;70%: Post answer</li> <li>If confidence &lt;70%: Tag @support-team with context</li> </ol> <p>Sample Output:</p> <pre><code>\u2713 How do I enable multi-channel support?\n\nTo enable multi-channel support, edit ~/.nanobot/config.json:\n\n{\n  \"channels\": {\n    \"discord\": { \"enabled\": true },\n    \"slack\": { \"enabled\": true }\n  }\n}\n\nThen restart: nanobot gateway\n\n\ud83d\udcda See: [Full Multi-Channel Guide](link)\n\ud83d\udc65 Still need help? Thread @alice, @bob, or @support-team\n</code></pre>"},{"location":"Workflow-Examples-and-Recipes/#advanced-escalation-logic","title":"Advanced: Escalation Logic","text":"<p>If bot unsure, creates MCP ticket:</p> <pre><code>\ud83e\udd14 I'm not confident in my answer (62% confidence).\nEscalating to human team...\n\n\ud83d\udccb Internal Ticket ID: SUP-2026-0225-001\n\ud83d\udc65 Assigned to: next available\n\u23f1\ufe0f Est. response: 15 mins\n\nCustomer sees: \"A human team member will respond shortly\"\n</code></pre>"},{"location":"Workflow-Examples-and-Recipes/#handle-volume","title":"Handle Volume","text":"<p>For 100 support questions/day: - Auto-answer: 60-70 questions (~$2.25/month Tier C) - Escalate: 30-40 questions (~30 mins human review) - ROI: ~2 person-hours saved, net positive</p>"},{"location":"Workflow-Examples-and-Recipes/#4-research-agent-web-search-synthesis","title":"4. Research Agent (Web Search + Synthesis)","text":"<p>Goal: User asks research question. Bot searches web, reads articles, synthesizes findings into report.</p> <p>Tools used: web_search, file_read, file_write, shell_exec (for web scraping)</p> <p>Why useful: Replace 2-3 hour research task with 2-minute bot task.</p>"},{"location":"Workflow-Examples-and-Recipes/#setup_3","title":"Setup","text":"<p>4.1 Config:</p> <pre><code>{\n  \"tools\": {\n    \"web_search\": {\n      \"enabled\": true,\n      \"api_key\": \"brave_api_key\",\n      \"max_results\": 10\n    },\n    \"file_read\": { \"enabled\": true },\n    \"file_write\": { \"enabled\": true }\n  },\n  \"llm\": {\n    \"model\": \"claude-opus\",\n    \"tier\": \"a\"\n  }\n}\n</code></pre>"},{"location":"Workflow-Examples-and-Recipes/#trigger-in-discord-research","title":"Trigger (in Discord #research)","text":"<pre><code>@BotName research:\nQuestion: \"What are latest trends in AI agent frameworks (Feb 2026)?\"\nFormat: report\nOutput: obsidian_file\nVault path: /obsidian/01-Research/{date}-{topic}.md\n</code></pre>"},{"location":"Workflow-Examples-and-Recipes/#execution_2","title":"Execution","text":"<p>Bot Process (takes 2-3 min):</p> <ol> <li>Web search: \"AI agent frameworks 2026 trends\"</li> <li>Read top 10 articles</li> <li>Extract key points: frameworks, capabilities, costs, adoption</li> <li>Synthesize into structured report</li> <li>Write to Obsidian with citations</li> </ol> <p>Sample Output:</p> <p>File: <code>/Obsidian/01-Research/2026-02-25-AI-Agent-Frameworks.md</code></p> <pre><code># AI Agent Frameworks - Trends Feb 2026\n\n## Executive Summary\n3 major frameworks dominating: Nanobot, AutoGPT-7, and Cursor-AI v2.\nCommon pattern: LLM routing + tool composition + memory consolidation.\n\n## Framework Comparison\n\n| Framework | LLM Support | Tools | Channels | Cost/mo |\n|---|---|---|---|---|\n| **Nanobot** | 100+ | 14 | 12+ | $0-200 |\n| **AutoGPT-7** | OpenAI only | 30 | 5 | $50-500 |\n| **Cursor-AI** | varies | 50+ | 3 | $20-300 |\n\n## Key Trends\n\n1. **Multi-provider routing** - Cost optimization (Trend strength: ++++)\n2. **Memory consolidation** - Reduce context window costs (++++)\n3. **Self-hosted inference** - Privacy + cost control (+++)\n4. **Tool composition** - Complex workflows from simple primitives (++++)\n\n## Detailed Analysis\n[30-50 lines of synthesis]\n\n## Sources\n- [Article 1](url) - \"2026 State of AI Agents\"\n- [Article 2](url) - \"Framework Benchmark Report\"\n- [Article 3](url) - \"Enterprise AI Agent Adoption\"\n\nGenerated 2026-02-25 by Nanobot Research Agent\n</code></pre>"},{"location":"Workflow-Examples-and-Recipes/#cost-002-per-research-task-tier-a-claude-opus","title":"Cost: ~$0.02 per research task (Tier A - Claude Opus)","text":"<p>ROI: Replaces 1-2 hours manual research at cost of $0.02 \ud83c\udfaf</p>"},{"location":"Workflow-Examples-and-Recipes/#5-github-automation-daily-standup","title":"5. GitHub Automation &amp; Daily Standup","text":"<p>Goal: Every morning, summarize overnight PRs/issues, post to Discord #engineering.</p> <p>Tools used: github_get_prs, github_get_issues, summarize skill, message_send, cron_schedule</p> <p>Why useful: Engineering team aware of PRs needing review without checking GitHub.</p>"},{"location":"Workflow-Examples-and-Recipes/#setup_4","title":"Setup","text":"<p>5.1 Config:</p> <pre><code>{\n  \"tools\": {\n    \"github\": {\n      \"enabled\": true,\n      \"token\": \"github-personal-access-token\",\n      \"org\": \"your-org\",\n      \"repos\": [\"nanobot\", \"cli-tools\", \"integrations\"]\n    }\n  },\n  \"skills\": {\n    \"cron\": { \"enabled\": true },\n    \"summarize\": { \"enabled\": true }\n  },\n  \"channels\": {\n    \"discord\": { \"enabled\": true }\n  }\n}\n</code></pre> <p>5.2 Create Cron Job:</p> <pre><code>@BotName cron create: morning_github_standup\n  schedule: \"0 8 * * 1-5\"  // Mon-Fri 8am\n  action: \"\n    Get all open PRs and issues from last 24h across repos\n    Summarize: PRs awaiting review, merged PRs, new critical issues\n    Post to Discord #engineering with action items\n  \"\n  provider: openrouter/qwen2:latest\n</code></pre>"},{"location":"Workflow-Examples-and-Recipes/#execution_3","title":"Execution","text":"<p>Every Weekday 8am:</p> <p>Bot fetches from GitHub: - 3 PRs opened overnight (with file diffs) - 8 PRs merged yesterday - 2 new critical issues - 15 comments on open PRs</p> <p>Generates summary:</p> <p>Discord #engineering:</p> <pre><code>\ud83d\udcca GitHub Standup - Thursday Feb 25\n\n## PRs Awaiting Review (3)\n\ud83d\udd34 #456: Refactor auth middleware (alice) - 8 files, needs review\n\ud83d\udfe1 #457: Add caching layer (bob) - 3 files, 1 approval needed\n\ud83d\udfe1 #458: Update dependencies (dependabot) - automated\n\n## Merged Yesterday (8)\n\u2705 #445: Fix S3 upload bug\n\u2705 #446: Add telemetry logging\n\u2705 #447-452: Dependency updates\n\n## Critical Issues (2)\n\ud83d\udd34 #2034: Memory leak in connection pool (opened 3h ago)\n\ud83d\udd34 #2035: API rate limiting broken\n\n## Action Items\n- @alice: Review #457 (3 mins)\n- @james: Investigate #2034 (estimate 1h)\n- @sara: Prioritize #2035 after standup\n\n## Stats\n- 8 PRs merged | 3 awaiting review | 14 commits\n- Test coverage: 87% (\u2191 1%)\n\n[Full report](link to GitHub)\n</code></pre>"},{"location":"Workflow-Examples-and-Recipes/#cost-0003-per-run-tier-c-daily-0003-per-run-tier-c-daily-009month","title":"Cost: ~0.003 per run (Tier C - daily) = **0.09/month**","text":""},{"location":"Workflow-Examples-and-Recipes/#6-obsidian-sync-weekly-review","title":"6. Obsidian Sync + Weekly Review","text":"<p>Goal: Friday 5pm, auto-generate weekly review from Obsidian vault + Discord logs.</p> <p>Tools used: file_read (Obsidian), shell_exec (Obsidian API), summarize skill, file_write</p> <p>Why useful: Weekly reflection on team progress, decisions, and blockers.</p>"},{"location":"Workflow-Examples-and-Recipes/#setup_5","title":"Setup","text":"<p>6.1 Obsidian Vault Structure:</p> <pre><code>/Vault/\n\u251c\u2500\u2500 00-System/\n\u2502   \u2514\u2500\u2500 weekly-review-template.md\n\u251c\u2500\u2500 01-Daily/\n\u2502   \u251c\u2500\u2500 2026-02-21.md\n\u2502   \u251c\u2500\u2500 2026-02-22.md\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 02-Project/\n\u2502   \u251c\u2500\u2500 project-a.md\n\u2502   \u251c\u2500\u2500 project-b.md\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 03-Archive/\n    \u2514\u2500\u2500 weekly-2026-w08.md\n</code></pre> <p>6.2 Cron Job:</p> <pre><code>@BotName cron create: weekly_review\n  schedule: \"0 17 * * 5\"  // Friday 5pm\n  action: \"\n    1. Read daily notes from last 7 days\n    2. Extract decisions, blockers, wins\n    3. Summarize project updates\n    4. Generate weekly review\n    5. Save to 03-Archive/weekly-{date}.md\n    6. Post summary to Discord #weekly-review\n  \"\n</code></pre>"},{"location":"Workflow-Examples-and-Recipes/#sample-output_2","title":"Sample Output","text":"<p>Discord #weekly-review:</p> <pre><code>\ud83d\udccb Weekly Review - Week of Feb 24\n\n**Wins This Week**\n\u2705 Launched multi-channel support (Major!)\n\u2705 Cut API latency by 40% with caching\n\u2705 Onboarded 3 new team members\n\n**Blockers**\n\ud83d\udd34 S3 integration still failing (blocker for 2 PRs)\n\ud83d\udfe1 API rate limits causing test flakiness\n\n**Key Decisions**\n- \u2713 Approved new design system (for Q2 rollout)\n- \u2713 Migrated to OpenRouter for cost control (saving 70%)\n- \u2713 Delayed mobile app launch to May (more runway needed)\n\n**Team Metrics**\n- 23 PRs merged | 3 critical bugs fixed\n- Code coverage: 87% (\u2191 1%)\n- Release readiness: 94%\n\n**Next Week Priorities**\n1. Fix S3 blocker (alice + james)\n2. Complete onboarding (sara)\n3. Q2 planning kickoff (friday afternoon)\n\n[Full weekly review](link)\n</code></pre>"},{"location":"Workflow-Examples-and-Recipes/#mixing-matching","title":"Mixing &amp; Matching","text":"<p>All these recipes share common patterns. Combine them:</p> <ul> <li>Daily Standup + Multi-Channel Distribution: Write once, post everywhere</li> <li>Research Agent + Obsidian: Auto-capture findings</li> <li>GitHub Standup + Cron: Every morning, team has context</li> <li>Customer Support + Memory: Knowledge base grows with every ticket</li> </ul> <p>Cost for running all 6 workflows continuously: - ~$50-100/month combined (using Tier B+C routing) - Replaces: ~10-15 person-hours/week work - ROI: 20-30x annual payback</p>"},{"location":"Workflow-Examples-and-Recipes/#customization-template","title":"Customization Template","text":"<p>Use this for building your own workflow:</p> <pre><code>Name: [workflow name]\nGoal: [what problem does this solve]\nTools: [list tools used]\n\nSetup:\n1. [Config changes]\n2. [File structures needed]\n3. [Initial trigger/setup]\n\nExecution:\n- [Step 1]\n- [Step 2]\n- [Step 3]\n\nSample Output:\n[Real example of what user sees]\n\nCost:\n[Est. cost/month]\n\nVariations:\n- [Variation 1]\n- [Variation 2]\n</code></pre>"},{"location":"Workflow-Examples-and-Recipes/#revision-history","title":"Revision History","text":"Date Version Change 2026-02-25 1.0.0 Initial workflow examples and recipes"}]}